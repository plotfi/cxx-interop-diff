import Combine
import _Concurrency
@_exported import os_object
@_exported import std_config

var __bool_true_false_are_defined: Int32 { get }
var DISPATCH_API_VERSION: Int32 { get }
var DISPATCH_SWIFT3_OVERLAY: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_function_t = @convention(c) (UnsafeMutableRawPointer?) -> Void
var NSEC_PER_SEC: UInt64 { get }
var NSEC_PER_MSEC: UInt64 { get }
var USEC_PER_SEC: UInt64 { get }
var NSEC_PER_USEC: UInt64 { get }

/**
 * @typedef dispatch_time_t
 *
 * @abstract
 * A somewhat abstract representation of time; where zero means "now" and
 * DISPATCH_TIME_FOREVER means "infinity" and every value in between is an
 * opaque encoding.
 */
typealias dispatch_time_t = UInt64
@available(iOS 12.0, *)
var DISPATCH_WALLTIME_NOW: UInt { get }
var DISPATCH_TIME_NOW: UInt64 { get }
var DISPATCH_TIME_FOREVER: UInt64 { get }

/**
 * @function dispatch_time
 *
 * @abstract
 * Create a dispatch_time_t relative to the current value of the default or
 * wall time clock, or modify an existing dispatch_time_t.
 *
 * @discussion
 * On Apple platforms, the default clock is based on mach_absolute_time().
 *
 * @param when
 * An optional dispatch_time_t to add nanoseconds to. If DISPATCH_TIME_NOW is
 * passed, then dispatch_time() will use the default clock (which is based on
 * mach_absolute_time() on Apple platforms). If DISPATCH_WALLTIME_NOW is used,
 * dispatch_time() will use the value returned by gettimeofday(3).
 * dispatch_time(DISPATCH_WALLTIME_NOW, delta) is equivalent to
 * dispatch_walltime(NULL, delta).
 *
 * @param delta
 * Nanoseconds to add.
 *
 * @result
 * A new dispatch_time_t.
 */
@available(iOS 4.0, *)
func __dispatch_time(_ when: dispatch_time_t, _ delta: Int64) -> dispatch_time_t

/**
 * @function dispatch_walltime
 *
 * @abstract
 * Create a dispatch_time_t using the wall clock.
 *
 * @discussion
 * On Mac OS X the wall clock is based on gettimeofday(3).
 *
 * @param when
 * A struct timespec to add time to. If NULL is passed, then
 * dispatch_walltime() will use the result of gettimeofday(3).
 * dispatch_walltime(NULL, delta) returns the same value as
 * dispatch_time(DISPATCH_WALLTIME_NOW, delta).
 *
 * @param delta
 * Nanoseconds to add.
 *
 * @result
 * A new dispatch_time_t.
 */
@available(iOS 4.0, *)
func __dispatch_walltime(_ when: UnsafePointer<timespec>?, _ delta: Int64) -> dispatch_time_t
class DispatchObject : OS_object {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}
@available(swift, obsoleted: 3, renamed: "DispatchObject")
typealias OS_dispatch_object = DispatchObject
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_object_t = DispatchObject

/**
 * @typedef dispatch_block_t
 *
 * @abstract
 * The type of blocks submitted to dispatch queues, which take no arguments
 * and have no return value.
 *
 * @discussion
 * When not building with Objective-C ARC, a block object allocated on or
 * copied to the heap must be released with a -[release] message or the
 * Block_release() function.
 *
 * The declaration of a block literal allocates storage on the stack.
 * Therefore, this is an invalid construct:
 * <code>
 * dispatch_block_t block;
 * if (x) {
 *     block = ^{ printf("true\n"); };
 * } else {
 *     block = ^{ printf("false\n"); };
 * }
 * block(); // unsafe!!!
 * </code>
 *
 * What is happening behind the scenes:
 * <code>
 * if (x) {
 *     struct Block __tmp_1 = ...; // setup details
 *     block = &__tmp_1;
 * } else {
 *     struct Block __tmp_2 = ...; // setup details
 *     block = &__tmp_2;
 * }
 * </code>
 *
 * As the example demonstrates, the address of a stack variable is escaping the
 * scope in which it is allocated. That is a classic C bug.
 *
 * Instead, the block literal must be copied to the heap with the Block_copy()
 * function or by sending it a -[copy] message.
 */
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_block_t = () -> Void
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_qos_class_t = qos_class_t

/**
 * @function dispatch_retain
 *
 * @abstract
 * Increment the reference count of a dispatch object.
 *
 * @discussion
 * Calls to dispatch_retain() must be balanced with calls to
 * dispatch_release().
 *
 * @param object
 * The object to retain.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_retain(_ object: DispatchObject)

/**
 * @function dispatch_release
 *
 * @abstract
 * Decrement the reference count of a dispatch object.
 *
 * @discussion
 * A dispatch object is asynchronously deallocated once all references are
 * released (i.e. the reference count becomes zero). The system does not
 * guarantee that a given client is the last or only reference to a given
 * object.
 *
 * @param object
 * The object to release.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_release(_ object: DispatchObject)

/**
 * @function dispatch_get_context
 *
 * @abstract
 * Returns the application defined context of the object.
 *
 * @param object
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * The context of the object; may be NULL.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_get_context(_ object: DispatchObject) -> UnsafeMutableRawPointer?

/**
 * @function dispatch_set_context
 *
 * @abstract
 * Associates an application defined context with the object.
 *
 * @param object
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The new client defined context for the object. This may be NULL.
 *
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_set_context(_ object: DispatchObject, _ context: UnsafeMutableRawPointer?)

/**
 * @function dispatch_set_finalizer_f
 *
 * @abstract
 * Set the finalizer function for a dispatch object.
 *
 * @param object
 * The dispatch object to modify.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param finalizer
 * The finalizer function pointer.
 *
 * @discussion
 * A dispatch object's finalizer will be invoked on the object's target queue
 * after all references to the object have been released. This finalizer may be
 * used by the application to release any resources associated with the object,
 * such as freeing the object's context.
 * The context parameter passed to the finalizer function is the current
 * context of the dispatch object at the time the finalizer call is made.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_set_finalizer_f(_ object: DispatchObject, _ finalizer: (@convention(c) (UnsafeMutableRawPointer?) -> Void)?)

/**
 * @function dispatch_activate
 *
 * @abstract
 * Activates the specified dispatch object.
 *
 * @discussion
 * Dispatch objects such as queues and sources may be created in an inactive
 * state. Objects in this state have to be activated before any blocks
 * associated with them will be invoked.
 *
 * The target queue of inactive objects can be changed using
 * dispatch_set_target_queue(). Change of target queue is no longer permitted
 * once an initially inactive object has been activated.
 *
 * Calling dispatch_activate() on an active object has no effect.
 * Releasing the last reference count on an inactive object is undefined.
 *
 * @param object
 * The object to be activated.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 10.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchObject.activate(self:)")
func dispatch_activate(_ object: DispatchObject)
extension DispatchObject {

  /**
   * @function dispatch_activate
   *
   * @abstract
   * Activates the specified dispatch object.
   *
   * @discussion
   * Dispatch objects such as queues and sources may be created in an inactive
   * state. Objects in this state have to be activated before any blocks
   * associated with them will be invoked.
   *
   * The target queue of inactive objects can be changed using
   * dispatch_set_target_queue(). Change of target queue is no longer permitted
   * once an initially inactive object has been activated.
   *
   * Calling dispatch_activate() on an active object has no effect.
   * Releasing the last reference count on an inactive object is undefined.
   *
   * @param object
   * The object to be activated.
   * The result of passing NULL in this parameter is undefined.
   */
  @available(iOS 10.0, *)
  func activate()

  /**
   * @function dispatch_suspend
   *
   * @abstract
   * Suspends the invocation of blocks on a dispatch object.
   *
   * @discussion
   * A suspended object will not invoke any blocks associated with it. The
   * suspension of an object will occur after any running block associated with
   * the object completes.
   *
   * Calls to dispatch_suspend() must be balanced with calls
   * to dispatch_resume().
   *
   * @param object
   * The object to be suspended.
   * The result of passing NULL in this parameter is undefined.
   */
  @available(iOS 4.0, *)
  func suspend()

  /**
   * @function dispatch_resume
   *
   * @abstract
   * Resumes the invocation of blocks on a dispatch object.
   *
   * @discussion
   * Dispatch objects can be suspended with dispatch_suspend(), which increments
   * an internal suspension count. dispatch_resume() is the inverse operation,
   * and consumes suspension counts. When the last suspension count is consumed,
   * blocks associated with the object will be invoked again.
   *
   * For backward compatibility reasons, dispatch_resume() on an inactive and not
   * otherwise suspended dispatch source object has the same effect as calling
   * dispatch_activate(). For new code, using dispatch_activate() is preferred.
   *
   * If the specified object has zero suspension count and is not an inactive
   * source, this function will result in an assertion and the process being
   * terminated.
   *
   * @param object
   * The object to be resumed.
   * The result of passing NULL in this parameter is undefined.
   */
  @available(iOS 4.0, *)
  func resume()

  /**
   * @function dispatch_set_target_queue
   *
   * @abstract
   * Sets the target queue for the given object.
   *
   * @discussion
   * An object's target queue is responsible for processing the object.
   *
   * When no quality of service class and relative priority is specified for a
   * dispatch queue at the time of creation, a dispatch queue's quality of service
   * class is inherited from its target queue. The dispatch_get_global_queue()
   * function may be used to obtain a target queue of a specific quality of
   * service class, however the use of dispatch_queue_attr_make_with_qos_class()
   * is recommended instead.
   *
   * Blocks submitted to a serial queue whose target queue is another serial
   * queue will not be invoked concurrently with blocks submitted to the target
   * queue or to any other queue with that same target queue.
   *
   * The result of introducing a cycle into the hierarchy of target queues is
   * undefined.
   *
   * A dispatch source's target queue specifies where its event handler and
   * cancellation handler blocks will be submitted.
   *
   * A dispatch I/O channel's target queue specifies where where its I/O
   * operations are executed. If the channel's target queue's priority is set to
   * DISPATCH_QUEUE_PRIORITY_BACKGROUND, then the I/O operations performed by
   * dispatch_io_read() or dispatch_io_write() on that queue will be
   * throttled when there is I/O contention.
   *
   * For all other dispatch object types, the only function of the target queue
   * is to determine where an object's finalizer function is invoked.
   *
   * In general, changing the target queue of an object is an asynchronous
   * operation that doesn't take effect immediately, and doesn't affect blocks
   * already associated with the specified object.
   *
   * However, if an object is inactive at the time dispatch_set_target_queue() is
   * called, then the target queue change takes effect immediately, and will
   * affect blocks already associated with the specified object. After an
   * initially inactive object has been activated, calling
   * dispatch_set_target_queue() results in an assertion and the process being
   * terminated.
   *
   * If a dispatch queue is active and targeted by other dispatch objects,
   * changing its target queue results in undefined behavior.
   *
   * @param object
   * The object to modify.
   * The result of passing NULL in this parameter is undefined.
   *
   * @param queue
   * The new target queue for the object. The queue is retained, and the
   * previous target queue, if any, is released.
   * If queue is DISPATCH_TARGET_QUEUE_DEFAULT, set the object's target queue
   * to the default target queue for the given object type.
   */
  @available(iOS 4.0, *)
  func setTarget(queue: DispatchQueue?)
}

/**
 * @function dispatch_suspend
 *
 * @abstract
 * Suspends the invocation of blocks on a dispatch object.
 *
 * @discussion
 * A suspended object will not invoke any blocks associated with it. The
 * suspension of an object will occur after any running block associated with
 * the object completes.
 *
 * Calls to dispatch_suspend() must be balanced with calls
 * to dispatch_resume().
 *
 * @param object
 * The object to be suspended.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchObject.suspend(self:)")
func dispatch_suspend(_ object: DispatchObject)

/**
 * @function dispatch_resume
 *
 * @abstract
 * Resumes the invocation of blocks on a dispatch object.
 *
 * @discussion
 * Dispatch objects can be suspended with dispatch_suspend(), which increments
 * an internal suspension count. dispatch_resume() is the inverse operation,
 * and consumes suspension counts. When the last suspension count is consumed,
 * blocks associated with the object will be invoked again.
 *
 * For backward compatibility reasons, dispatch_resume() on an inactive and not
 * otherwise suspended dispatch source object has the same effect as calling
 * dispatch_activate(). For new code, using dispatch_activate() is preferred.
 *
 * If the specified object has zero suspension count and is not an inactive
 * source, this function will result in an assertion and the process being
 * terminated.
 *
 * @param object
 * The object to be resumed.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchObject.resume(self:)")
func dispatch_resume(_ object: DispatchObject)

/**
 * @function dispatch_set_qos_class_floor
 *
 * @abstract
 * Sets the QOS class floor on a dispatch queue, source or workloop.
 *
 * @discussion
 * The QOS class of workitems submitted to this object asynchronously will be
 * elevated to at least the specified QOS class floor. The QOS of the workitem
 * will be used if higher than the floor even when the workitem has been created
 * without "ENFORCE" semantics.
 *
 * Setting the QOS class floor is equivalent to the QOS effects of configuring
 * a queue whose target queue has a QoS class set to the same value.
 *
 * @param object
 * A dispatch queue, workloop, or source to configure.
 * The object must be inactive.
 *
 * Passing another object type or an object that has been activated is undefined
 * and will cause the process to be terminated.
 *
 * @param qos_class
 * A QOS class value:
 *  - QOS_CLASS_USER_INTERACTIVE
 *  - QOS_CLASS_USER_INITIATED
 *  - QOS_CLASS_DEFAULT
 *  - QOS_CLASS_UTILITY
 *  - QOS_CLASS_BACKGROUND
 * Passing any other value is undefined.
 *
 * @param relative_priority
 * A relative priority within the QOS class. This value is a negative
 * offset from the maximum supported scheduler priority for the given class.
 * Passing a value greater than zero or less than QOS_MIN_RELATIVE_PRIORITY
 * is undefined.
 */
@available(iOS 12.0, *)
func dispatch_set_qos_class_floor(_ object: DispatchObject, _ qos_class: qos_class_t, _ relative_priority: Int32)

/**
 * @function dispatch_wait
 *
 * @abstract
 * Wait synchronously for an object or until the specified timeout has elapsed.
 *
 * @discussion
 * Type-generic macro that maps to dispatch_block_wait, dispatch_group_wait or
 * dispatch_semaphore_wait, depending on the type of the first argument.
 * See documentation for these functions for more details.
 * This function is unavailable for any other object type.
 *
 * @param object
 * The object to wait on.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param timeout
 * When to timeout (see dispatch_time). As a convenience, there are the
 * DISPATCH_TIME_NOW and DISPATCH_TIME_FOREVER constants.
 *
 * @result
 * Returns zero on success or non-zero on error (i.e. timed out).
 */
@available(*, unavailable)
func dispatch_wait(_ object: UnsafeMutableRawPointer, _ timeout: dispatch_time_t) -> Int

/**
 * @function dispatch_notify
 *
 * @abstract
 * Schedule a notification block to be submitted to a queue when the execution
 * of a specified object has completed.
 *
 * @discussion
 * Type-generic macro that maps to dispatch_block_notify or
 * dispatch_group_notify, depending on the type of the first argument.
 * See documentation for these functions for more details.
 * This function is unavailable for any other object type.
 *
 * @param object
 * The object to observe.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param queue
 * The queue to which the supplied notification block will be submitted when
 * the observed object completes.
 *
 * @param notification_block
 * The block to submit when the observed object completes.
 */
@available(*, unavailable)
func dispatch_notify(_ object: UnsafeMutableRawPointer, _ queue: DispatchObject, _ notification_block: @escaping () -> Void)

/**
 * @function dispatch_cancel
 *
 * @abstract
 * Cancel the specified object.
 *
 * @discussion
 * Type-generic macro that maps to dispatch_block_cancel or
 * dispatch_source_cancel, depending on the type of the first argument.
 * See documentation for these functions for more details.
 * This function is unavailable for any other object type.
 *
 * @param object
 * The object to cancel.
 * The result of passing NULL in this parameter is undefined.
 */
@available(*, unavailable)
func dispatch_cancel(_ object: UnsafeMutableRawPointer)

/**
 * @function dispatch_testcancel
 *
 * @abstract
 * Test whether the specified object has been canceled
 *
 * @discussion
 * Type-generic macro that maps to dispatch_block_testcancel or
 * dispatch_source_testcancel, depending on the type of the first argument.
 * See documentation for these functions for more details.
 * This function is unavailable for any other object type.
 *
 * @param object
 * The object to test.
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * Non-zero if canceled and zero if not canceled.
 */
@available(*, unavailable)
func dispatch_testcancel(_ object: UnsafeMutableRawPointer) -> Int

/**
 * @function dispatch_debug
 *
 * @abstract
 * Programmatically log debug information about a dispatch object.
 *
 * @discussion
 * Programmatically log debug information about a dispatch object. By default,
 * the log output is sent to syslog at notice level. In the debug version of
 * the library, the log output is sent to a file in /var/tmp.
 * The log output destination can be configured via the LIBDISPATCH_LOG
 * environment variable, valid values are: YES, NO, syslog, stderr, file.
 *
 * This function is deprecated and will be removed in a future release.
 * Objective-C callers may use -debugDescription instead.
 *
 * @param object
 * The object to introspect.
 *
 * @param message
 * The message to log above and beyond the introspection.
 */
@available(*, unavailable, message: "Variadic function is unavailable")
@available(iOS, unavailable, introduced: 4.0, deprecated: 6.0, message: "unsupported interface")
func dispatch_debug(_ object: DispatchObject, _ message: UnsafePointer<CChar>, _ varargs: Any...)
@available(iOS, unavailable, introduced: 4.0, deprecated: 6.0, message: "unsupported interface")
func dispatch_debugv(_ object: DispatchObject, _ message: UnsafePointer<CChar>, _ ap: CVaListPointer)
class DispatchQueue : DispatchObject {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}

extension DispatchQueue {
  struct Attributes : OptionSet {
    let rawValue: UInt64
    init(rawValue: UInt64)
    static let concurrent: DispatchQueue.Attributes
    @available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
    static let initiallyInactive: DispatchQueue.Attributes
    typealias ArrayLiteralElement = DispatchQueue.Attributes
    typealias Element = DispatchQueue.Attributes
    typealias RawValue = UInt64
  }
  enum GlobalQueuePriority {
    @available(macOS, deprecated: 10.10, message: "Use qos attributes instead")
    @available(iOS, deprecated: 8.0, message: "Use qos attributes instead")
    @available(tvOS, deprecated, message: "Use qos attributes instead")
    @available(watchOS, deprecated, message: "Use qos attributes instead")
    case high
    @available(macOS, deprecated: 10.10, message: "Use qos attributes instead")
    @available(iOS, deprecated: 8.0, message: "Use qos attributes instead")
    @available(tvOS, deprecated, message: "Use qos attributes instead")
    @available(watchOS, deprecated, message: "Use qos attributes instead")
    case `default`
    @available(macOS, deprecated: 10.10, message: "Use qos attributes instead")
    @available(iOS, deprecated: 8.0, message: "Use qos attributes instead")
    @available(tvOS, deprecated, message: "Use qos attributes instead")
    @available(watchOS, deprecated, message: "Use qos attributes instead")
    case low
    @available(macOS, deprecated: 10.10, message: "Use qos attributes instead")
    @available(iOS, deprecated: 8.0, message: "Use qos attributes instead")
    @available(tvOS, deprecated, message: "Use qos attributes instead")
    @available(watchOS, deprecated, message: "Use qos attributes instead")
    case background
    static func == (a: DispatchQueue.GlobalQueuePriority, b: DispatchQueue.GlobalQueuePriority) -> Bool
    func hash(into hasher: inout Hasher)
    var hashValue: Int { get }
  }
  enum AutoreleaseFrequency {
    case inherit
    @available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
    case workItem
    @available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
    case never
    static func == (a: DispatchQueue.AutoreleaseFrequency, b: DispatchQueue.AutoreleaseFrequency) -> Bool
    func hash(into hasher: inout Hasher)
    var hashValue: Int { get }
  }
  class func concurrentPerform(iterations: Int, execute work: (Int) -> Void)
  class var main: DispatchQueue { get }
  @available(macOS, deprecated: 10.10)
  @available(iOS, deprecated: 8.0)
  @available(tvOS, deprecated)
  @available(watchOS, deprecated)
  class func global(priority: DispatchQueue.GlobalQueuePriority) -> DispatchQueue
  @available(macOS 10.10, iOS 8.0, *)
  class func global(qos: DispatchQoS.QoSClass = .default) -> DispatchQueue
  class func getSpecific<T>(key: DispatchSpecificKey<T>) -> T?
  convenience init(label: String, qos: DispatchQoS = .unspecified, attributes: DispatchQueue.Attributes = [], autoreleaseFrequency: DispatchQueue.AutoreleaseFrequency = .inherit, target: DispatchQueue? = nil)
  var label: String { get }
  ///
  /// Submits a block for synchronous execution on this queue.
  ///
  /// Submits a work item to a dispatch queue like `async(execute:)`, however
  /// `sync(execute:)` will not return until the work item has finished.
  ///
  /// Work items submitted to a queue with `sync(execute:)` do not observe certain
  /// queue attributes of that queue when invoked (such as autorelease frequency
  /// and QoS class).
  ///
  /// Calls to `sync(execute:)` targeting the current queue will result
  /// in deadlock. Use of `sync(execute:)` is also subject to the same
  /// multi-party deadlock problems that may result from the use of a mutex.
  /// Use of `async(execute:)` is preferred.
  ///
  /// As an optimization, `sync(execute:)` invokes the work item on the thread which
  /// submitted it, except when the queue is the main queue or
  /// a queue targetting it.
  ///
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `async(execute:)`
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func sync(execute workItem: DispatchWorkItem)
  ///
  /// Submits a work item for asynchronous execution on a dispatch queue.
  ///
  /// `async(execute:)` is the fundamental mechanism for submitting
  /// work items to a dispatch queue.
  ///
  /// Calls to `async(execute:)` always return immediately after the work item has
  /// been submitted, and never wait for the work item to be invoked.
  ///
  /// The target queue determines whether the work item will be invoked serially or
  /// concurrently with respect to other work items submitted to that same queue.
  /// Serial queues are processed concurrently with respect to each other.
  ///
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `sync(execute:)`
  ///
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func async(execute workItem: DispatchWorkItem)
  @available(macOS 10.14, iOS 12.0, *)
  func asyncAndWait(execute workItem: DispatchWorkItem)
  ///
  /// Submits a work item to a dispatch queue and associates it with the given
  /// dispatch group. The dispatch group may be used to wait for the completion
  /// of the work items it references.
  ///
  /// - parameter group: the dispatch group to associate with the submitted block.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `sync(execute:)`
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func async(group: DispatchGroup, execute workItem: DispatchWorkItem)
  ///
  /// Submits a work item to a dispatch queue and optionally associates it with a
  /// dispatch group. The dispatch group may be used to wait for the completion
  /// of the work items it references.
  ///
  /// - parameter group: the dispatch group to associate with the submitted
  /// work item. If this is `nil`, the work item is not associated with a group.
  /// - parameter flags: flags that control the execution environment of the
  /// - parameter qos: the QoS at which the work item should be executed.
  ///	Defaults to `DispatchQoS.unspecified`.
  /// - parameter flags: flags that control the execution environment of the
  /// work item.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `sync(execute:)`
  /// - SeeAlso: `DispatchQoS`
  /// - SeeAlso: `DispatchWorkItemFlags`
  ///
  func async(group: DispatchGroup? = nil, qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], execute work: @escaping @convention(block) () -> Void)
  ///
  /// Submits a block for synchronous execution on this queue.
  ///
  /// Submits a work item to a dispatch queue like `sync(execute:)`, and returns
  /// the value, of type `T`, returned by that work item.
  ///
  /// - parameter execute: The work item to be invoked on the queue.
  /// - returns the value returned by the work item.
  /// - SeeAlso: `sync(execute:)`
  ///
  func sync<T>(execute work: () throws -> T) rethrows -> T
  ///
  /// Submits a block for synchronous execution on this queue.
  ///
  /// Submits a work item to a dispatch queue like `sync(execute:)`, and returns
  /// the value, of type `T`, returned by that work item.
  ///
  /// - parameter flags: flags that control the execution environment of the
  /// - parameter execute: The work item to be invoked on the queue.
  /// - returns the value returned by the work item.
  /// - SeeAlso: `sync(execute:)`
  /// - SeeAlso: `DispatchWorkItemFlags`
  ///
  func sync<T>(flags: DispatchWorkItemFlags, execute work: () throws -> T) rethrows -> T
  ///
  /// Submits a work item to a dispatch queue for asynchronous execution after
  /// a specified time.
  ///
  /// - parameter: deadline the time after which the work item should be executed,
  /// given as a `DispatchTime`.
  /// - parameter qos: the QoS at which the work item should be executed.
  ///	Defaults to `DispatchQoS.unspecified`.
  /// - parameter flags: flags that control the execution environment of the
  /// work item.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `async(execute:)`
  /// - SeeAlso: `asyncAfter(deadline:execute:)`
  /// - SeeAlso: `DispatchQoS`
  /// - SeeAlso: `DispatchWorkItemFlags`
  /// - SeeAlso: `DispatchTime`
  ///
  func asyncAfter(deadline: DispatchTime, qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], execute work: @escaping @convention(block) () -> Void)
  ///
  /// Submits a work item to a dispatch queue for asynchronous execution after
  /// a specified time.
  ///
  /// - parameter: deadline the time after which the work item should be executed,
  /// given as a `DispatchWallTime`.
  /// - parameter qos: the QoS at which the work item should be executed.
  ///	Defaults to `DispatchQoS.unspecified`.
  /// - parameter flags: flags that control the execution environment of the
  /// work item.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `async(execute:)`
  /// - SeeAlso: `asyncAfter(wallDeadline:execute:)`
  /// - SeeAlso: `DispatchQoS`
  /// - SeeAlso: `DispatchWorkItemFlags`
  /// - SeeAlso: `DispatchWallTime`
  ///
  func asyncAfter(wallDeadline: DispatchWallTime, qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], execute work: @escaping @convention(block) () -> Void)
  ///
  /// Submits a work item to a dispatch queue for asynchronous execution after
  /// a specified time.
  ///
  /// - parameter: deadline the time after which the work item should be executed,
  /// given as a `DispatchTime`.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `asyncAfter(deadline:qos:flags:execute:)`
  /// - SeeAlso: `DispatchTime`
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func asyncAfter(deadline: DispatchTime, execute: DispatchWorkItem)
  ///
  /// Submits a work item to a dispatch queue for asynchronous execution after
  /// a specified time.
  ///
  /// - parameter: deadline the time after which the work item should be executed,
  /// given as a `DispatchWallTime`.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `asyncAfter(wallDeadline:qos:flags:execute:)`
  /// - SeeAlso: `DispatchTime`
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func asyncAfter(wallDeadline: DispatchWallTime, execute: DispatchWorkItem)
  @available(macOS 10.10, iOS 8.0, *)
  var qos: DispatchQoS { get }
  func getSpecific<T>(key: DispatchSpecificKey<T>) -> T?
  func setSpecific<T>(key: DispatchSpecificKey<T>, value: T?)
}

@available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
extension DispatchQueue : Scheduler {
  /// The scheduler time type used by the dispatch queue.
  struct SchedulerTimeType : Strideable, Codable, Hashable {
    /// The dispatch time represented by this type.
    var dispatchTime: DispatchTime
    /// Creates a dispatch queue time type instance.
    ///
    /// - Parameter time: The dispatch time to represent.
    init(_ time: DispatchTime)
    init(from decoder: Decoder) throws
    func encode(to encoder: Encoder) throws
    /// Returns the distance to another dispatch queue time.
    ///
    /// - Parameter other: Another dispatch queue time.
    /// - Returns: The time interval between this time and the provided time.
    func distance(to other: DispatchQueue.SchedulerTimeType) -> DispatchQueue.SchedulerTimeType.Stride
    /// Returns a dispatch queue scheduler time calculated by advancing this instance’s time by the given interval.
    ///
    /// - Parameter n: A time interval to advance.
    /// - Returns: A dispatch queue time advanced by the given interval from this instance’s time.
    func advanced(by n: DispatchQueue.SchedulerTimeType.Stride) -> DispatchQueue.SchedulerTimeType
    func hash(into hasher: inout Hasher)
    @_alwaysEmitIntoClient static func < (lhs: DispatchQueue.SchedulerTimeType, rhs: DispatchQueue.SchedulerTimeType) -> Bool
    struct Stride : SchedulerTimeIntervalConvertible, Comparable, SignedNumeric, ExpressibleByFloatLiteral, Hashable, Codable {
      /// If created via floating point literal, the value is converted to nanoseconds via multiplication.
      typealias FloatLiteralType = Double
      /// Nanoseconds, same as DispatchTimeInterval.
      typealias IntegerLiteralType = Int
      typealias Magnitude = Int
      /// The value of this time interval in nanoseconds.
      var magnitude: Int
      /// A `DispatchTimeInterval` created with the value of this type in nanoseconds.
      var timeInterval: DispatchTimeInterval { get }
      /// Creates a dispatch queue time interval from the given dispatch time interval.
      ///
      /// - Parameter timeInterval: A dispatch time interval.
      init(_ timeInterval: DispatchTimeInterval)
      /// Creates a dispatch queue time interval from a floating-point seconds value.
      ///
      /// - Parameter value: The number of seconds, as a `Double`.
      init(floatLiteral value: Double)
      /// Creates a dispatch queue time interval from an integer seconds value.
      ///
      /// - Parameter value: The number of seconds, as an `Int`.
      init(integerLiteral value: Int)
      /// Creates a dispatch queue time interval from a binary integer type representing a number of seconds.
      ///
      /// If `source` cannot be exactly represented, the resulting time interval is `nil`.
      /// - Parameter source: A binary integer representing a time interval.
      init?<T>(exactly source: T) where T : BinaryInteger
      static func < (lhs: DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride) -> Bool
      static func * (lhs: DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride) -> DispatchQueue.SchedulerTimeType.Stride
      static func + (lhs: DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride) -> DispatchQueue.SchedulerTimeType.Stride
      static func - (lhs: DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride) -> DispatchQueue.SchedulerTimeType.Stride
      static func -= (lhs: inout DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride)
      static func *= (lhs: inout DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride)
      static func += (lhs: inout DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride)
      static func seconds(_ s: Double) -> DispatchQueue.SchedulerTimeType.Stride
      static func seconds(_ s: Int) -> DispatchQueue.SchedulerTimeType.Stride
      static func milliseconds(_ ms: Int) -> DispatchQueue.SchedulerTimeType.Stride
      static func microseconds(_ us: Int) -> DispatchQueue.SchedulerTimeType.Stride
      static func nanoseconds(_ ns: Int) -> DispatchQueue.SchedulerTimeType.Stride
      func hash(into hasher: inout Hasher)
      static func == (a: DispatchQueue.SchedulerTimeType.Stride, b: DispatchQueue.SchedulerTimeType.Stride) -> Bool
      func encode(to encoder: Encoder) throws
      var hashValue: Int { get }
      init(from decoder: Decoder) throws
    }
    var hashValue: Int { get }
  }
  /// Options that affect the operation of the dispatch queue scheduler.
  struct SchedulerOptions {
    /// The dispatch queue quality of service.
    var qos: DispatchQoS
    /// The dispatch queue work item flags.
    var flags: DispatchWorkItemFlags
    /// The dispatch group, if any, that should be used for performing actions.
    var group: DispatchGroup?
    init(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], group: DispatchGroup? = nil)
  }
  var minimumTolerance: DispatchQueue.SchedulerTimeType.Stride { get }
  var now: DispatchQueue.SchedulerTimeType { get }
  func schedule(options: DispatchQueue.SchedulerOptions?, _ action: @escaping () -> Void)
  func schedule(after date: DispatchQueue.SchedulerTimeType, tolerance: DispatchQueue.SchedulerTimeType.Stride, options: DispatchQueue.SchedulerOptions?, _ action: @escaping () -> Void)
  func schedule(after date: DispatchQueue.SchedulerTimeType, interval: DispatchQueue.SchedulerTimeType.Stride, tolerance: DispatchQueue.SchedulerTimeType.Stride, options: DispatchQueue.SchedulerOptions?, _ action: @escaping () -> Void) -> Cancellable
}

extension DispatchQueue.GlobalQueuePriority : Equatable {
}

extension DispatchQueue.GlobalQueuePriority : Hashable {
}

extension DispatchQueue.AutoreleaseFrequency : Equatable {
}

extension DispatchQueue.AutoreleaseFrequency : Hashable {
}
@available(swift, obsoleted: 3, renamed: "DispatchQueue")
typealias OS_dispatch_queue = DispatchQueue
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_queue_t = DispatchQueue
class OS_dispatch_queue_global : DispatchQueue {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}
typealias dispatch_queue_global_t = OS_dispatch_queue_global
class OS_dispatch_queue_serial : DispatchQueue {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}
typealias dispatch_queue_serial_t = OS_dispatch_queue_serial
class OS_dispatch_queue_main : OS_dispatch_queue_serial {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}
typealias dispatch_queue_main_t = OS_dispatch_queue_main
class OS_dispatch_queue_concurrent : DispatchQueue {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}
typealias dispatch_queue_concurrent_t = OS_dispatch_queue_concurrent
@available(iOS 4.0, *)
func __dispatch_async(_ queue: DispatchQueue, _ block: @escaping () -> Void)

/**
 * @function dispatch_async_f
 *
 * @abstract
 * Submits a function for asynchronous execution on a dispatch queue.
 *
 * @discussion
 * See dispatch_async() for details.
 *
 * @param queue
 * The target dispatch queue to which the function is submitted.
 * The system will hold a reference on the target queue until the function
 * has returned.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_async_f().
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_async_f(_ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchQueue.sync(self:execute:)")
func dispatch_sync(_ queue: DispatchQueue, _ block: () -> Void)
extension DispatchQueue {
  @available(iOS 4.0, *)
  func sync(execute block: () -> Void)

  /**
   * @function dispatch_queue_create_with_target
   *
   * @abstract
   * Creates a new dispatch queue with a specified target queue.
   *
   * @discussion
   * Dispatch queues created with the DISPATCH_QUEUE_SERIAL or a NULL attribute
   * invoke blocks serially in FIFO order.
   *
   * Dispatch queues created with the DISPATCH_QUEUE_CONCURRENT attribute may
   * invoke blocks concurrently (similarly to the global concurrent queues, but
   * potentially with more overhead), and support barrier blocks submitted with
   * the dispatch barrier API, which e.g. enables the implementation of efficient
   * reader-writer schemes.
   *
   * When a dispatch queue is no longer needed, it should be released with
   * dispatch_release(). Note that any pending blocks submitted asynchronously to
   * a queue will hold a reference to that queue. Therefore a queue will not be
   * deallocated until all pending blocks have finished.
   *
   * When using a dispatch queue attribute @a attr specifying a QoS class (derived
   * from the result of dispatch_queue_attr_make_with_qos_class()), passing the
   * result of dispatch_get_global_queue() in @a target will ignore the QoS class
   * of that global queue and will use the global queue with the QoS class
   * specified by attr instead.
   *
   * Queues created with dispatch_queue_create_with_target() cannot have their
   * target queue changed, unless created inactive (See
   * dispatch_queue_attr_make_initially_inactive()), in which case the target
   * queue can be changed until the newly created queue is activated with
   * dispatch_activate().
   *
   * @param label
   * A string label to attach to the queue.
   * This parameter is optional and may be NULL.
   *
   * @param attr
   * A predefined attribute such as DISPATCH_QUEUE_SERIAL,
   * DISPATCH_QUEUE_CONCURRENT, or the result of a call to
   * a dispatch_queue_attr_make_with_* function.
   *
   * @param target
   * The target queue for the newly created queue. The target queue is retained.
   * If this parameter is DISPATCH_TARGET_QUEUE_DEFAULT, sets the queue's target
   * queue to the default target queue for the given queue type.
   *
   * @result
   * The newly created dispatch queue.
   */
  @available(iOS 10.0, *)
  /*not inherited*/ init(__label label: UnsafePointer<CChar>?, attr: __OS_dispatch_queue_attr?, queue target: DispatchQueue?)

  /**
   * @function dispatch_queue_create
   *
   * @abstract
   * Creates a new dispatch queue to which blocks may be submitted.
   *
   * @discussion
   * Dispatch queues created with the DISPATCH_QUEUE_SERIAL or a NULL attribute
   * invoke blocks serially in FIFO order.
   *
   * Dispatch queues created with the DISPATCH_QUEUE_CONCURRENT attribute may
   * invoke blocks concurrently (similarly to the global concurrent queues, but
   * potentially with more overhead), and support barrier blocks submitted with
   * the dispatch barrier API, which e.g. enables the implementation of efficient
   * reader-writer schemes.
   *
   * When a dispatch queue is no longer needed, it should be released with
   * dispatch_release(). Note that any pending blocks submitted asynchronously to
   * a queue will hold a reference to that queue. Therefore a queue will not be
   * deallocated until all pending blocks have finished.
   *
   * Passing the result of the dispatch_queue_attr_make_with_qos_class() function
   * to the attr parameter of this function allows a quality of service class and
   * relative priority to be specified for the newly created queue.
   * The quality of service class so specified takes precedence over the quality
   * of service class of the newly created dispatch queue's target queue (if any)
   * as long that does not result in a lower QOS class and relative priority.
   *
   * When no quality of service class is specified, the target queue of a newly
   * created dispatch queue is the default priority global concurrent queue.
   *
   * @param label
   * A string label to attach to the queue.
   * This parameter is optional and may be NULL.
   *
   * @param attr
   * A predefined attribute such as DISPATCH_QUEUE_SERIAL,
   * DISPATCH_QUEUE_CONCURRENT, or the result of a call to
   * a dispatch_queue_attr_make_with_* function.
   *
   * @result
   * The newly created dispatch queue.
   */
  @available(iOS 4.0, *)
  /*not inherited*/ init(__label label: UnsafePointer<CChar>?, attr: __OS_dispatch_queue_attr?)
}

/**
 * @function dispatch_sync_f
 *
 * @abstract
 * Submits a function for synchronous execution on a dispatch queue.
 *
 * @discussion
 * See dispatch_sync() for details.
 *
 * @param queue
 * The target dispatch queue to which the function is submitted.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_sync_f().
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_sync_f(_ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)
@available(iOS 12.0, *)
func dispatch_async_and_wait(_ queue: DispatchQueue, _ block: () -> Void)

/**
 * @function dispatch_async_and_wait_f
 *
 * @abstract
 * Submits a function for synchronous execution on a dispatch queue.
 *
 * @discussion
 * See dispatch_async_and_wait() for details.
 *
 * @param queue
 * The target dispatch queue to which the function is submitted.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_async_and_wait_f().
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 12.0, *)
func dispatch_async_and_wait_f(_ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)
var DISPATCH_APPLY_AUTO_AVAILABLE: Int32 { get }
@available(iOS 4.0, *)
func __dispatch_apply(_ iterations: Int, _ queue: DispatchQueue?, _ block: (Int) -> Void)

/**
 * @function dispatch_apply_f
 *
 * @abstract
 * Submits a function to a dispatch queue for parallel invocation.
 *
 * @discussion
 * See dispatch_apply() for details.
 *
 * @param iterations
 * The number of iterations to perform.
 *
 * @param queue
 * The dispatch queue to which the function is submitted.
 * The preferred value to pass is DISPATCH_APPLY_AUTO to automatically use
 * a queue appropriate for the calling thread.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the specified queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_apply_f(). The second parameter passed to this function is the
 * current index of iteration.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_apply_f(_ iterations: Int, _ queue: DispatchQueue?, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?, Int) -> Void)

/**
 * @function dispatch_get_current_queue
 *
 * @abstract
 * Returns the queue on which the currently executing block is running.
 *
 * @discussion
 * Returns the queue on which the currently executing block is running.
 *
 * When dispatch_get_current_queue() is called outside of the context of a
 * submitted block, it will return the default concurrent queue.
 *
 * Recommended for debugging and logging purposes only:
 * The code must not make any assumptions about the queue returned, unless it
 * is one of the global queues or a queue the code has itself created.
 * The code must not assume that synchronous execution onto a queue is safe
 * from deadlock if that queue is not the one returned by
 * dispatch_get_current_queue().
 *
 * When dispatch_get_current_queue() is called on the main thread, it may
 * or may not return the same value as dispatch_get_main_queue(). Comparing
 * the two is not a valid way to test whether code is executing on the
 * main thread (see dispatch_assert_queue() and dispatch_assert_queue_not()).
 *
 * This function is deprecated and will be removed in a future release.
 *
 * @result
 * Returns the current queue.
 */
@available(iOS, unavailable, introduced: 4.0, deprecated: 6.0, message: "unsupported interface")
func dispatch_get_current_queue() -> DispatchQueue

/**
 * @function dispatch_get_main_queue
 *
 * @abstract
 * Returns the default queue that is bound to the main thread.
 *
 * @discussion
 * In order to invoke blocks submitted to the main queue, the application must
 * call dispatch_main(), NSApplicationMain(), or use a CFRunLoop on the main
 * thread.
 *
 * The main queue is meant to be used in application context to interact with
 * the main thread and the main runloop.
 *
 * Because the main queue doesn't behave entirely like a regular serial queue,
 * it may have unwanted side-effects when used in processes that are not UI apps
 * (daemons). For such processes, the main queue should be avoided.
 *
 * @see dispatch_queue_main_t
 *
 * @result
 * Returns the main queue. This queue is created automatically on behalf of
 * the main thread before main() is called.
 */
@available(*, unavailable, message: "Not available in Swift")
func dispatch_get_main_queue() -> dispatch_queue_main_t
var DISPATCH_QUEUE_PRIORITY_HIGH: Int32 { get }
var DISPATCH_QUEUE_PRIORITY_DEFAULT: Int32 { get }
var DISPATCH_QUEUE_PRIORITY_LOW: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_queue_priority_t = Int

/**
 * @function dispatch_get_global_queue
 *
 * @abstract
 * Returns a well-known global concurrent queue of a given quality of service
 * class.
 *
 * @discussion
 * See dispatch_queue_global_t.
 *
 * @param identifier
 * A quality of service class defined in qos_class_t or a priority defined in
 * dispatch_queue_priority_t.
 *
 * It is recommended to use quality of service class values to identify the
 * well-known global concurrent queues:
 *  - QOS_CLASS_USER_INTERACTIVE
 *  - QOS_CLASS_USER_INITIATED
 *  - QOS_CLASS_DEFAULT
 *  - QOS_CLASS_UTILITY
 *  - QOS_CLASS_BACKGROUND
 *
 * The global concurrent queues may still be identified by their priority,
 * which map to the following QOS classes:
 *  - DISPATCH_QUEUE_PRIORITY_HIGH:         QOS_CLASS_USER_INITIATED
 *  - DISPATCH_QUEUE_PRIORITY_DEFAULT:      QOS_CLASS_DEFAULT
 *  - DISPATCH_QUEUE_PRIORITY_LOW:          QOS_CLASS_UTILITY
 *  - DISPATCH_QUEUE_PRIORITY_BACKGROUND:   QOS_CLASS_BACKGROUND
 *
 * @param flags
 * Reserved for future use. Passing any value other than zero may result in
 * a NULL return value.
 *
 * @result
 * Returns the requested global queue or NULL if the requested global queue
 * does not exist.
 */
@available(iOS 4.0, *)
@_effects(readnone) func __dispatch_get_global_queue(_ identifier: Int, _ flags: UInt) -> dispatch_queue_global_t
class __OS_dispatch_queue_attr : DispatchObject {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_queue_attr_t = __OS_dispatch_queue_attr

/**
 * @function dispatch_queue_attr_make_initially_inactive
 *
 * @abstract
 * Returns an attribute value which may be provided to dispatch_queue_create()
 * or dispatch_queue_create_with_target(), in order to make the created queue
 * initially inactive.
 *
 * @discussion
 * Dispatch queues may be created in an inactive state. Queues in this state
 * have to be activated before any blocks associated with them will be invoked.
 *
 * A queue in inactive state cannot be deallocated, dispatch_activate() must be
 * called before the last reference to a queue created with this attribute is
 * released.
 *
 * The target queue of a queue in inactive state can be changed using
 * dispatch_set_target_queue(). Change of target queue is no longer permitted
 * once an initially inactive queue has been activated.
 *
 * @param attr
 * A queue attribute value to be combined with the initially inactive attribute.
 *
 * @return
 * Returns an attribute value which may be provided to dispatch_queue_create()
 * and dispatch_queue_create_with_target().
 * The new value combines the attributes specified by the 'attr' parameter with
 * the initially inactive attribute.
 */
@available(iOS 10.0, *)
@_effects(readonly) func __dispatch_queue_attr_make_initially_inactive(_ attr: __OS_dispatch_queue_attr?) -> __OS_dispatch_queue_attr
enum __dispatch_autorelease_frequency_t : UInt, @unchecked Sendable {
  init?(rawValue: UInt)
  var rawValue: UInt { get }
  typealias RawValue = UInt
  @available(iOS 10.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  case DISPATCH_AUTORELEASE_FREQUENCY_INHERIT
  @available(iOS 10.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  case DISPATCH_AUTORELEASE_FREQUENCY_WORK_ITEM
  @available(iOS 10.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  case DISPATCH_AUTORELEASE_FREQUENCY_NEVER
}

/**
 * @function dispatch_queue_attr_make_with_autorelease_frequency
 *
 * @abstract
 * Returns a dispatch queue attribute value with the autorelease frequency
 * set to the specified value.
 *
 * @discussion
 * When a queue uses the per-workitem autorelease frequency (either directly
 * or inherithed from its target queue), any block submitted asynchronously to
 * this queue (via dispatch_async(), dispatch_barrier_async(),
 * dispatch_group_notify(), etc...) is executed as if surrounded by a individual
 * Objective-C <code>@autoreleasepool</code> scope.
 *
 * Autorelease frequency has no effect on blocks that are submitted
 * synchronously to a queue (via dispatch_sync(), dispatch_barrier_sync()).
 *
 * The global concurrent queues have the DISPATCH_AUTORELEASE_FREQUENCY_NEVER
 * behavior. Manually created dispatch queues use
 * DISPATCH_AUTORELEASE_FREQUENCY_INHERIT by default.
 *
 * Queues created with this attribute cannot change target queues after having
 * been activated. See dispatch_set_target_queue() and dispatch_activate().
 *
 * @param attr
 * A queue attribute value to be combined with the specified autorelease
 * frequency or NULL.
 *
 * @param frequency
 * The requested autorelease frequency.
 *
 * @return
 * Returns an attribute value which may be provided to dispatch_queue_create()
 * or NULL if an invalid autorelease frequency was requested.
 * This new value combines the attributes specified by the 'attr' parameter and
 * the chosen autorelease frequency.
 */
@available(iOS 10.0, *)
@_effects(readonly) func __dispatch_queue_attr_make_with_autorelease_frequency(_ attr: __OS_dispatch_queue_attr?, _ frequency: __dispatch_autorelease_frequency_t) -> __OS_dispatch_queue_attr

/**
 * @function dispatch_queue_attr_make_with_qos_class
 *
 * @abstract
 * Returns an attribute value which may be provided to dispatch_queue_create()
 * or dispatch_queue_create_with_target(), in order to assign a QOS class and
 * relative priority to the queue.
 *
 * @discussion
 * When specified in this manner, the QOS class and relative priority take
 * precedence over those inherited from the dispatch queue's target queue (if
 * any) as long that does not result in a lower QOS class and relative priority.
 *
 * The global queue priorities map to the following QOS classes:
 *  - DISPATCH_QUEUE_PRIORITY_HIGH:         QOS_CLASS_USER_INITIATED
 *  - DISPATCH_QUEUE_PRIORITY_DEFAULT:      QOS_CLASS_DEFAULT
 *  - DISPATCH_QUEUE_PRIORITY_LOW:          QOS_CLASS_UTILITY
 *  - DISPATCH_QUEUE_PRIORITY_BACKGROUND:   QOS_CLASS_BACKGROUND
 *
 * Example:
 * <code>
 *	dispatch_queue_t queue;
 *	dispatch_queue_attr_t attr;
 *	attr = dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_SERIAL,
 *			QOS_CLASS_UTILITY, 0);
 *	queue = dispatch_queue_create("com.example.myqueue", attr);
 * </code>
 *
 * The QOS class and relative priority set this way on a queue have no effect on
 * blocks that are submitted synchronously to a queue (via dispatch_sync(),
 * dispatch_barrier_sync()).
 *
 * @param attr
 * A queue attribute value to be combined with the QOS class, or NULL.
 *
 * @param qos_class
 * A QOS class value:
 *  - QOS_CLASS_USER_INTERACTIVE
 *  - QOS_CLASS_USER_INITIATED
 *  - QOS_CLASS_DEFAULT
 *  - QOS_CLASS_UTILITY
 *  - QOS_CLASS_BACKGROUND
 * Passing any other value results in NULL being returned.
 *
 * @param relative_priority
 * A relative priority within the QOS class. This value is a negative
 * offset from the maximum supported scheduler priority for the given class.
 * Passing a value greater than zero or less than QOS_MIN_RELATIVE_PRIORITY
 * results in NULL being returned.
 *
 * @return
 * Returns an attribute value which may be provided to dispatch_queue_create()
 * and dispatch_queue_create_with_target(), or NULL if an invalid QOS class was
 * requested.
 * The new value combines the attributes specified by the 'attr' parameter and
 * the new QOS class and relative priority.
 */
@available(iOS 8.0, *)
@_effects(readonly) func __dispatch_queue_attr_make_with_qos_class(_ attr: __OS_dispatch_queue_attr?, _ qos_class: qos_class_t, _ relative_priority: Int32) -> __OS_dispatch_queue_attr

/**
 * @function dispatch_queue_create_with_target
 *
 * @abstract
 * Creates a new dispatch queue with a specified target queue.
 *
 * @discussion
 * Dispatch queues created with the DISPATCH_QUEUE_SERIAL or a NULL attribute
 * invoke blocks serially in FIFO order.
 *
 * Dispatch queues created with the DISPATCH_QUEUE_CONCURRENT attribute may
 * invoke blocks concurrently (similarly to the global concurrent queues, but
 * potentially with more overhead), and support barrier blocks submitted with
 * the dispatch barrier API, which e.g. enables the implementation of efficient
 * reader-writer schemes.
 *
 * When a dispatch queue is no longer needed, it should be released with
 * dispatch_release(). Note that any pending blocks submitted asynchronously to
 * a queue will hold a reference to that queue. Therefore a queue will not be
 * deallocated until all pending blocks have finished.
 *
 * When using a dispatch queue attribute @a attr specifying a QoS class (derived
 * from the result of dispatch_queue_attr_make_with_qos_class()), passing the
 * result of dispatch_get_global_queue() in @a target will ignore the QoS class
 * of that global queue and will use the global queue with the QoS class
 * specified by attr instead.
 *
 * Queues created with dispatch_queue_create_with_target() cannot have their
 * target queue changed, unless created inactive (See
 * dispatch_queue_attr_make_initially_inactive()), in which case the target
 * queue can be changed until the newly created queue is activated with
 * dispatch_activate().
 *
 * @param label
 * A string label to attach to the queue.
 * This parameter is optional and may be NULL.
 *
 * @param attr
 * A predefined attribute such as DISPATCH_QUEUE_SERIAL,
 * DISPATCH_QUEUE_CONCURRENT, or the result of a call to
 * a dispatch_queue_attr_make_with_* function.
 *
 * @param target
 * The target queue for the newly created queue. The target queue is retained.
 * If this parameter is DISPATCH_TARGET_QUEUE_DEFAULT, sets the queue's target
 * queue to the default target queue for the given queue type.
 *
 * @result
 * The newly created dispatch queue.
 */
@available(iOS 10.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchQueue.init(__label:attr:queue:)")
func __dispatch_queue_create_with_target(_ label: UnsafePointer<CChar>?, _ attr: __OS_dispatch_queue_attr?, _ target: DispatchQueue?) -> DispatchQueue

/**
 * @function dispatch_queue_create
 *
 * @abstract
 * Creates a new dispatch queue to which blocks may be submitted.
 *
 * @discussion
 * Dispatch queues created with the DISPATCH_QUEUE_SERIAL or a NULL attribute
 * invoke blocks serially in FIFO order.
 *
 * Dispatch queues created with the DISPATCH_QUEUE_CONCURRENT attribute may
 * invoke blocks concurrently (similarly to the global concurrent queues, but
 * potentially with more overhead), and support barrier blocks submitted with
 * the dispatch barrier API, which e.g. enables the implementation of efficient
 * reader-writer schemes.
 *
 * When a dispatch queue is no longer needed, it should be released with
 * dispatch_release(). Note that any pending blocks submitted asynchronously to
 * a queue will hold a reference to that queue. Therefore a queue will not be
 * deallocated until all pending blocks have finished.
 *
 * Passing the result of the dispatch_queue_attr_make_with_qos_class() function
 * to the attr parameter of this function allows a quality of service class and
 * relative priority to be specified for the newly created queue.
 * The quality of service class so specified takes precedence over the quality
 * of service class of the newly created dispatch queue's target queue (if any)
 * as long that does not result in a lower QOS class and relative priority.
 *
 * When no quality of service class is specified, the target queue of a newly
 * created dispatch queue is the default priority global concurrent queue.
 *
 * @param label
 * A string label to attach to the queue.
 * This parameter is optional and may be NULL.
 *
 * @param attr
 * A predefined attribute such as DISPATCH_QUEUE_SERIAL,
 * DISPATCH_QUEUE_CONCURRENT, or the result of a call to
 * a dispatch_queue_attr_make_with_* function.
 *
 * @result
 * The newly created dispatch queue.
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchQueue.init(__label:attr:)")
func __dispatch_queue_create(_ label: UnsafePointer<CChar>?, _ attr: __OS_dispatch_queue_attr?) -> DispatchQueue

/**
 * @function dispatch_queue_get_label
 *
 * @abstract
 * Returns the label of the given queue, as specified when the queue was
 * created, or the empty string if a NULL label was specified.
 *
 * Passing DISPATCH_CURRENT_QUEUE_LABEL will return the label of the current
 * queue.
 *
 * @param queue
 * The queue to query, or DISPATCH_CURRENT_QUEUE_LABEL.
 *
 * @result
 * The label of the queue.
 */
@available(iOS 4.0, *)
@_effects(readonly) func __dispatch_queue_get_label(_ queue: DispatchQueue?) -> UnsafePointer<CChar>

/**
 * @function dispatch_queue_get_qos_class
 *
 * @abstract
 * Returns the QOS class and relative priority of the given queue.
 *
 * @discussion
 * If the given queue was created with an attribute value returned from
 * dispatch_queue_attr_make_with_qos_class(), this function returns the QOS
 * class and relative priority specified at that time; for any other attribute
 * value it returns a QOS class of QOS_CLASS_UNSPECIFIED and a relative
 * priority of 0.
 *
 * If the given queue is one of the global queues, this function returns its
 * assigned QOS class value as documented under dispatch_get_global_queue() and
 * a relative priority of 0; in the case of the main queue it returns the QOS
 * value provided by qos_class_main() and a relative priority of 0.
 *
 * @param queue
 * The queue to query.
 *
 * @param relative_priority_ptr
 * A pointer to an int variable to be filled with the relative priority offset
 * within the QOS class, or NULL.
 *
 * @return
 * A QOS class value:
 *	- QOS_CLASS_USER_INTERACTIVE
 *	- QOS_CLASS_USER_INITIATED
 *	- QOS_CLASS_DEFAULT
 *	- QOS_CLASS_UTILITY
 *	- QOS_CLASS_BACKGROUND
 *	- QOS_CLASS_UNSPECIFIED
 */
@available(iOS 8.0, *)
func __dispatch_queue_get_qos_class(_ queue: DispatchQueue, _ relative_priority_ptr: UnsafeMutablePointer<Int32>?) -> qos_class_t

/**
 * @function dispatch_set_target_queue
 *
 * @abstract
 * Sets the target queue for the given object.
 *
 * @discussion
 * An object's target queue is responsible for processing the object.
 *
 * When no quality of service class and relative priority is specified for a
 * dispatch queue at the time of creation, a dispatch queue's quality of service
 * class is inherited from its target queue. The dispatch_get_global_queue()
 * function may be used to obtain a target queue of a specific quality of
 * service class, however the use of dispatch_queue_attr_make_with_qos_class()
 * is recommended instead.
 *
 * Blocks submitted to a serial queue whose target queue is another serial
 * queue will not be invoked concurrently with blocks submitted to the target
 * queue or to any other queue with that same target queue.
 *
 * The result of introducing a cycle into the hierarchy of target queues is
 * undefined.
 *
 * A dispatch source's target queue specifies where its event handler and
 * cancellation handler blocks will be submitted.
 *
 * A dispatch I/O channel's target queue specifies where where its I/O
 * operations are executed. If the channel's target queue's priority is set to
 * DISPATCH_QUEUE_PRIORITY_BACKGROUND, then the I/O operations performed by
 * dispatch_io_read() or dispatch_io_write() on that queue will be
 * throttled when there is I/O contention.
 *
 * For all other dispatch object types, the only function of the target queue
 * is to determine where an object's finalizer function is invoked.
 *
 * In general, changing the target queue of an object is an asynchronous
 * operation that doesn't take effect immediately, and doesn't affect blocks
 * already associated with the specified object.
 *
 * However, if an object is inactive at the time dispatch_set_target_queue() is
 * called, then the target queue change takes effect immediately, and will
 * affect blocks already associated with the specified object. After an
 * initially inactive object has been activated, calling
 * dispatch_set_target_queue() results in an assertion and the process being
 * terminated.
 *
 * If a dispatch queue is active and targeted by other dispatch objects,
 * changing its target queue results in undefined behavior.
 *
 * @param object
 * The object to modify.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param queue
 * The new target queue for the object. The queue is retained, and the
 * previous target queue, if any, is released.
 * If queue is DISPATCH_TARGET_QUEUE_DEFAULT, set the object's target queue
 * to the default target queue for the given object type.
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchObject.setTarget(self:queue:)")
func dispatch_set_target_queue(_ object: DispatchObject, _ queue: DispatchQueue?)

/**
 * @function dispatch_main
 *
 * @abstract
 * Execute blocks submitted to the main queue.
 *
 * @discussion
 * This function "parks" the main thread and waits for blocks to be submitted
 * to the main queue. This function never returns.
 *
 * Applications that call NSApplicationMain() or CFRunLoopRun() on the
 * main thread do not need to call dispatch_main().
 */
@available(iOS 4.0, *)
func dispatchMain() -> Never

/**
 * @function dispatch_main
 *
 * @abstract
 * Execute blocks submitted to the main queue.
 *
 * @discussion
 * This function "parks" the main thread and waits for blocks to be submitted
 * to the main queue. This function never returns.
 *
 * Applications that call NSApplicationMain() or CFRunLoopRun() on the
 * main thread do not need to call dispatch_main().
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "dispatchMain()")
func dispatch_main() -> Never
@available(iOS 4.0, *)
func __dispatch_after(_ when: dispatch_time_t, _ queue: DispatchQueue, _ block: @escaping () -> Void)

/**
 * @function dispatch_after_f
 *
 * @abstract
 * Schedule a function for execution on a given queue at a specified time.
 *
 * @discussion
 * See dispatch_after() for details.
 *
 * @param when
 * A temporal milestone returned by dispatch_time() or dispatch_walltime().
 *
 * @param queue
 * A queue to which the given function will be submitted at the specified time.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_after_f().
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_after_f(_ when: dispatch_time_t, _ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)
@available(iOS 4.3, *)
func __dispatch_barrier_async(_ queue: DispatchQueue, _ block: @escaping () -> Void)

/**
 * @function dispatch_barrier_async_f
 *
 * @abstract
 * Submits a barrier function for asynchronous execution on a dispatch queue.
 *
 * @discussion
 * Submits a function to a dispatch queue like dispatch_async_f(), but marks
 * that function as a barrier (relevant only on DISPATCH_QUEUE_CONCURRENT
 * queues).
 *
 * See dispatch_async_f() for details and "Dispatch Barrier API" for a
 * description of the barrier semantics.
 *
 * @param queue
 * The target dispatch queue to which the function is submitted.
 * The system will hold a reference on the target queue until the function
 * has returned.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_barrier_async_f().
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.3, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_barrier_async_f(_ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)
@available(iOS 4.3, *)
func __dispatch_barrier_sync(_ queue: DispatchQueue, _ block: () -> Void)

/**
 * @function dispatch_barrier_sync_f
 *
 * @abstract
 * Submits a barrier function for synchronous execution on a dispatch queue.
 *
 * @discussion
 * Submits a function to a dispatch queue like dispatch_sync_f(), but marks that
 * fuction as a barrier (relevant only on DISPATCH_QUEUE_CONCURRENT queues).
 *
 * See dispatch_sync_f() for details.
 *
 * @param queue
 * The target dispatch queue to which the function is submitted.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_barrier_sync_f().
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.3, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_barrier_sync_f(_ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)
@available(iOS 12.0, *)
func dispatch_barrier_async_and_wait(_ queue: DispatchQueue, _ block: () -> Void)

/**
 * @function dispatch_barrier_async_and_wait_f
 *
 * @abstract
 * Submits a function for synchronous execution on a dispatch queue.
 *
 * @discussion
 * Submits a function to a dispatch queue like dispatch_async_and_wait_f(), but
 * marks that function as a barrier (relevant only on DISPATCH_QUEUE_CONCURRENT
 * queues).
 *
 * See "Dispatch Barrier API" for a description of the barrier semantics.
 *
 * @param queue
 * The target dispatch queue to which the function is submitted.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_barrier_async_and_wait_f().
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 12.0, *)
func dispatch_barrier_async_and_wait_f(_ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)

/**
 * @function dispatch_queue_set_specific
 *
 * @abstract
 * Associates a subsystem-specific context with a dispatch queue, for a key
 * unique to the subsystem.
 *
 * @discussion
 * The specified destructor will be invoked with the context on the default
 * priority global concurrent queue when a new context is set for the same key,
 * or after all references to the queue have been released.
 *
 * @param queue
 * The dispatch queue to modify.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param key
 * The key to set the context for, typically a pointer to a static variable
 * specific to the subsystem. Keys are only compared as pointers and never
 * dereferenced. Passing a string constant directly is not recommended.
 * The NULL key is reserved and attempts to set a context for it are ignored.
 *
 * @param context
 * The new subsystem-specific context for the object. This may be NULL.
 *
 * @param destructor
 * The destructor function pointer. This may be NULL and is ignored if context
 * is NULL.
 */
@available(iOS 5.0, *)
func __dispatch_queue_set_specific(_ queue: DispatchQueue, _ key: UnsafeRawPointer, _ context: UnsafeMutableRawPointer?, _ destructor: (@convention(c) (UnsafeMutableRawPointer?) -> Void)?)

/**
 * @function dispatch_queue_get_specific
 *
 * @abstract
 * Returns the subsystem-specific context associated with a dispatch queue, for
 * a key unique to the subsystem.
 *
 * @discussion
 * Returns the context for the specified key if it has been set on the specified
 * queue.
 *
 * @param queue
 * The dispatch queue to query.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param key
 * The key to get the context for, typically a pointer to a static variable
 * specific to the subsystem. Keys are only compared as pointers and never
 * dereferenced. Passing a string constant directly is not recommended.
 *
 * @result
 * The context for the specified key or NULL if no context was found.
 */
@available(iOS 5.0, *)
@_effects(readonly) func __dispatch_queue_get_specific(_ queue: DispatchQueue, _ key: UnsafeRawPointer) -> UnsafeMutableRawPointer?

/**
 * @function dispatch_get_specific
 *
 * @abstract
 * Returns the current subsystem-specific context for a key unique to the
 * subsystem.
 *
 * @discussion
 * When called from a block executing on a queue, returns the context for the
 * specified key if it has been set on the queue, otherwise returns the result
 * of dispatch_get_specific() executed on the queue's target queue or NULL
 * if the current queue is a global concurrent queue.
 *
 * @param key
 * The key to get the context for, typically a pointer to a static variable
 * specific to the subsystem. Keys are only compared as pointers and never
 * dereferenced. Passing a string constant directly is not recommended.
 *
 * @result
 * The context for the specified key or NULL if no context was found.
 */
@available(iOS 5.0, *)
@_effects(readonly) func __dispatch_get_specific(_ key: UnsafeRawPointer) -> UnsafeMutableRawPointer?

/**
 * @function dispatch_assert_queue
 *
 * @abstract
 * Verifies that the current block is executing on a given dispatch queue.
 *
 * @discussion
 * Some code expects to be run on a specific dispatch queue. This function
 * verifies that that expectation is true.
 *
 * If the currently executing block was submitted to the specified queue or to
 * any queue targeting it (see dispatch_set_target_queue()), this function
 * returns.
 *
 * If the currently executing block was submitted with a synchronous API
 * (dispatch_sync(), dispatch_barrier_sync(), ...), the context of the
 * submitting block is also evaluated (recursively).
 * If a synchronously submitting block is found that was itself submitted to
 * the specified queue or to any queue targeting it, this function returns.
 *
 * Otherwise this function asserts: it logs an explanation to the system log and
 * terminates the application.
 *
 * Passing the result of dispatch_get_main_queue() to this function verifies
 * that the current block was submitted to the main queue, or to a queue
 * targeting it, or is running on the main thread (in any context).
 *
 * When dispatch_assert_queue() is called outside of the context of a
 * submitted block (for example from the context of a thread created manually
 * with pthread_create()) then this function will also assert and terminate
 * the application.
 *
 * The variant dispatch_assert_queue_debug() is compiled out when the
 * preprocessor macro NDEBUG is defined. (See also assert(3)).
 *
 * @param queue
 * The dispatch queue that the current block is expected to run on.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 10.0, *)
func __dispatch_assert_queue(_ queue: DispatchQueue)

/**
 * @function dispatch_assert_queue_barrier
 *
 * @abstract
 * Verifies that the current block is executing on a given dispatch queue,
 * and that the block acts as a barrier on that queue.
 *
 * @discussion
 * This behaves exactly like dispatch_assert_queue(), with the additional check
 * that the current block acts as a barrier on the specified queue, which is
 * always true if the specified queue is serial (see DISPATCH_BLOCK_BARRIER or
 * dispatch_barrier_async() for details).
 *
 * The variant dispatch_assert_queue_barrier_debug() is compiled out when the
 * preprocessor macro NDEBUG is defined. (See also assert()).
 *
 * @param queue
 * The dispatch queue that the current block is expected to run as a barrier on.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 10.0, *)
func __dispatch_assert_queue_barrier(_ queue: DispatchQueue)

/**
 * @function dispatch_assert_queue_not
 *
 * @abstract
 * Verifies that the current block is not executing on a given dispatch queue.
 *
 * @discussion
 * This function is the equivalent of dispatch_assert_queue() with the test for
 * equality inverted. That means that it will terminate the application when
 * dispatch_assert_queue() would return, and vice-versa. See discussion there.
 *
 * The variant dispatch_assert_queue_not_debug() is compiled out when the
 * preprocessor macro NDEBUG is defined. (See also assert(3)).
 *
 * @param queue
 * The dispatch queue that the current block is expected not to run on.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 10.0, *)
func __dispatch_assert_queue_not(_ queue: DispatchQueue)
struct __dispatch_block_flags_t : OptionSet, @unchecked Sendable {
  init(rawValue: UInt)
  let rawValue: UInt
  typealias RawValue = UInt
  typealias Element = __dispatch_block_flags_t
  typealias ArrayLiteralElement = __dispatch_block_flags_t
  @available(iOS 8.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  static var DISPATCH_BLOCK_BARRIER: __dispatch_block_flags_t { get }
  @available(iOS 8.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  static var DISPATCH_BLOCK_DETACHED: __dispatch_block_flags_t { get }
  @available(iOS 8.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  static var DISPATCH_BLOCK_ASSIGN_CURRENT: __dispatch_block_flags_t { get }
  @available(iOS 8.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  static var DISPATCH_BLOCK_NO_QOS_CLASS: __dispatch_block_flags_t { get }
  @available(iOS 8.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  static var DISPATCH_BLOCK_INHERIT_QOS_CLASS: __dispatch_block_flags_t { get }
  @available(iOS 8.0, *)
  @available(*, unavailable, message: "Not available in Swift")
  static var DISPATCH_BLOCK_ENFORCE_QOS_CLASS: __dispatch_block_flags_t { get }
}

/**
 * @function dispatch_block_create
 *
 * @abstract
 * Create a new dispatch block object on the heap from an existing block and
 * the given flags.
 *
 * @discussion
 * The provided block is Block_copy'ed to the heap and retained by the newly
 * created dispatch block object.
 *
 * The returned dispatch block object is intended to be submitted to a dispatch
 * queue with dispatch_async() and related functions, but may also be invoked
 * directly. Both operations can be performed an arbitrary number of times but
 * only the first completed execution of a dispatch block object can be waited
 * on with dispatch_block_wait() or observed with dispatch_block_notify().
 *
 * If the returned dispatch block object is submitted to a dispatch queue, the
 * submitted block instance will be associated with the QOS class current at the
 * time of submission, unless one of the following flags assigned a specific QOS
 * class (or no QOS class) at the time of block creation:
 *  - DISPATCH_BLOCK_ASSIGN_CURRENT
 *  - DISPATCH_BLOCK_NO_QOS_CLASS
 *  - DISPATCH_BLOCK_DETACHED
 * The QOS class the block object will be executed with also depends on the QOS
 * class assigned to the queue and which of the following flags was specified or
 * defaulted to:
 *  - DISPATCH_BLOCK_INHERIT_QOS_CLASS (default for asynchronous execution)
 *  - DISPATCH_BLOCK_ENFORCE_QOS_CLASS (default for synchronous execution)
 * See description of dispatch_block_flags_t for details.
 *
 * If the returned dispatch block object is submitted directly to a serial queue
 * and is configured to execute with a specific QOS class, the system will make
 * a best effort to apply the necessary QOS overrides to ensure that blocks
 * submitted earlier to the serial queue are executed at that same QOS class or
 * higher.
 *
 * @param flags
 * Configuration flags for the block object.
 * Passing a value that is not a bitwise OR of flags from dispatch_block_flags_t
 * results in NULL being returned.
 *
 * @param block
 * The block to create the dispatch block object from.
 *
 * @result
 * The newly created dispatch block object, or NULL.
 * When not building with Objective-C ARC, must be released with a -[release]
 * message or the Block_release() function.
 */
@available(iOS 8.0, *)
@available(*, unavailable, message: "Use DispatchWorkItem()")
func dispatch_block_create(_ flags: __dispatch_block_flags_t, _ block: @escaping () -> Void) -> () -> Void

/**
 * @function dispatch_block_create_with_qos_class
 *
 * @abstract
 * Create a new dispatch block object on the heap from an existing block and
 * the given flags, and assign it the specified QOS class and relative priority.
 *
 * @discussion
 * The provided block is Block_copy'ed to the heap and retained by the newly
 * created dispatch block object.
 *
 * The returned dispatch block object is intended to be submitted to a dispatch
 * queue with dispatch_async() and related functions, but may also be invoked
 * directly. Both operations can be performed an arbitrary number of times but
 * only the first completed execution of a dispatch block object can be waited
 * on with dispatch_block_wait() or observed with dispatch_block_notify().
 *
 * If invoked directly, the returned dispatch block object will be executed with
 * the assigned QOS class as long as that does not result in a lower QOS class
 * than what is current on the calling thread.
 *
 * If the returned dispatch block object is submitted to a dispatch queue, the
 * QOS class it will be executed with depends on the QOS class assigned to the
 * block, the QOS class assigned to the queue and which of the following flags
 * was specified or defaulted to:
 *  - DISPATCH_BLOCK_INHERIT_QOS_CLASS: default for asynchronous execution
 *  - DISPATCH_BLOCK_ENFORCE_QOS_CLASS: default for synchronous execution
 * See description of dispatch_block_flags_t for details.
 *
 * If the returned dispatch block object is submitted directly to a serial queue
 * and is configured to execute with a specific QOS class, the system will make
 * a best effort to apply the necessary QOS overrides to ensure that blocks
 * submitted earlier to the serial queue are executed at that same QOS class or
 * higher.
 *
 * @param flags
 * Configuration flags for the new block object.
 * Passing a value that is not a bitwise OR of flags from dispatch_block_flags_t
 * results in NULL being returned.
 *
 * @param qos_class
 * A QOS class value:
 *  - QOS_CLASS_USER_INTERACTIVE
 *  - QOS_CLASS_USER_INITIATED
 *  - QOS_CLASS_DEFAULT
 *  - QOS_CLASS_UTILITY
 *  - QOS_CLASS_BACKGROUND
 *  - QOS_CLASS_UNSPECIFIED
 * Passing QOS_CLASS_UNSPECIFIED is equivalent to specifying the
 * DISPATCH_BLOCK_NO_QOS_CLASS flag. Passing any other value results in NULL
 * being returned.
 *
 * @param relative_priority
 * A relative priority within the QOS class. This value is a negative
 * offset from the maximum supported scheduler priority for the given class.
 * Passing a value greater than zero or less than QOS_MIN_RELATIVE_PRIORITY
 * results in NULL being returned.
 *
 * @param block
 * The block to create the dispatch block object from.
 *
 * @result
 * The newly created dispatch block object, or NULL.
 * When not building with Objective-C ARC, must be released with a -[release]
 * message or the Block_release() function.
 */
@available(iOS 8.0, *)
@available(*, unavailable, message: "Use DispatchWorkItem()")
func dispatch_block_create_with_qos_class(_ flags: __dispatch_block_flags_t, _ qos_class: qos_class_t, _ relative_priority: Int32, _ block: @escaping () -> Void) -> () -> Void

/**
 * @function dispatch_block_perform
 *
 * @abstract
 * Create, synchronously execute and release a dispatch block object from the
 * specified block and flags.
 *
 * @discussion
 * Behaves identically to the sequence
 * <code>
 * dispatch_block_t b = dispatch_block_create(flags, block);
 * b();
 * Block_release(b);
 * </code>
 * but may be implemented more efficiently internally by not requiring a copy
 * to the heap of the specified block or the allocation of a new block object.
 *
 * @param flags
 * Configuration flags for the temporary block object.
 * The result of passing a value that is not a bitwise OR of flags from
 * dispatch_block_flags_t is undefined.
 *
 * @param block
 * The block to create the temporary block object from.
 */
@available(iOS 8.0, *)
@available(*, unavailable, message: "Use DispatchWorkItem.perform()")
func dispatch_block_perform(_ flags: __dispatch_block_flags_t, _ block: () -> Void)

/**
 * @function dispatch_block_wait
 *
 * @abstract
 * Wait synchronously until execution of the specified dispatch block object has
 * completed or until the specified timeout has elapsed.
 *
 * @discussion
 * This function will return immediately if execution of the block object has
 * already completed.
 *
 * It is not possible to wait for multiple executions of the same block object
 * with this interface; use dispatch_group_wait() for that purpose. A single
 * dispatch block object may either be waited on once and executed once,
 * or it may be executed any number of times. The behavior of any other
 * combination is undefined. Submission to a dispatch queue counts as an
 * execution, even if cancellation (dispatch_block_cancel) means the block's
 * code never runs.
 *
 * The result of calling this function from multiple threads simultaneously
 * with the same dispatch block object is undefined, but note that doing so
 * would violate the rules described in the previous paragraph.
 *
 * If this function returns indicating that the specified timeout has elapsed,
 * then that invocation does not count as the one allowed wait.
 *
 * If at the time this function is called, the specified dispatch block object
 * has been submitted directly to a serial queue, the system will make a best
 * effort to apply the necessary QOS overrides to ensure that the block and any
 * blocks submitted earlier to that serial queue are executed at the QOS class
 * (or higher) of the thread calling dispatch_block_wait().
 *
 * @param block
 * The dispatch block object to wait on.
 * The result of passing NULL or a block object not returned by one of the
 * dispatch_block_create* functions is undefined.
 *
 * @param timeout
 * When to timeout (see dispatch_time). As a convenience, there are the
 * DISPATCH_TIME_NOW and DISPATCH_TIME_FOREVER constants.
 *
 * @result
 * Returns zero on success (the dispatch block object completed within the
 * specified timeout) or non-zero on error (i.e. timed out).
 */
@available(iOS 8.0, *)
@available(*, unavailable, message: "Use DispatchWorkItem.wait(timeout:)")
func dispatch_block_wait(_ block: @escaping () -> Void, _ timeout: dispatch_time_t) -> Int

/**
 * @function dispatch_block_notify
 *
 * @abstract
 * Schedule a notification block to be submitted to a queue when the execution
 * of a specified dispatch block object has completed.
 *
 * @discussion
 * This function will submit the notification block immediately if execution of
 * the observed block object has already completed.
 *
 * It is not possible to be notified of multiple executions of the same block
 * object with this interface, use dispatch_group_notify() for that purpose.
 *
 * A single dispatch block object may either be observed one or more times
 * and executed once, or it may be executed any number of times. The behavior
 * of any other combination is undefined. Submission to a dispatch queue
 * counts as an execution, even if cancellation (dispatch_block_cancel) means
 * the block's code never runs.
 *
 * If multiple notification blocks are scheduled for a single block object,
 * there is no defined order in which the notification blocks will be submitted
 * to their associated queues.
 *
 * @param block
 * The dispatch block object to observe.
 * The result of passing NULL or a block object not returned by one of the
 * dispatch_block_create* functions is undefined.
 *
 * @param queue
 * The queue to which the supplied notification block will be submitted when
 * the observed block completes.
 *
 * @param notification_block
 * The notification block to submit when the observed block object completes.
 */
@available(iOS 8.0, *)
@available(*, unavailable, message: "Use DispatchWorkItem.notify(queue:execute:)")
func dispatch_block_notify(_ block: @escaping () -> Void, _ queue: DispatchQueue, _ notification_block: @escaping () -> Void)

/**
 * @function dispatch_block_cancel
 *
 * @abstract
 * Asynchronously cancel the specified dispatch block object.
 *
 * @discussion
 * Cancellation causes any future execution of the dispatch block object to
 * return immediately, but does not affect any execution of the block object
 * that is already in progress.
 *
 * Release of any resources associated with the block object will be delayed
 * until execution of the block object is next attempted (or any execution
 * already in progress completes).
 *
 * NOTE: care needs to be taken to ensure that a block object that may be
 *       canceled does not capture any resources that require execution of the
 *       block body in order to be released (e.g. memory allocated with
 *       malloc(3) that the block body calls free(3) on). Such resources will
 *       be leaked if the block body is never executed due to cancellation.
 *
 * @param block
 * The dispatch block object to cancel.
 * The result of passing NULL or a block object not returned by one of the
 * dispatch_block_create* functions is undefined.
 */
@available(iOS 8.0, *)
@available(*, unavailable, message: "Use DispatchWorkItem.cancel()")
func dispatch_block_cancel(_ block: @escaping () -> Void)

/**
 * @function dispatch_block_testcancel
 *
 * @abstract
 * Tests whether the given dispatch block object has been canceled.
 *
 * @param block
 * The dispatch block object to test.
 * The result of passing NULL or a block object not returned by one of the
 * dispatch_block_create* functions is undefined.
 *
 * @result
 * Non-zero if canceled and zero if not canceled.
 */
@available(iOS 8.0, *)
@available(*, unavailable, message: "Use DispatchWorkItem.isCancelled")
func dispatch_block_testcancel(_ block: @escaping () -> Void) -> Int
class DispatchSource : DispatchObject {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}

extension DispatchSource {
  struct MachSendEvent : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let dead: DispatchSource.MachSendEvent
    typealias ArrayLiteralElement = DispatchSource.MachSendEvent
    typealias Element = DispatchSource.MachSendEvent
    typealias RawValue = UInt
  }
  struct MemoryPressureEvent : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let normal: DispatchSource.MemoryPressureEvent
    static let warning: DispatchSource.MemoryPressureEvent
    static let critical: DispatchSource.MemoryPressureEvent
    static let all: DispatchSource.MemoryPressureEvent
    typealias ArrayLiteralElement = DispatchSource.MemoryPressureEvent
    typealias Element = DispatchSource.MemoryPressureEvent
    typealias RawValue = UInt
  }
  struct ProcessEvent : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let exit: DispatchSource.ProcessEvent
    static let fork: DispatchSource.ProcessEvent
    static let exec: DispatchSource.ProcessEvent
    static let signal: DispatchSource.ProcessEvent
    static let all: DispatchSource.ProcessEvent
    typealias ArrayLiteralElement = DispatchSource.ProcessEvent
    typealias Element = DispatchSource.ProcessEvent
    typealias RawValue = UInt
  }
  struct TimerFlags : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let strict: DispatchSource.TimerFlags
    typealias ArrayLiteralElement = DispatchSource.TimerFlags
    typealias Element = DispatchSource.TimerFlags
    typealias RawValue = UInt
  }
  struct FileSystemEvent : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let delete: DispatchSource.FileSystemEvent
    static let write: DispatchSource.FileSystemEvent
    static let extend: DispatchSource.FileSystemEvent
    static let attrib: DispatchSource.FileSystemEvent
    static let link: DispatchSource.FileSystemEvent
    static let rename: DispatchSource.FileSystemEvent
    static let revoke: DispatchSource.FileSystemEvent
    static let funlock: DispatchSource.FileSystemEvent
    static let all: DispatchSource.FileSystemEvent
    typealias ArrayLiteralElement = DispatchSource.FileSystemEvent
    typealias Element = DispatchSource.FileSystemEvent
    typealias RawValue = UInt
  }
  class func makeMachSendSource(port: mach_port_t, eventMask: DispatchSource.MachSendEvent, queue: DispatchQueue? = nil) -> DispatchSourceMachSend
  class func makeMachReceiveSource(port: mach_port_t, queue: DispatchQueue? = nil) -> DispatchSourceMachReceive
  class func makeMemoryPressureSource(eventMask: DispatchSource.MemoryPressureEvent, queue: DispatchQueue? = nil) -> DispatchSourceMemoryPressure
  class func makeProcessSource(identifier: pid_t, eventMask: DispatchSource.ProcessEvent, queue: DispatchQueue? = nil) -> DispatchSourceProcess
  class func makeReadSource(fileDescriptor: Int32, queue: DispatchQueue? = nil) -> DispatchSourceRead
  class func makeSignalSource(signal: Int32, queue: DispatchQueue? = nil) -> DispatchSourceSignal
  class func makeTimerSource(flags: DispatchSource.TimerFlags = [], queue: DispatchQueue? = nil) -> DispatchSourceTimer
  class func makeUserDataAddSource(queue: DispatchQueue? = nil) -> DispatchSourceUserDataAdd
  class func makeUserDataOrSource(queue: DispatchQueue? = nil) -> DispatchSourceUserDataOr
  class func makeUserDataReplaceSource(queue: DispatchQueue? = nil) -> DispatchSourceUserDataReplace
  class func makeFileSystemObjectSource(fileDescriptor: Int32, eventMask: DispatchSource.FileSystemEvent, queue: DispatchQueue? = nil) -> DispatchSourceFileSystemObject
  class func makeWriteSource(fileDescriptor: Int32, queue: DispatchQueue? = nil) -> DispatchSourceWrite
}
@available(swift, obsoleted: 3, renamed: "DispatchSource")
typealias OS_dispatch_source = DispatchSource
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_source_t = DispatchSource
protocol DispatchSourceProtocol : NSObjectProtocol {
}

extension DispatchSourceProtocol {
  typealias DispatchSourceHandler = @convention(block) () -> Void
  func setEventHandler(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], handler: Self.DispatchSourceHandler?)
  @available(macOS 10.10, iOS 8.0, *)
  func setEventHandler(handler: DispatchWorkItem)
  func setCancelHandler(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], handler: Self.DispatchSourceHandler?)
  @available(macOS 10.10, iOS 8.0, *)
  func setCancelHandler(handler: DispatchWorkItem)
  func setRegistrationHandler(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], handler: Self.DispatchSourceHandler?)
  @available(macOS 10.10, iOS 8.0, *)
  func setRegistrationHandler(handler: DispatchWorkItem)
  @available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
  func activate()
  func cancel()
  func resume()
  func suspend()
  var handle: UInt { get }
  var mask: UInt { get }
  var data: UInt { get }
  var isCancelled: Bool { get }
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceProtocol")
typealias OS_dispatch_sourceProtocol = DispatchSourceProtocol
extension DispatchSource : DispatchSourceProtocol {
}

/**
 * @typedef dispatch_source_type_t
 *
 * @abstract
 * Constants of this type represent the class of low-level system object that
 * is being monitored by the dispatch source. Constants of this type are
 * passed as a parameter to dispatch_source_create() and determine how the
 * handle argument is interpreted (i.e. as a file descriptor, mach port,
 * signal number, process identifier, etc.), and how the mask argument is
 * interpreted.
 */
typealias __dispatch_source_type_t = OpaquePointer
protocol DispatchSourceUserDataAdd : DispatchSourceProtocol {
}

extension DispatchSourceUserDataAdd {
  /// @function add
  ///
  /// @abstract
  /// Merges data into a dispatch source of type DISPATCH_SOURCE_TYPE_DATA_ADD
  /// and submits its event handler block to its target queue.
  ///
  /// @param data
  /// The value to add to the current pending data. A value of zero has no effect
  /// and will not result in the submission of the event handler block.
  func add(data: UInt)
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceUserDataAdd")
typealias OS_dispatch_source_data_add = DispatchSourceUserDataAdd
extension DispatchSource : DispatchSourceUserDataAdd {
}
protocol DispatchSourceUserDataOr : DispatchSourceProtocol {
}

extension DispatchSourceUserDataOr {
  /// @function or
  ///
  /// @abstract
  /// Merges data into a dispatch source of type DISPATCH_SOURCE_TYPE_DATA_OR and
  /// submits its event handler block to its target queue.
  ///
  /// @param data
  /// The value to OR into the current pending data. A value of zero has no effect
  /// and will not result in the submission of the event handler block.
  func or(data: UInt)
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceUserDataOr")
typealias OS_dispatch_source_data_or = DispatchSourceUserDataOr
extension DispatchSource : DispatchSourceUserDataOr {
}
protocol DispatchSourceUserDataReplace : DispatchSourceProtocol {
}

extension DispatchSourceUserDataReplace {
  /// @function replace
  ///
  /// @abstract
  /// Merges data into a dispatch source of type DISPATCH_SOURCE_TYPE_DATA_REPLACE
  /// and submits its event handler block to its target queue.
  ///
  /// @param data
  /// The value that will replace the current pending data. A value of zero will be stored
  /// but will not result in the submission of the event handler block.
  func replace(data: UInt)
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceUserDataReplace")
typealias OS_dispatch_source_data_replace = DispatchSourceUserDataReplace
extension DispatchSource : DispatchSourceUserDataReplace {
}
protocol DispatchSourceMachSend : DispatchSourceProtocol {
}

extension DispatchSourceMachSend {
  var handle: mach_port_t { get }
  var data: DispatchSource.MachSendEvent { get }
  var mask: DispatchSource.MachSendEvent { get }
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceMachSend")
typealias OS_dispatch_source_mach_send = DispatchSourceMachSend
extension DispatchSource : DispatchSourceMachSend {
}
protocol DispatchSourceMachReceive : DispatchSourceProtocol {
}

extension DispatchSourceMachReceive {
  var handle: mach_port_t { get }
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceMachReceive")
typealias OS_dispatch_source_mach_recv = DispatchSourceMachReceive
extension DispatchSource : DispatchSourceMachReceive {
}
protocol DispatchSourceMemoryPressure : DispatchSourceProtocol {
}

extension DispatchSourceMemoryPressure {
  var data: DispatchSource.MemoryPressureEvent { get }
  var mask: DispatchSource.MemoryPressureEvent { get }
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceMemoryPressure")
typealias OS_dispatch_source_memorypressure = DispatchSourceMemoryPressure
extension DispatchSource : DispatchSourceMemoryPressure {
}
protocol DispatchSourceProcess : DispatchSourceProtocol {
}

extension DispatchSourceProcess {
  var handle: pid_t { get }
  var data: DispatchSource.ProcessEvent { get }
  var mask: DispatchSource.ProcessEvent { get }
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceProcess")
typealias OS_dispatch_source_proc = DispatchSourceProcess
extension DispatchSource : DispatchSourceProcess {
}
protocol DispatchSourceRead : DispatchSourceProtocol {
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceRead")
typealias OS_dispatch_source_read = DispatchSourceRead
extension DispatchSource : DispatchSourceRead {
}
protocol DispatchSourceSignal : DispatchSourceProtocol {
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceSignal")
typealias OS_dispatch_source_signal = DispatchSourceSignal
extension DispatchSource : DispatchSourceSignal {
}
protocol DispatchSourceTimer : DispatchSourceProtocol {
}

extension DispatchSourceTimer {
  ///
  /// Sets the deadline and leeway for a timer event that fires once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared and the next timer event will occur at `deadline`.
  ///
  /// Delivery of the timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  /// - note: Delivery of the timer event does not cancel the timer source.
  ///
  /// - parameter deadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(deadline:repeating:leeway:)")
  func scheduleOneshot(deadline: DispatchTime, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline and leeway for a timer event that fires once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared and the next timer event will occur at `wallDeadline`.
  ///
  /// Delivery of the timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  /// - note: Delivery of the timer event does not cancel the timer source.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(wallDeadline:repeating:leeway:)")
  func scheduleOneshot(wallDeadline: DispatchWallTime, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `deadline` and every `interval` units of
  /// time thereafter until the timer source is canceled.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `deadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `deadline + N * interval`, the upper
  /// limit is the smaller of `leeway` and `interval/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter deadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter interval: the interval for the timer.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(deadline:repeating:leeway:)")
  func scheduleRepeating(deadline: DispatchTime, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `deadline` and every `interval` seconds
  /// thereafter until the timer source is canceled.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption and
  /// system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `deadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `deadline + N * interval`, the upper
  /// limit is the smaller of `leeway` and `interval/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter deadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter interval: the interval for the timer in seconds.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(deadline:repeating:leeway:)")
  func scheduleRepeating(deadline: DispatchTime, interval: Double, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `wallDeadline` and every `interval` units of
  /// time thereafter until the timer source is canceled.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption and
  /// system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `wallDeadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `wallDeadline + N * interval`, the upper
  /// limit is the smaller of `leeway` and `interval/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter interval: the interval for the timer.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(wallDeadline:repeating:leeway:)")
  func scheduleRepeating(wallDeadline: DispatchWallTime, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `wallDeadline` and every `interval` seconds
  /// thereafter until the timer source is canceled.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption and
  /// system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `wallDeadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `wallDeadline + N * interval`, the upper
  /// limit is the smaller of `leeway` and `interval/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter interval: the interval for the timer in seconds.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(wallDeadline:repeating:leeway:)")
  func scheduleRepeating(wallDeadline: DispatchWallTime, interval: Double, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, repeat interval and leeway for a timer event.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `deadline` and every `repeating` units of
  /// time thereafter until the timer source is canceled. If the value of `repeating` is `.never`,
  /// or is defaulted, the timer fires only once.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `deadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `deadline + N * repeating`, the upper
  /// limit is the smaller of `leeway` and `repeating/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter deadline: the time at which the first timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter repeating: the repeat interval for the timer, or `.never` if the timer should fire
  ///		only once.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift 4)
  func schedule(deadline: DispatchTime, repeating interval: DispatchTimeInterval = .never, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, repeat interval and leeway for a timer event.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `deadline` and every `repeating` seconds
  /// thereafter until the timer source is canceled. If the value of `repeating` is `.infinity`,
  /// the timer fires only once.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `deadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `deadline + N * repeating`, the upper
  /// limit is the smaller of `leeway` and `repeating/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter deadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter repeating: the repeat interval for the timer in seconds, or `.infinity` if the timer
  ///		should fire only once.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift 4)
  func schedule(deadline: DispatchTime, repeating interval: Double, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, repeat interval and leeway for a timer event.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `wallDeadline` and every `repeating` units of
  /// time thereafter until the timer source is canceled. If the value of `repeating` is `.never`,
  /// or is defaulted, the timer fires only once.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption and
  /// system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `wallDeadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `wallDeadline + N * repeating`, the upper
  /// limit is the smaller of `leeway` and `repeating/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter repeating: the repeat interval for the timer, or `.never` if the timer should fire
  ///		only once.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift 4)
  func schedule(wallDeadline: DispatchWallTime, repeating interval: DispatchTimeInterval = .never, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, repeat interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `wallDeadline` and every `repeating` seconds
  /// thereafter until the timer source is canceled. If the value of `repeating` is `.infinity`,
  /// the timer fires only once.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `wallDeadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `wallDeadline + N * repeating`, the upper
  /// limit is the smaller of `leeway` and `repeating/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter repeating: the repeat interval for the timer in secondss, or `.infinity` if the timer
  /// 	should fire only once.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift 4)
  func schedule(wallDeadline: DispatchWallTime, repeating interval: Double, leeway: DispatchTimeInterval = .nanoseconds(0))
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceTimer")
typealias OS_dispatch_source_timer = DispatchSourceTimer
extension DispatchSource : DispatchSourceTimer {
}
protocol DispatchSourceFileSystemObject : DispatchSourceProtocol {
}

extension DispatchSourceFileSystemObject {
  var handle: Int32 { get }
  var data: DispatchSource.FileSystemEvent { get }
  var mask: DispatchSource.FileSystemEvent { get }
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceFileSystemObject")
typealias OS_dispatch_source_vnode = DispatchSourceFileSystemObject
extension DispatchSource : DispatchSourceFileSystemObject {
}
protocol DispatchSourceWrite : DispatchSourceProtocol {
}
@available(swift, obsoleted: 3, renamed: "DispatchSourceWrite")
typealias OS_dispatch_source_write = DispatchSourceWrite
extension DispatchSource : DispatchSourceWrite {
}
var DISPATCH_MACH_SEND_DEAD: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_source_mach_send_flags_t = UInt

/**
 * @typedef dispatch_source_mach_recv_flags_t
 * Type of dispatch_source_mach_recv flags
 */
typealias dispatch_source_mach_recv_flags_t = UInt
var DISPATCH_MEMORYPRESSURE_NORMAL: Int32 { get }
var DISPATCH_MEMORYPRESSURE_WARN: Int32 { get }
var DISPATCH_MEMORYPRESSURE_CRITICAL: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_source_memorypressure_flags_t = UInt
var DISPATCH_PROC_EXIT: UInt32 { get }
var DISPATCH_PROC_FORK: Int32 { get }
var DISPATCH_PROC_EXEC: Int32 { get }
var DISPATCH_PROC_SIGNAL: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_source_proc_flags_t = UInt
var DISPATCH_VNODE_DELETE: Int32 { get }
var DISPATCH_VNODE_WRITE: Int32 { get }
var DISPATCH_VNODE_EXTEND: Int32 { get }
var DISPATCH_VNODE_ATTRIB: Int32 { get }
var DISPATCH_VNODE_LINK: Int32 { get }
var DISPATCH_VNODE_RENAME: Int32 { get }
var DISPATCH_VNODE_REVOKE: Int32 { get }
var DISPATCH_VNODE_FUNLOCK: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_source_vnode_flags_t = UInt
var DISPATCH_TIMER_STRICT: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_source_timer_flags_t = UInt

/**
 * @function dispatch_source_create
 *
 * @abstract
 * Creates a new dispatch source to monitor low-level system objects and auto-
 * matically submit a handler block to a dispatch queue in response to events.
 *
 * @discussion
 * Dispatch sources are not reentrant. Any events received while the dispatch
 * source is suspended or while the event handler block is currently executing
 * will be coalesced and delivered after the dispatch source is resumed or the
 * event handler block has returned.
 *
 * Dispatch sources are created in an inactive state. After creating the
 * source and setting any desired attributes (i.e. the handler, context, etc.),
 * a call must be made to dispatch_activate() in order to begin event delivery.
 *
 * Calling dispatch_set_target_queue() on a source once it has been activated
 * is not allowed (see dispatch_activate() and dispatch_set_target_queue()).
 *
 * For backward compatibility reasons, dispatch_resume() on an inactive,
 * and not otherwise suspended source has the same effect as calling
 * dispatch_activate(). For new code, using dispatch_activate() is preferred.
 *
 * @param type
 * Declares the type of the dispatch source. Must be one of the defined
 * dispatch_source_type_t constants.
 *
 * @param handle
 * The underlying system handle to monitor. The interpretation of this argument
 * is determined by the constant provided in the type parameter.
 *
 * @param mask
 * A mask of flags specifying which events are desired. The interpretation of
 * this argument is determined by the constant provided in the type parameter.
 *
 * @param queue
 * The dispatch queue to which the event handler block will be submitted.
 * If queue is DISPATCH_TARGET_QUEUE_DEFAULT, the source will submit the event
 * handler block to the default priority global queue.
 *
 * @result
 * The newly created dispatch source. Or NULL if invalid arguments are passed.
 */
@available(iOS 4.0, *)
func __dispatch_source_create(_ type: __dispatch_source_type_t, _ handle: UInt, _ mask: UInt, _ queue: DispatchQueue?) -> DispatchSource
@available(iOS 4.0, *)
func __dispatch_source_set_event_handler(_ source: DispatchSource, _ handler: (() -> Void)?)

/**
 * @function dispatch_source_set_event_handler_f
 *
 * @abstract
 * Sets the event handler function for the given dispatch source.
 *
 * @param source
 * The dispatch source to modify.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param handler
 * The event handler function to submit to the source's target queue.
 * The context parameter passed to the event handler function is the context of
 * the dispatch source current at the time the event handler was set.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_source_set_event_handler_f(_ source: DispatchSource, _ handler: (@convention(c) (UnsafeMutableRawPointer?) -> Void)?)
@available(iOS 4.0, *)
func __dispatch_source_set_cancel_handler(_ source: DispatchSource, _ handler: (() -> Void)?)

/**
 * @function dispatch_source_set_cancel_handler_f
 *
 * @abstract
 * Sets the cancellation handler function for the given dispatch source.
 *
 * @discussion
 * See dispatch_source_set_cancel_handler() for more details.
 *
 * @param source
 * The dispatch source to modify.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param handler
 * The cancellation handler function to submit to the source's target queue.
 * The context parameter passed to the event handler function is the current
 * context of the dispatch source at the time the handler call is made.
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_source_set_cancel_handler_f(_ source: DispatchSource, _ handler: (@convention(c) (UnsafeMutableRawPointer?) -> Void)?)

/**
 * @function dispatch_source_cancel
 *
 * @abstract
 * Asynchronously cancel the dispatch source, preventing any further invocation
 * of its event handler block.
 *
 * @discussion
 * Cancellation prevents any further invocation of the event handler block for
 * the specified dispatch source, but does not interrupt an event handler
 * block that is already in progress.
 *
 * The cancellation handler is submitted to the source's target queue once the
 * the source's event handler has finished, indicating it is now safe to close
 * the source's handle (i.e. file descriptor or mach port).
 *
 * See dispatch_source_set_cancel_handler() for more information.
 *
 * @param source
 * The dispatch source to be canceled.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
func __dispatch_source_cancel(_ source: DispatchSource)

/**
 * @function dispatch_source_testcancel
 *
 * @abstract
 * Tests whether the given dispatch source has been canceled.
 *
 * @param source
 * The dispatch source to be tested.
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * Non-zero if canceled and zero if not canceled.
 */
@available(iOS 4.0, *)
@_effects(readonly) func __dispatch_source_testcancel(_ source: DispatchSource) -> Int

/**
 * @function dispatch_source_get_handle
 *
 * @abstract
 * Returns the underlying system handle associated with this dispatch source.
 *
 * @param source
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * The return value should be interpreted according to the type of the dispatch
 * source, and may be one of the following handles:
 *
 *  DISPATCH_SOURCE_TYPE_DATA_ADD:        n/a
 *  DISPATCH_SOURCE_TYPE_DATA_OR:         n/a
 *  DISPATCH_SOURCE_TYPE_DATA_REPLACE:    n/a
 *  DISPATCH_SOURCE_TYPE_MACH_SEND:       mach port (mach_port_t)
 *  DISPATCH_SOURCE_TYPE_MACH_RECV:       mach port (mach_port_t)
 *  DISPATCH_SOURCE_TYPE_MEMORYPRESSURE   n/a
 *  DISPATCH_SOURCE_TYPE_PROC:            process identifier (pid_t)
 *  DISPATCH_SOURCE_TYPE_READ:            file descriptor (int)
 *  DISPATCH_SOURCE_TYPE_SIGNAL:          signal number (int)
 *  DISPATCH_SOURCE_TYPE_TIMER:           n/a
 *  DISPATCH_SOURCE_TYPE_VNODE:           file descriptor (int)
 *  DISPATCH_SOURCE_TYPE_WRITE:           file descriptor (int)
 */
@available(iOS 4.0, *)
@_effects(readonly) func __dispatch_source_get_handle(_ source: DispatchSource) -> UInt

/**
 * @function dispatch_source_get_mask
 *
 * @abstract
 * Returns the mask of events monitored by the dispatch source.
 *
 * @param source
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * The return value should be interpreted according to the type of the dispatch
 * source, and may be one of the following flag sets:
 *
 *  DISPATCH_SOURCE_TYPE_DATA_ADD:        n/a
 *  DISPATCH_SOURCE_TYPE_DATA_OR:         n/a
 *  DISPATCH_SOURCE_TYPE_DATA_REPLACE:    n/a
 *  DISPATCH_SOURCE_TYPE_MACH_SEND:       dispatch_source_mach_send_flags_t
 *  DISPATCH_SOURCE_TYPE_MACH_RECV:       dispatch_source_mach_recv_flags_t
 *  DISPATCH_SOURCE_TYPE_MEMORYPRESSURE   dispatch_source_memorypressure_flags_t
 *  DISPATCH_SOURCE_TYPE_PROC:            dispatch_source_proc_flags_t
 *  DISPATCH_SOURCE_TYPE_READ:            n/a
 *  DISPATCH_SOURCE_TYPE_SIGNAL:          n/a
 *  DISPATCH_SOURCE_TYPE_TIMER:           dispatch_source_timer_flags_t
 *  DISPATCH_SOURCE_TYPE_VNODE:           dispatch_source_vnode_flags_t
 *  DISPATCH_SOURCE_TYPE_WRITE:           n/a
 */
@available(iOS 4.0, *)
@_effects(readonly) func __dispatch_source_get_mask(_ source: DispatchSource) -> UInt

/**
 * @function dispatch_source_get_data
 *
 * @abstract
 * Returns pending data for the dispatch source.
 *
 * @discussion
 * This function is intended to be called from within the event handler block.
 * The result of calling this function outside of the event handler callback is
 * undefined.
 *
 * @param source
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * The return value should be interpreted according to the type of the dispatch
 * source, and may be one of the following:
 *
 *  DISPATCH_SOURCE_TYPE_DATA_ADD:        application defined data
 *  DISPATCH_SOURCE_TYPE_DATA_OR:         application defined data
 *  DISPATCH_SOURCE_TYPE_DATA_REPLACE:    application defined data
 *  DISPATCH_SOURCE_TYPE_MACH_SEND:       dispatch_source_mach_send_flags_t
 *  DISPATCH_SOURCE_TYPE_MACH_RECV:       dispatch_source_mach_recv_flags_t
 *  DISPATCH_SOURCE_TYPE_MEMORYPRESSURE   dispatch_source_memorypressure_flags_t
 *  DISPATCH_SOURCE_TYPE_PROC:            dispatch_source_proc_flags_t
 *  DISPATCH_SOURCE_TYPE_READ:            estimated bytes available to read
 *  DISPATCH_SOURCE_TYPE_SIGNAL:          number of signals delivered since
 *                                            the last handler invocation
 *  DISPATCH_SOURCE_TYPE_TIMER:           number of times the timer has fired
 *                                            since the last handler invocation
 *  DISPATCH_SOURCE_TYPE_VNODE:           dispatch_source_vnode_flags_t
 *  DISPATCH_SOURCE_TYPE_WRITE:           estimated buffer space available
 */
@available(iOS 4.0, *)
@_effects(readonly) func __dispatch_source_get_data(_ source: DispatchSource) -> UInt

/**
 * @function dispatch_source_merge_data
 *
 * @abstract
 * Merges data into a dispatch source of type DISPATCH_SOURCE_TYPE_DATA_ADD,
 * DISPATCH_SOURCE_TYPE_DATA_OR or DISPATCH_SOURCE_TYPE_DATA_REPLACE,
 * and submits its event handler block to its target queue.
 *
 * @param source
 * The result of passing NULL in this parameter is undefined.
 *
 * @param value
 * The value to coalesce with the pending data using a logical OR or an ADD
 * as specified by the dispatch source type. A value of zero has no effect
 * and will not result in the submission of the event handler block.
 */
@available(iOS 4.0, *)
func __dispatch_source_merge_data(_ source: DispatchSource, _ value: UInt)

/**
 * @function dispatch_source_set_timer
 *
 * @abstract
 * Sets a start time, interval, and leeway value for a timer source.
 *
 * @discussion
 * Once this function returns, any pending source data accumulated for the
 * previous timer values has been cleared; the next fire of the timer will
 * occur at 'start', and every 'interval' nanoseconds thereafter until the
 * timer source is canceled.
 *
 * Any fire of the timer may be delayed by the system in order to improve power
 * consumption and system performance. The upper limit to the allowable delay
 * may be configured with the 'leeway' argument, the lower limit is under the
 * control of the system.
 *
 * For the initial timer fire at 'start', the upper limit to the allowable
 * delay is set to 'leeway' nanoseconds. For the subsequent timer fires at
 * 'start' + N * 'interval', the upper limit is MIN('leeway','interval'/2).
 *
 * The lower limit to the allowable delay may vary with process state such as
 * visibility of application UI. If the specified timer source was created with
 * a mask of DISPATCH_TIMER_STRICT, the system will make a best effort to
 * strictly observe the provided 'leeway' value even if it is smaller than the
 * current lower limit. Note that a minimal amount of delay is to be expected
 * even if this flag is specified.
 *
 * The 'start' argument also determines which clock will be used for the timer:
 * If 'start' is DISPATCH_TIME_NOW or was created with dispatch_time(3), the
 * timer is based on up time (which is obtained from mach_absolute_time() on
 * Apple platforms). If 'start' was created with dispatch_walltime(3), the
 * timer is based on gettimeofday(3).
 *
 * Calling this function has no effect if the timer source has already been
 * canceled.
 *
 * @param start
 * The start time of the timer. See dispatch_time() and dispatch_walltime()
 * for more information.
 *
 * @param interval
 * The nanosecond interval for the timer. Use DISPATCH_TIME_FOREVER for a
 * one-shot timer.
 *
 * @param leeway
 * The nanosecond leeway for the timer.
 */
@available(iOS 4.0, *)
func __dispatch_source_set_timer(_ source: DispatchSource, _ start: dispatch_time_t, _ interval: UInt64, _ leeway: UInt64)
@available(iOS 4.3, *)
func __dispatch_source_set_registration_handler(_ source: DispatchSource, _ handler: (() -> Void)?)

/**
 * @function dispatch_source_set_registration_handler_f
 *
 * @abstract
 * Sets the registration handler function for the given dispatch source.
 *
 * @discussion
 * See dispatch_source_set_registration_handler() for more details.
 *
 * @param source
 * The dispatch source to modify.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param handler
 * The registration handler function to submit to the source's target queue.
 * The context parameter passed to the registration handler function is the
 * current context of the dispatch source at the time the handler call is made.
 */
@available(iOS 4.3, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_source_set_registration_handler_f(_ source: DispatchSource, _ handler: (@convention(c) (UnsafeMutableRawPointer?) -> Void)?)
class DispatchGroup : DispatchObject {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}

/// dispatch_group
extension DispatchGroup {
  func notify(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], queue: DispatchQueue, execute work: @escaping @convention(block) () -> Void)
  @available(macOS 10.10, iOS 8.0, *)
  func notify(queue: DispatchQueue, work: DispatchWorkItem)
  func wait()
  func wait(timeout: DispatchTime) -> DispatchTimeoutResult
  func wait(wallTimeout timeout: DispatchWallTime) -> DispatchTimeoutResult
}
@available(swift, obsoleted: 3, renamed: "DispatchGroup")
typealias OS_dispatch_group = DispatchGroup
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_group_t = DispatchGroup

/**
 * @function dispatch_group_create
 *
 * @abstract
 * Creates new group with which blocks may be associated.
 *
 * @discussion
 * This function creates a new group with which blocks may be associated.
 * The dispatch group may be used to wait for the completion of the blocks it
 * references. The group object memory is freed with dispatch_release().
 *
 * @result
 * The newly created group, or NULL on failure.
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchGroup.init()")
func dispatch_group_create() -> DispatchGroup
extension DispatchGroup {

  /**
   * @function dispatch_group_create
   *
   * @abstract
   * Creates new group with which blocks may be associated.
   *
   * @discussion
   * This function creates a new group with which blocks may be associated.
   * The dispatch group may be used to wait for the completion of the blocks it
   * references. The group object memory is freed with dispatch_release().
   *
   * @result
   * The newly created group, or NULL on failure.
   */
  @available(iOS 4.0, *)
  /*not inherited*/ init()

  /**
   * @function dispatch_group_enter
   *
   * @abstract
   * Manually indicate a block has entered the group
   *
   * @discussion
   * Calling this function indicates another block has joined the group through
   * a means other than dispatch_group_async(). Calls to this function must be
   * balanced with dispatch_group_leave().
   *
   * @param group
   * The dispatch group to update.
   * The result of passing NULL in this parameter is undefined.
   */
  @available(iOS 4.0, *)
  func enter()

  /**
   * @function dispatch_group_leave
   *
   * @abstract
   * Manually indicate a block in the group has completed
   *
   * @discussion
   * Calling this function indicates block has completed and left the dispatch
   * group by a means other than dispatch_group_async().
   *
   * @param group
   * The dispatch group to update.
   * The result of passing NULL in this parameter is undefined.
   */
  @available(iOS 4.0, *)
  func leave()
}
@available(iOS 4.0, *)
func __dispatch_group_async(_ group: DispatchGroup, _ queue: DispatchQueue, _ block: @escaping () -> Void)

/**
 * @function dispatch_group_async_f
 *
 * @abstract
 * Submits a function to a dispatch queue and associates the block with the
 * given dispatch group.
 *
 * @discussion
 * See dispatch_group_async() for details.
 *
 * @param group
 * A dispatch group to associate with the submitted function.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param queue
 * The dispatch queue to which the function will be submitted for asynchronous
 * invocation.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_group_async_f().
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_group_async_f(_ group: DispatchGroup, _ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)

/**
 * @function dispatch_group_wait
 *
 * @abstract
 * Wait synchronously until all the blocks associated with a group have
 * completed or until the specified timeout has elapsed.
 *
 * @discussion
 * This function waits for the completion of the blocks associated with the
 * given dispatch group, and returns after all blocks have completed or when
 * the specified timeout has elapsed.
 *
 * This function will return immediately if there are no blocks associated
 * with the dispatch group (i.e. the group is empty).
 *
 * The result of calling this function from multiple threads simultaneously
 * with the same dispatch group is undefined.
 *
 * After the successful return of this function, the dispatch group is empty.
 * It may either be released with dispatch_release() or re-used for additional
 * blocks. See dispatch_group_async() for more information.
 *
 * @param group
 * The dispatch group to wait on.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param timeout
 * When to timeout (see dispatch_time). As a convenience, there are the
 * DISPATCH_TIME_NOW and DISPATCH_TIME_FOREVER constants.
 *
 * @result
 * Returns zero on success (all blocks associated with the group completed
 * within the specified timeout) or non-zero on error (i.e. timed out).
 */
@available(iOS 4.0, *)
func __dispatch_group_wait(_ group: DispatchGroup, _ timeout: dispatch_time_t) -> Int
@available(iOS 4.0, *)
func __dispatch_group_notify(_ group: DispatchGroup, _ queue: DispatchQueue, _ block: @escaping () -> Void)

/**
 * @function dispatch_group_notify_f
 *
 * @abstract
 * Schedule a function to be submitted to a queue when all the blocks
 * associated with a group have completed.
 *
 * @discussion
 * See dispatch_group_notify() for details.
 *
 * @param group
 * The dispatch group to observe.
 * The result of passing NULL in this parameter is undefined.
 *
 * @param context
 * The application-defined context parameter to pass to the function.
 *
 * @param work
 * The application-defined function to invoke on the target queue. The first
 * parameter passed to this function is the context provided to
 * dispatch_group_notify_f().
 */
@available(iOS 4.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_group_notify_f(_ group: DispatchGroup, _ queue: DispatchQueue, _ context: UnsafeMutableRawPointer?, _ work: @convention(c) (UnsafeMutableRawPointer?) -> Void)

/**
 * @function dispatch_group_enter
 *
 * @abstract
 * Manually indicate a block has entered the group
 *
 * @discussion
 * Calling this function indicates another block has joined the group through
 * a means other than dispatch_group_async(). Calls to this function must be
 * balanced with dispatch_group_leave().
 *
 * @param group
 * The dispatch group to update.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchGroup.enter(self:)")
func dispatch_group_enter(_ group: DispatchGroup)

/**
 * @function dispatch_group_leave
 *
 * @abstract
 * Manually indicate a block in the group has completed
 *
 * @discussion
 * Calling this function indicates block has completed and left the dispatch
 * group by a means other than dispatch_group_async().
 *
 * @param group
 * The dispatch group to update.
 * The result of passing NULL in this parameter is undefined.
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchGroup.leave(self:)")
func dispatch_group_leave(_ group: DispatchGroup)
class DispatchSemaphore : DispatchObject {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}

/// dispatch_semaphore
extension DispatchSemaphore {
  @discardableResult
  func signal() -> Int
  func wait()
  func wait(timeout: DispatchTime) -> DispatchTimeoutResult
  func wait(wallTimeout: DispatchWallTime) -> DispatchTimeoutResult
}
@available(swift, obsoleted: 3, renamed: "DispatchSemaphore")
typealias OS_dispatch_semaphore = DispatchSemaphore
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_semaphore_t = DispatchSemaphore

/**
 * @function dispatch_semaphore_create
 *
 * @abstract
 * Creates new counting semaphore with an initial value.
 *
 * @discussion
 * Passing zero for the value is useful for when two threads need to reconcile
 * the completion of a particular event. Passing a value greater than zero is
 * useful for managing a finite pool of resources, where the pool size is equal
 * to the value.
 *
 * @param value
 * The starting value for the semaphore. Passing a value less than zero will
 * cause NULL to be returned.
 *
 * @result
 * The newly created semaphore, or NULL on failure.
 */
@available(iOS 4.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchSemaphore.init(value:)")
func dispatch_semaphore_create(_ value: Int) -> DispatchSemaphore
extension DispatchSemaphore {

  /**
   * @function dispatch_semaphore_create
   *
   * @abstract
   * Creates new counting semaphore with an initial value.
   *
   * @discussion
   * Passing zero for the value is useful for when two threads need to reconcile
   * the completion of a particular event. Passing a value greater than zero is
   * useful for managing a finite pool of resources, where the pool size is equal
   * to the value.
   *
   * @param value
   * The starting value for the semaphore. Passing a value less than zero will
   * cause NULL to be returned.
   *
   * @result
   * The newly created semaphore, or NULL on failure.
   */
  @available(iOS 4.0, *)
  /*not inherited*/ init(value: Int)
}

/**
 * @function dispatch_semaphore_wait
 *
 * @abstract
 * Wait (decrement) for a semaphore.
 *
 * @discussion
 * Decrement the counting semaphore. If the resulting value is less than zero,
 * this function waits for a signal to occur before returning.
 *
 * @param dsema
 * The semaphore. The result of passing NULL in this parameter is undefined.
 *
 * @param timeout
 * When to timeout (see dispatch_time). As a convenience, there are the
 * DISPATCH_TIME_NOW and DISPATCH_TIME_FOREVER constants.
 *
 * @result
 * Returns zero on success, or non-zero if the timeout occurred.
 */
@available(iOS 4.0, *)
func __dispatch_semaphore_wait(_ dsema: DispatchSemaphore, _ timeout: dispatch_time_t) -> Int

/**
 * @function dispatch_semaphore_signal
 *
 * @abstract
 * Signal (increment) a semaphore.
 *
 * @discussion
 * Increment the counting semaphore. If the previous value was less than zero,
 * this function wakes a waiting thread before returning.
 *
 * @param dsema The counting semaphore.
 * The result of passing NULL in this parameter is undefined.
 *
 * @result
 * This function returns non-zero if a thread is woken. Otherwise, zero is
 * returned.
 */
@available(iOS 4.0, *)
func __dispatch_semaphore_signal(_ dsema: DispatchSemaphore) -> Int
@available(*, unavailable, message: "Use lazily initialized globals instead")
typealias dispatch_once_t = Int
var DISPATCH_ONCE_INLINE_FASTPATH: Int32 { get }
@available(iOS 4.0, *)
@available(*, unavailable, message: "Use lazily initialized globals instead")
func dispatch_once(_ predicate: UnsafeMutablePointer<Int>, _ block: () -> Void)
@available(*, unavailable, message: "Use lazily initialized globals instead")
func _dispatch_once(_ predicate: UnsafeMutablePointer<Int>, _ block: () -> Void)
@_effects(readnone) func __builtin_expect(_: Int, _: Int) -> Int
func __builtin_assume(_: Bool)
@available(iOS 4.0, *)
@available(*, unavailable, message: "Use lazily initialized globals instead")
func dispatch_once_f(_ predicate: UnsafeMutablePointer<Int>, _ context: UnsafeMutableRawPointer?, _ function: @convention(c) (UnsafeMutableRawPointer?) -> Void)
@available(*, unavailable, message: "Use lazily initialized globals instead")
func _dispatch_once_f(_ predicate: UnsafeMutablePointer<Int>, _ context: UnsafeMutableRawPointer?, _ function: @convention(c) (UnsafeMutableRawPointer?) -> Void)
@available(swift, obsoleted: 3, renamed: "__DispatchData")
typealias OS_dispatch_data = __DispatchData
class __DispatchData : NSObject {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_data_t = __DispatchData
@available(iOS 5.0, *)
@available(*, unavailable, message: "Not available in Swift")
let _dispatch_data_destructor_free: @convention(block) () -> Void
@available(iOS 7.0, *)
@available(*, unavailable, message: "Not available in Swift")
let _dispatch_data_destructor_munmap: @convention(block) () -> Void

/**
 * @function dispatch_data_create
 * Creates a dispatch data object from the given contiguous buffer of memory. If
 * a non-default destructor is provided, ownership of the buffer remains with
 * the caller (i.e. the bytes will not be copied). The last release of the data
 * object will result in the invocation of the specified destructor on the
 * specified queue to free the buffer.
 *
 * If the DISPATCH_DATA_DESTRUCTOR_FREE destructor is provided the buffer will
 * be freed via free(3) and the queue argument ignored.
 *
 * If the DISPATCH_DATA_DESTRUCTOR_DEFAULT destructor is provided, data object
 * creation will copy the buffer into internal memory managed by the system.
 *
 * @param buffer	A contiguous buffer of data.
 * @param size		The size of the contiguous buffer of data.
 * @param queue		The queue to which the destructor should be submitted.
 * @param destructor	The destructor responsible for freeing the data when it
 *			is no longer needed.
 * @result		A newly created dispatch data object.
 */
@available(iOS 5.0, *)
@available(*, unavailable, message: "Not available in Swift")
func dispatch_data_create(_ buffer: UnsafeRawPointer, _ size: Int, _ queue: DispatchQueue?, _ destructor: (() -> Void)?) -> __DispatchData

/**
 * @function dispatch_data_get_size
 * Returns the logical size of the memory region(s) represented by the specified
 * dispatch data object.
 *
 * @param data	The dispatch data object to query.
 * @result	The number of bytes represented by the data object.
 */
@available(iOS 5.0, *)
@_effects(readonly) func __dispatch_data_get_size(_ data: __DispatchData) -> Int

/**
 * @function dispatch_data_create_map
 * Maps the memory represented by the specified dispatch data object as a single
 * contiguous memory region and returns a new data object representing it.
 * If non-NULL references to a pointer and a size variable are provided, they
 * are filled with the location and extent of that region. These allow direct
 * read access to the represented memory, but are only valid until the returned
 * object is released. Under ARC, if that object is held in a variable with
 * automatic storage, care needs to be taken to ensure that it is not released
 * by the compiler before memory access via the pointer has been completed.
 *
 * @param data		The dispatch data object to map.
 * @param buffer_ptr	A pointer to a pointer variable to be filled with the
 *			location of the mapped contiguous memory region, or
 *			NULL.
 * @param size_ptr	A pointer to a size_t variable to be filled with the
 *			size of the mapped contiguous memory region, or NULL.
 * @result		A newly created dispatch data object.
 */
@available(iOS 5.0, *)
func __dispatch_data_create_map(_ data: __DispatchData, _ buffer_ptr: UnsafeMutablePointer<UnsafeRawPointer?>?, _ size_ptr: UnsafeMutablePointer<Int>?) -> __DispatchData

/**
 * @function dispatch_data_create_concat
 * Returns a new dispatch data object representing the concatenation of the
 * specified data objects. Those objects may be released by the application
 * after the call returns (however, the system might not deallocate the memory
 * region(s) described by them until the newly created object has also been
 * released).
 *
 * @param data1	The data object representing the region(s) of memory to place
 *		at the beginning of the newly created object.
 * @param data2	The data object representing the region(s) of memory to place
 *		at the end of the newly created object.
 * @result	A newly created object representing the concatenation of the
 *		data1 and data2 objects.
 */
@available(iOS 5.0, *)
func __dispatch_data_create_concat(_ data1: __DispatchData, _ data2: __DispatchData) -> __DispatchData

/**
 * @function dispatch_data_create_subrange
 * Returns a new dispatch data object representing a subrange of the specified
 * data object, which may be released by the application after the call returns
 * (however, the system might not deallocate the memory region(s) described by
 * that object until the newly created object has also been released).
 *
 * @param data		The data object representing the region(s) of memory to
 *			create a subrange of.
 * @param offset	The offset into the data object where the subrange
 *			starts.
 * @param length	The length of the range.
 * @result		A newly created object representing the specified
 *			subrange of the data object.
 */
@available(iOS 5.0, *)
func __dispatch_data_create_subrange(_ data: __DispatchData, _ offset: Int, _ length: Int) -> __DispatchData

/**
 * @typedef dispatch_data_applier_t
 * A block to be invoked for every contiguous memory region in a data object.
 *
 * @param region	A data object representing the current region.
 * @param offset	The logical offset of the current region to the start
 *			of the data object.
 * @param buffer	The location of the memory for the current region.
 * @param size		The size of the memory for the current region.
 * @result		A Boolean indicating whether traversal should continue.
 */
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_data_applier_t = (__DispatchData, Int, UnsafeRawPointer, Int) -> Bool

/**
 * @function dispatch_data_apply
 * Traverse the memory regions represented by the specified dispatch data object
 * in logical order and invoke the specified block once for every contiguous
 * memory region encountered.
 *
 * Each invocation of the block is passed a data object representing the current
 * region and its logical offset, along with the memory location and extent of
 * the region. These allow direct read access to the memory region, but are only
 * valid until the passed-in region object is released. Note that the region
 * object is released by the system when the block returns, it is the
 * responsibility of the application to retain it if the region object or the
 * associated memory location are needed after the block returns.
 *
 * @param data		The data object to traverse.
 * @param applier	The block to be invoked for every contiguous memory
 *			region in the data object.
 * @result		A Boolean indicating whether traversal completed
 *			successfully.
 */
@available(iOS 5.0, *)
func __dispatch_data_apply(_ data: __DispatchData, _ applier: (__DispatchData, Int, UnsafeRawPointer, Int) -> Bool) -> Bool

/**
 * @function dispatch_data_copy_region
 * Finds the contiguous memory region containing the specified location among
 * the regions represented by the specified object and returns a copy of the
 * internal dispatch data object representing that region along with its logical
 * offset in the specified object.
 *
 * @param data		The dispatch data object to query.
 * @param location	The logical position in the data object to query.
 * @param offset_ptr	A pointer to a size_t variable to be filled with the
 *			logical offset of the returned region object to the
 *			start of the queried data object.
 * @result		A newly created dispatch data object.
 */
@available(iOS 5.0, *)
func __dispatch_data_copy_region(_ data: __DispatchData, _ location: Int, _ offset_ptr: UnsafeMutablePointer<Int>) -> __DispatchData
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_fd_t = Int32

/**
 * @function dispatch_read
 * Schedule a read operation for asynchronous execution on the specified file
 * descriptor. The specified handler is enqueued with the data read from the
 * file descriptor when the operation has completed or an error occurs.
 *
 * The data object passed to the handler will be automatically released by the
 * system when the handler returns. It is the responsibility of the application
 * to retain, concatenate or copy the data object if it is needed after the
 * handler returns.
 *
 * The data object passed to the handler will only contain as much data as is
 * currently available from the file descriptor (up to the specified length).
 *
 * If an unrecoverable error occurs on the file descriptor, the handler will be
 * enqueued with the appropriate error code along with a data object of any data
 * that could be read successfully.
 *
 * An invocation of the handler with an error code of zero and an empty data
 * object indicates that EOF was reached.
 *
 * The system takes control of the file descriptor until the handler is
 * enqueued, and during this time file descriptor flags such as O_NONBLOCK will
 * be modified by the system on behalf of the application. It is an error for
 * the application to modify a file descriptor directly while it is under the
 * control of the system, but it may create additional dispatch I/O convenience
 * operations or dispatch I/O channels associated with that file descriptor.
 *
 * @param fd		The file descriptor from which to read the data.
 * @param length	The length of data to read from the file descriptor,
 *			or SIZE_MAX to indicate that all of the data currently
 *			available from the file descriptor should be read.
 * @param queue		The dispatch queue to which the handler should be
 *			submitted.
 * @param handler	The handler to enqueue when data is ready to be
 *			delivered.
 *		param data	The data read from the file descriptor.
 *		param error	An errno condition for the read operation or
 *				zero if the read was successful.
 */
@available(iOS 5.0, *)
func __dispatch_read(_ fd: Int32, _ length: Int, _ queue: DispatchQueue, _ handler: @escaping (__DispatchData, Int32) -> Void)

/**
 * @function dispatch_write
 * Schedule a write operation for asynchronous execution on the specified file
 * descriptor. The specified handler is enqueued when the operation has
 * completed or an error occurs.
 *
 * If an unrecoverable error occurs on the file descriptor, the handler will be
 * enqueued with the appropriate error code along with the data that could not
 * be successfully written.
 *
 * An invocation of the handler with an error code of zero indicates that the
 * data was fully written to the channel.
 *
 * The system takes control of the file descriptor until the handler is
 * enqueued, and during this time file descriptor flags such as O_NONBLOCK will
 * be modified by the system on behalf of the application. It is an error for
 * the application to modify a file descriptor directly while it is under the
 * control of the system, but it may create additional dispatch I/O convenience
 * operations or dispatch I/O channels associated with that file descriptor.
 *
 * @param fd		The file descriptor to which to write the data.
 * @param data		The data object to write to the file descriptor.
 * @param queue		The dispatch queue to which the handler should be
 *			submitted.
 * @param handler	The handler to enqueue when the data has been written.
 *		param data	The data that could not be written to the I/O
 *				channel, or NULL.
 *		param error	An errno condition for the write operation or
 *				zero if the write was successful.
 */
@available(iOS 5.0, *)
func __dispatch_write(_ fd: Int32, _ data: __DispatchData, _ queue: DispatchQueue, _ handler: @escaping (__DispatchData?, Int32) -> Void)
class DispatchIO : DispatchObject {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}

extension DispatchIO {
  enum StreamType : UInt {
    case stream
    case random
    init?(rawValue: UInt)
    typealias RawValue = UInt
    var rawValue: UInt { get }
  }
  struct CloseFlags : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let stop: DispatchIO.CloseFlags
    typealias ArrayLiteralElement = DispatchIO.CloseFlags
    typealias Element = DispatchIO.CloseFlags
    typealias RawValue = UInt
  }
  struct IntervalFlags : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    init(nilLiteral: ())
    static let strictInterval: DispatchIO.IntervalFlags
    typealias ArrayLiteralElement = DispatchIO.IntervalFlags
    typealias Element = DispatchIO.IntervalFlags
    typealias RawValue = UInt
  }
  class func read(fromFileDescriptor: Int32, maxLength: Int, runningHandlerOn queue: DispatchQueue, handler: @escaping (_ data: DispatchData, _ error: Int32) -> Void)
  class func write(toFileDescriptor: Int32, data: DispatchData, runningHandlerOn queue: DispatchQueue, handler: @escaping (_ data: DispatchData?, _ error: Int32) -> Void)
  convenience init(type: DispatchIO.StreamType, fileDescriptor: Int32, queue: DispatchQueue, cleanupHandler: @escaping (_ error: Int32) -> Void)
  @available(swift, obsoleted: 4)
  convenience init(type: DispatchIO.StreamType, path: UnsafePointer<Int8>, oflag: Int32, mode: mode_t, queue: DispatchQueue, cleanupHandler: @escaping (_ error: Int32) -> Void)
  @available(swift 4)
  convenience init?(type: DispatchIO.StreamType, path: UnsafePointer<Int8>, oflag: Int32, mode: mode_t, queue: DispatchQueue, cleanupHandler: @escaping (_ error: Int32) -> Void)
  convenience init(type: DispatchIO.StreamType, io: DispatchIO, queue: DispatchQueue, cleanupHandler: @escaping (_ error: Int32) -> Void)
  func read(offset: off_t, length: Int, queue: DispatchQueue, ioHandler: @escaping (_ done: Bool, _ data: DispatchData?, _ error: Int32) -> Void)
  func write(offset: off_t, data: DispatchData, queue: DispatchQueue, ioHandler: @escaping (_ done: Bool, _ data: DispatchData?, _ error: Int32) -> Void)
  func setInterval(interval: DispatchTimeInterval, flags: DispatchIO.IntervalFlags = [])
  func close(flags: DispatchIO.CloseFlags = [])
}

extension DispatchIO.StreamType : Equatable {
}

extension DispatchIO.StreamType : Hashable {
}

extension DispatchIO.StreamType : RawRepresentable {
}
@available(swift, obsoleted: 3, renamed: "DispatchIO")
typealias OS_dispatch_io = DispatchIO
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_io_t = DispatchIO
var DISPATCH_IO_STREAM: Int32 { get }
var DISPATCH_IO_RANDOM: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_io_type_t = UInt

/**
 * @function dispatch_io_create
 * Create a dispatch I/O channel associated with a file descriptor. The system
 * takes control of the file descriptor until the channel is closed, an error
 * occurs on the file descriptor or all references to the channel are released.
 * At that time the specified cleanup handler will be enqueued and control over
 * the file descriptor relinquished.
 *
 * While a file descriptor is under the control of a dispatch I/O channel, file
 * descriptor flags such as O_NONBLOCK will be modified by the system on behalf
 * of the application. It is an error for the application to modify a file
 * descriptor directly while it is under the control of a dispatch I/O channel,
 * but it may create additional channels associated with that file descriptor.
 *
 * @param type	The desired type of I/O channel (DISPATCH_IO_STREAM
 *		or DISPATCH_IO_RANDOM).
 * @param fd	The file descriptor to associate with the I/O channel.
 * @param queue	The dispatch queue to which the handler should be submitted.
 * @param cleanup_handler	The handler to enqueue when the system
 *				relinquishes control over the file descriptor.
 *	param error		An errno condition if control is relinquished
 *				because channel creation failed, zero otherwise.
 * @result	The newly created dispatch I/O channel or NULL if an error
 *		occurred (invalid type specified).
 */
@available(iOS 5.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchIO.init(__type:fd:queue:handler:)")
func __dispatch_io_create(_ type: UInt, _ fd: Int32, _ queue: DispatchQueue, _ cleanup_handler: @escaping (Int32) -> Void) -> DispatchIO
extension DispatchIO {

  /**
   * @function dispatch_io_create
   * Create a dispatch I/O channel associated with a file descriptor. The system
   * takes control of the file descriptor until the channel is closed, an error
   * occurs on the file descriptor or all references to the channel are released.
   * At that time the specified cleanup handler will be enqueued and control over
   * the file descriptor relinquished.
   *
   * While a file descriptor is under the control of a dispatch I/O channel, file
   * descriptor flags such as O_NONBLOCK will be modified by the system on behalf
   * of the application. It is an error for the application to modify a file
   * descriptor directly while it is under the control of a dispatch I/O channel,
   * but it may create additional channels associated with that file descriptor.
   *
   * @param type	The desired type of I/O channel (DISPATCH_IO_STREAM
   *		or DISPATCH_IO_RANDOM).
   * @param fd	The file descriptor to associate with the I/O channel.
   * @param queue	The dispatch queue to which the handler should be submitted.
   * @param cleanup_handler	The handler to enqueue when the system
   *				relinquishes control over the file descriptor.
   *	param error		An errno condition if control is relinquished
   *				because channel creation failed, zero otherwise.
   * @result	The newly created dispatch I/O channel or NULL if an error
   *		occurred (invalid type specified).
   */
  @available(iOS 5.0, *)
  /*not inherited*/ init(__type type: UInt, fd: Int32, queue: DispatchQueue, handler cleanup_handler: @escaping (Int32) -> Void)

  /**
   * @function dispatch_io_create_with_path
   * Create a dispatch I/O channel associated with a path name. The specified
   * path, oflag and mode parameters will be passed to open(2) when the first I/O
   * operation on the channel is ready to execute and the resulting file
   * descriptor will remain open and under the control of the system until the
   * channel is closed, an error occurs on the file descriptor or all references
   * to the channel are released. At that time the file descriptor will be closed
   * and the specified cleanup handler will be enqueued.
   *
   * @param type	The desired type of I/O channel (DISPATCH_IO_STREAM
   *		or DISPATCH_IO_RANDOM).
   * @param path	The absolute path to associate with the I/O channel.
   * @param oflag	The flags to pass to open(2) when opening the file at
   *		path.
   * @param mode	The mode to pass to open(2) when creating the file at
   *		path (i.e. with flag O_CREAT), zero otherwise.
   * @param queue	The dispatch queue to which the handler should be
   *		submitted.
   * @param cleanup_handler	The handler to enqueue when the system
   *				has closed the file at path.
   *	param error		An errno condition if control is relinquished
   *				because channel creation or opening of the
   *				specified file failed, zero otherwise.
   * @result	The newly created dispatch I/O channel or NULL if an error
   *		occurred (invalid type or non-absolute path specified).
   */
  @available(iOS 5.0, *)
  /*not inherited*/ init(__type type: UInt, path: UnsafePointer<CChar>, oflag: Int32, mode: mode_t, queue: DispatchQueue, handler cleanup_handler: @escaping (Int32) -> Void)

  /**
   * @function dispatch_io_create_with_io
   * Create a new dispatch I/O channel from an existing dispatch I/O channel.
   * The new channel inherits the file descriptor or path name associated with
   * the existing channel, but not its channel type or policies.
   *
   * If the existing channel is associated with a file descriptor, control by the
   * system over that file descriptor is extended until the new channel is also
   * closed, an error occurs on the file descriptor, or all references to both
   * channels are released. At that time the specified cleanup handler will be
   * enqueued and control over the file descriptor relinquished.
   *
   * While a file descriptor is under the control of a dispatch I/O channel, file
   * descriptor flags such as O_NONBLOCK will be modified by the system on behalf
   * of the application. It is an error for the application to modify a file
   * descriptor directly while it is under the control of a dispatch I/O channel,
   * but it may create additional channels associated with that file descriptor.
   *
   * @param type	The desired type of I/O channel (DISPATCH_IO_STREAM
   *		or DISPATCH_IO_RANDOM).
   * @param io	The existing channel to create the new I/O channel from.
   * @param queue	The dispatch queue to which the handler should be submitted.
   * @param cleanup_handler	The handler to enqueue when the system
   *				relinquishes control over the file descriptor
   *				(resp. closes the file at path) associated with
   *				the existing channel.
   *	param error		An errno condition if control is relinquished
   *				because channel creation failed, zero otherwise.
   * @result	The newly created dispatch I/O channel or NULL if an error
   *		occurred (invalid type specified).
   */
  @available(iOS 5.0, *)
  /*not inherited*/ init(__type type: UInt, io: DispatchIO, queue: DispatchQueue, handler cleanup_handler: @escaping (Int32) -> Void)

  /**
   * @function dispatch_io_barrier
   * Schedule a barrier operation on the specified I/O channel; all previously
   * scheduled operations on the channel will complete before the provided
   * barrier block is enqueued onto the global queue determined by the channel's
   * target queue, and no subsequently scheduled operations will start until the
   * barrier block has returned.
   *
   * If multiple channels are associated with the same file descriptor, a barrier
   * operation scheduled on any of these channels will act as a barrier across all
   * channels in question, i.e. all previously scheduled operations on any of the
   * channels will complete before the barrier block is enqueued, and no
   * operations subsequently scheduled on any of the channels will start until the
   * barrier block has returned.
   *
   * While the barrier block is running, it may safely operate on the channel's
   * underlying file descriptor with fsync(2), lseek(2) etc. (but not close(2)).
   *
   * @param channel	The dispatch I/O channel to schedule the barrier on.
   * @param barrier	The barrier block.
   */
  @available(iOS 5.0, *)
  func barrier(execute barrier: @escaping () -> Void)

  /**
   * @function dispatch_io_get_descriptor
   * Returns the file descriptor underlying a dispatch I/O channel.
   *
   * Will return -1 for a channel closed with dispatch_io_close() and for a
   * channel associated with a path name that has not yet been open(2)ed.
   *
   * If called from a barrier block scheduled on a channel associated with a path
   * name that has not yet been open(2)ed, this will trigger the channel open(2)
   * operation and return the resulting file descriptor.
   *
   * @param channel	The dispatch I/O channel to query.
   * @result		The file descriptor underlying the channel, or -1.
   */
  @available(iOS 5.0, *)
  var fileDescriptor: Int32 { get }

  /**
   * @function dispatch_io_set_high_water
   * Set a high water mark on the I/O channel for all operations.
   *
   * The system will make a best effort to enqueue I/O handlers with partial
   * results as soon the number of bytes processed by an operation (i.e. read or
   * written) reaches the high water mark.
   *
   * The size of data objects passed to I/O handlers for this channel will never
   * exceed the specified high water mark.
   *
   * The default value for the high water mark is unlimited (i.e. SIZE_MAX).
   *
   * @param channel	The dispatch I/O channel on which to set the policy.
   * @param high_water	The number of bytes to use as a high water mark.
   */
  @available(iOS 5.0, *)
  func setLimit(highWater high_water: Int)

  /**
   * @function dispatch_io_set_low_water
   * Set a low water mark on the I/O channel for all operations.
   *
   * The system will process (i.e. read or write) at least the low water mark
   * number of bytes for an operation before enqueueing I/O handlers with partial
   * results.
   *
   * The size of data objects passed to intermediate I/O handler invocations for
   * this channel (i.e. excluding the final invocation) will never be smaller than
   * the specified low water mark, except if the channel has an interval with the
   * DISPATCH_IO_STRICT_INTERVAL flag set or if EOF or an error was encountered.
   *
   * I/O handlers should be prepared to receive amounts of data significantly
   * larger than the low water mark in general. If an I/O handler requires
   * intermediate results of fixed size, set both the low and and the high water
   * mark to that size.
   *
   * The default value for the low water mark is unspecified, but must be assumed
   * to be such that intermediate handler invocations may occur.
   * If I/O handler invocations with partial results are not desired, set the
   * low water mark to SIZE_MAX.
   *
   * @param channel	The dispatch I/O channel on which to set the policy.
   * @param low_water	The number of bytes to use as a low water mark.
   */
  @available(iOS 5.0, *)
  func setLimit(lowWater low_water: Int)
}

/**
 * @function dispatch_io_create_with_path
 * Create a dispatch I/O channel associated with a path name. The specified
 * path, oflag and mode parameters will be passed to open(2) when the first I/O
 * operation on the channel is ready to execute and the resulting file
 * descriptor will remain open and under the control of the system until the
 * channel is closed, an error occurs on the file descriptor or all references
 * to the channel are released. At that time the file descriptor will be closed
 * and the specified cleanup handler will be enqueued.
 *
 * @param type	The desired type of I/O channel (DISPATCH_IO_STREAM
 *		or DISPATCH_IO_RANDOM).
 * @param path	The absolute path to associate with the I/O channel.
 * @param oflag	The flags to pass to open(2) when opening the file at
 *		path.
 * @param mode	The mode to pass to open(2) when creating the file at
 *		path (i.e. with flag O_CREAT), zero otherwise.
 * @param queue	The dispatch queue to which the handler should be
 *		submitted.
 * @param cleanup_handler	The handler to enqueue when the system
 *				has closed the file at path.
 *	param error		An errno condition if control is relinquished
 *				because channel creation or opening of the
 *				specified file failed, zero otherwise.
 * @result	The newly created dispatch I/O channel or NULL if an error
 *		occurred (invalid type or non-absolute path specified).
 */
@available(iOS 5.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchIO.init(__type:path:oflag:mode:queue:handler:)")
func __dispatch_io_create_with_path(_ type: UInt, _ path: UnsafePointer<CChar>, _ oflag: Int32, _ mode: mode_t, _ queue: DispatchQueue, _ cleanup_handler: @escaping (Int32) -> Void) -> DispatchIO

/**
 * @function dispatch_io_create_with_io
 * Create a new dispatch I/O channel from an existing dispatch I/O channel.
 * The new channel inherits the file descriptor or path name associated with
 * the existing channel, but not its channel type or policies.
 *
 * If the existing channel is associated with a file descriptor, control by the
 * system over that file descriptor is extended until the new channel is also
 * closed, an error occurs on the file descriptor, or all references to both
 * channels are released. At that time the specified cleanup handler will be
 * enqueued and control over the file descriptor relinquished.
 *
 * While a file descriptor is under the control of a dispatch I/O channel, file
 * descriptor flags such as O_NONBLOCK will be modified by the system on behalf
 * of the application. It is an error for the application to modify a file
 * descriptor directly while it is under the control of a dispatch I/O channel,
 * but it may create additional channels associated with that file descriptor.
 *
 * @param type	The desired type of I/O channel (DISPATCH_IO_STREAM
 *		or DISPATCH_IO_RANDOM).
 * @param io	The existing channel to create the new I/O channel from.
 * @param queue	The dispatch queue to which the handler should be submitted.
 * @param cleanup_handler	The handler to enqueue when the system
 *				relinquishes control over the file descriptor
 *				(resp. closes the file at path) associated with
 *				the existing channel.
 *	param error		An errno condition if control is relinquished
 *				because channel creation failed, zero otherwise.
 * @result	The newly created dispatch I/O channel or NULL if an error
 *		occurred (invalid type specified).
 */
@available(iOS 5.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchIO.init(__type:io:queue:handler:)")
func __dispatch_io_create_with_io(_ type: UInt, _ io: DispatchIO, _ queue: DispatchQueue, _ cleanup_handler: @escaping (Int32) -> Void) -> DispatchIO

/**
 * @typedef dispatch_io_handler_t
 * The prototype of I/O handler blocks for dispatch I/O operations.
 *
 * @param done		A flag indicating whether the operation is complete.
 * @param data		The data object to be handled.
 * @param error		An errno condition for the operation.
 */
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_io_handler_t = (Bool, __DispatchData?, Int32) -> Void

/**
 * @function dispatch_io_read
 * Schedule a read operation for asynchronous execution on the specified I/O
 * channel. The I/O handler is enqueued one or more times depending on the
 * general load of the system and the policy specified on the I/O channel.
 *
 * Any data read from the channel is described by the dispatch data object
 * passed to the I/O handler. This object will be automatically released by the
 * system when the I/O handler returns. It is the responsibility of the
 * application to retain, concatenate or copy the data object if it is needed
 * after the I/O handler returns.
 *
 * Dispatch I/O handlers are not reentrant. The system will ensure that no new
 * I/O handler instance is invoked until the previously enqueued handler block
 * has returned.
 *
 * An invocation of the I/O handler with the done flag set indicates that the
 * read operation is complete and that the handler will not be enqueued again.
 *
 * If an unrecoverable error occurs on the I/O channel's underlying file
 * descriptor, the I/O handler will be enqueued with the done flag set, the
 * appropriate error code and a NULL data object.
 *
 * An invocation of the I/O handler with the done flag set, an error code of
 * zero and an empty data object indicates that EOF was reached.
 *
 * @param channel	The dispatch I/O channel from which to read the data.
 * @param offset	The offset relative to the channel position from which
 *			to start reading (only for DISPATCH_IO_RANDOM).
 * @param length	The length of data to read from the I/O channel, or
 *			SIZE_MAX to indicate that data should be read until EOF
 *			is reached.
 * @param queue		The dispatch queue to which the I/O handler should be
 *			submitted.
 * @param io_handler	The I/O handler to enqueue when data is ready to be
 *			delivered.
 *	param done	A flag indicating whether the operation is complete.
 *	param data	An object with the data most recently read from the
 *			I/O channel as part of this read operation, or NULL.
 *	param error	An errno condition for the read operation or zero if
 *			the read was successful.
 */
@available(iOS 5.0, *)
func __dispatch_io_read(_ channel: DispatchIO, _ offset: off_t, _ length: Int, _ queue: DispatchQueue, _ io_handler: @escaping (Bool, __DispatchData?, Int32) -> Void)

/**
 * @function dispatch_io_write
 * Schedule a write operation for asynchronous execution on the specified I/O
 * channel. The I/O handler is enqueued one or more times depending on the
 * general load of the system and the policy specified on the I/O channel.
 *
 * Any data remaining to be written to the I/O channel is described by the
 * dispatch data object passed to the I/O handler. This object will be
 * automatically released by the system when the I/O handler returns. It is the
 * responsibility of the application to retain, concatenate or copy the data
 * object if it is needed after the I/O handler returns.
 *
 * Dispatch I/O handlers are not reentrant. The system will ensure that no new
 * I/O handler instance is invoked until the previously enqueued handler block
 * has returned.
 *
 * An invocation of the I/O handler with the done flag set indicates that the
 * write operation is complete and that the handler will not be enqueued again.
 *
 * If an unrecoverable error occurs on the I/O channel's underlying file
 * descriptor, the I/O handler will be enqueued with the done flag set, the
 * appropriate error code and an object containing the data that could not be
 * written.
 *
 * An invocation of the I/O handler with the done flag set and an error code of
 * zero indicates that the data was fully written to the channel.
 *
 * @param channel	The dispatch I/O channel on which to write the data.
 * @param offset	The offset relative to the channel position from which
 *			to start writing (only for DISPATCH_IO_RANDOM).
 * @param data		The data to write to the I/O channel. The data object
 *			will be retained by the system until the write operation
 *			is complete.
 * @param queue		The dispatch queue to which the I/O handler should be
 *			submitted.
 * @param io_handler	The I/O handler to enqueue when data has been delivered.
 *	param done	A flag indicating whether the operation is complete.
 *	param data	An object of the data remaining to be
 *			written to the I/O channel as part of this write
 *			operation, or NULL.
 *	param error	An errno condition for the write operation or zero
 *			if the write was successful.
 */
@available(iOS 5.0, *)
func __dispatch_io_write(_ channel: DispatchIO, _ offset: off_t, _ data: __DispatchData, _ queue: DispatchQueue, _ io_handler: @escaping (Bool, __DispatchData?, Int32) -> Void)
var DISPATCH_IO_STOP: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_io_close_flags_t = UInt

/**
 * @function dispatch_io_close
 * Close the specified I/O channel to new read or write operations; scheduling
 * operations on a closed channel results in their handler returning an error.
 *
 * If the DISPATCH_IO_STOP flag is provided, the system will make a best effort
 * to interrupt any outstanding read and write operations on the I/O channel,
 * otherwise those operations will run to completion normally.
 * Partial results of read and write operations may be returned even after a
 * channel is closed with the DISPATCH_IO_STOP flag.
 * The final invocation of an I/O handler of an interrupted operation will be
 * passed an ECANCELED error code, as will the I/O handler of an operation
 * scheduled on a closed channel.
 *
 * @param channel	The dispatch I/O channel to close.
 * @param flags		The flags for the close operation.
 */
@available(iOS 5.0, *)
func __dispatch_io_close(_ channel: DispatchIO, _ flags: UInt)

/**
 * @function dispatch_io_barrier
 * Schedule a barrier operation on the specified I/O channel; all previously
 * scheduled operations on the channel will complete before the provided
 * barrier block is enqueued onto the global queue determined by the channel's
 * target queue, and no subsequently scheduled operations will start until the
 * barrier block has returned.
 *
 * If multiple channels are associated with the same file descriptor, a barrier
 * operation scheduled on any of these channels will act as a barrier across all
 * channels in question, i.e. all previously scheduled operations on any of the
 * channels will complete before the barrier block is enqueued, and no
 * operations subsequently scheduled on any of the channels will start until the
 * barrier block has returned.
 *
 * While the barrier block is running, it may safely operate on the channel's
 * underlying file descriptor with fsync(2), lseek(2) etc. (but not close(2)).
 *
 * @param channel	The dispatch I/O channel to schedule the barrier on.
 * @param barrier	The barrier block.
 */
@available(iOS 5.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchIO.barrier(self:execute:)")
func dispatch_io_barrier(_ channel: DispatchIO, _ barrier: @escaping () -> Void)

/**
 * @function dispatch_io_get_descriptor
 * Returns the file descriptor underlying a dispatch I/O channel.
 *
 * Will return -1 for a channel closed with dispatch_io_close() and for a
 * channel associated with a path name that has not yet been open(2)ed.
 *
 * If called from a barrier block scheduled on a channel associated with a path
 * name that has not yet been open(2)ed, this will trigger the channel open(2)
 * operation and return the resulting file descriptor.
 *
 * @param channel	The dispatch I/O channel to query.
 * @result		The file descriptor underlying the channel, or -1.
 */
@available(iOS 5.0, *)
@available(swift, obsoleted: 3, renamed: "getter:DispatchIO.fileDescriptor(self:)")
func dispatch_io_get_descriptor(_ channel: DispatchIO) -> Int32

/**
 * @function dispatch_io_set_high_water
 * Set a high water mark on the I/O channel for all operations.
 *
 * The system will make a best effort to enqueue I/O handlers with partial
 * results as soon the number of bytes processed by an operation (i.e. read or
 * written) reaches the high water mark.
 *
 * The size of data objects passed to I/O handlers for this channel will never
 * exceed the specified high water mark.
 *
 * The default value for the high water mark is unlimited (i.e. SIZE_MAX).
 *
 * @param channel	The dispatch I/O channel on which to set the policy.
 * @param high_water	The number of bytes to use as a high water mark.
 */
@available(iOS 5.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchIO.setLimit(self:highWater:)")
func dispatch_io_set_high_water(_ channel: DispatchIO, _ high_water: Int)

/**
 * @function dispatch_io_set_low_water
 * Set a low water mark on the I/O channel for all operations.
 *
 * The system will process (i.e. read or write) at least the low water mark
 * number of bytes for an operation before enqueueing I/O handlers with partial
 * results.
 *
 * The size of data objects passed to intermediate I/O handler invocations for
 * this channel (i.e. excluding the final invocation) will never be smaller than
 * the specified low water mark, except if the channel has an interval with the
 * DISPATCH_IO_STRICT_INTERVAL flag set or if EOF or an error was encountered.
 *
 * I/O handlers should be prepared to receive amounts of data significantly
 * larger than the low water mark in general. If an I/O handler requires
 * intermediate results of fixed size, set both the low and and the high water
 * mark to that size.
 *
 * The default value for the low water mark is unspecified, but must be assumed
 * to be such that intermediate handler invocations may occur.
 * If I/O handler invocations with partial results are not desired, set the
 * low water mark to SIZE_MAX.
 *
 * @param channel	The dispatch I/O channel on which to set the policy.
 * @param low_water	The number of bytes to use as a low water mark.
 */
@available(iOS 5.0, *)
@available(swift, obsoleted: 3, renamed: "DispatchIO.setLimit(self:lowWater:)")
func dispatch_io_set_low_water(_ channel: DispatchIO, _ low_water: Int)
var DISPATCH_IO_STRICT_INTERVAL: Int32 { get }
@available(*, unavailable, message: "Not available in Swift")
typealias dispatch_io_interval_flags_t = UInt

/**
 * @function dispatch_io_set_interval
 * Set a nanosecond interval at which I/O handlers are to be enqueued on the
 * I/O channel for all operations.
 *
 * This allows an application to receive periodic feedback on the progress of
 * read and write operations, e.g. for the purposes of displaying progress bars.
 *
 * If the amount of data ready to be delivered to an I/O handler at the interval
 * is inferior to the channel low water mark, the handler will only be enqueued
 * if the DISPATCH_IO_STRICT_INTERVAL flag is set.
 *
 * Note that the system may defer enqueueing interval I/O handlers by a small
 * unspecified amount of leeway in order to align with other system activity for
 * improved system performance or power consumption.
 *
 * @param channel	The dispatch I/O channel on which to set the policy.
 * @param interval	The interval in nanoseconds at which delivery of the I/O
 *					handler is desired.
 * @param flags		Flags indicating desired data delivery behavior at
 *					interval time.
 */
@available(iOS 5.0, *)
func __dispatch_io_set_interval(_ channel: DispatchIO, _ interval: UInt64, _ flags: UInt)
class OS_dispatch_workloop : DispatchQueue {
  @available(*, unavailable, message: "Unavailable in Swift")
  init()
}
typealias dispatch_workloop_t = OS_dispatch_workloop

/**
 * @function dispatch_workloop_create
 *
 * @abstract
 * Creates a new dispatch workloop to which workitems may be submitted.
 *
 * @param label
 * A string label to attach to the workloop.
 *
 * @result
 * The newly created dispatch workloop.
 */
@available(iOS 12.0, *)
func dispatch_workloop_create(_ label: UnsafePointer<CChar>?) -> dispatch_workloop_t

/**
 * @function dispatch_workloop_create_inactive
 *
 * @abstract
 * Creates a new inactive dispatch workloop that can be setup and then
 * activated.
 *
 * @discussion
 * Creating an inactive workloop allows for it to receive further configuration
 * before it is activated, and workitems can be submitted to it.
 *
 * Submitting workitems to an inactive workloop is undefined and will cause the
 * process to be terminated.
 *
 * @param label
 * A string label to attach to the workloop.
 *
 * @result
 * The newly created dispatch workloop.
 */
@available(iOS 12.0, *)
func dispatch_workloop_create_inactive(_ label: UnsafePointer<CChar>?) -> dispatch_workloop_t

/**
 * @function dispatch_workloop_set_autorelease_frequency
 *
 * @abstract
 * Sets the autorelease frequency of the workloop.
 *
 * @discussion
 * See dispatch_queue_attr_make_with_autorelease_frequency().
 * The default policy for a workloop is
 * DISPATCH_AUTORELEASE_FREQUENCY_WORK_ITEM.
 *
 * @param workloop
 * The dispatch workloop to modify.
 *
 * This workloop must be inactive, passing an activated object is undefined
 * and will cause the process to be terminated.
 *
 * @param frequency
 * The requested autorelease frequency.
 */
@available(iOS 12.0, *)
func dispatch_workloop_set_autorelease_frequency(_ workloop: dispatch_workloop_t, _ frequency: __dispatch_autorelease_frequency_t)

/**
  * @function dispatch_workloop_set_os_workgroup
  *
  * @abstract
  * Associates an os_workgroup_t with the specified dispatch workloop.
  *
  * The worker thread will be a member of the specified os_workgroup_t while executing
  * work items submitted to the workloop.
  *
  * @param workloop
  * The dispatch workloop to modify.
  *
  * This workloop must be inactive, passing an activated object is undefined
  * and will cause the process to be terminated.
  *
  * @param workgroup
  * The workgroup to associate with this workloop.
  *
  * The workgroup specified is retained and the previously associated workgroup
  * (if any) is released.
  */
@available(iOS 14.0, *)
func dispatch_workloop_set_os_workgroup(_ workloop: dispatch_workloop_t, _ workgroup: os_workgroup_t)
func + (time: DispatchTime, interval: DispatchTimeInterval) -> DispatchTime

func + (time: DispatchTime, seconds: Double) -> DispatchTime

func + (time: DispatchWallTime, interval: DispatchTimeInterval) -> DispatchWallTime

func + (time: DispatchWallTime, seconds: Double) -> DispatchWallTime

func - (time: DispatchTime, interval: DispatchTimeInterval) -> DispatchTime

func - (time: DispatchTime, seconds: Double) -> DispatchTime

func - (time: DispatchWallTime, interval: DispatchTimeInterval) -> DispatchWallTime

func - (time: DispatchWallTime, seconds: Double) -> DispatchWallTime

@available(*, unavailable, renamed: "DispatchIO.StreamType.random")
var DISPATCH_IO_RANDOM: Int { get }

@available(*, unavailable, renamed: "DispatchIO.CloseFlags.stop")
var DISPATCH_IO_STOP: Int { get }

@available(*, unavailable, renamed: "DispatchIO.StreamType.stream")
var DISPATCH_IO_STREAM: Int { get }

@available(*, unavailable, renamed: "DispatchIO.IntervalFlags.strictInterval")
var DISPATCH_IO_STRICT_INTERVAL: Int { get }

@available(*, unavailable, renamed: "DispatchSource.MachSendEvent.dead")
var DISPATCH_MACH_SEND_DEAD: Int { get }

@available(*, unavailable, renamed: "DispatchSource.MemoryPressureEvent.critical")
var DISPATCH_MEMORYPRESSURE_CRITICAL: Int { get }

@available(*, unavailable, renamed: "DispatchSource.MemoryPressureEvent.normal")
var DISPATCH_MEMORYPRESSURE_NORMAL: Int { get }

@available(*, unavailable, renamed: "DispatchSource.MemoryPressureEvent.warning")
var DISPATCH_MEMORYPRESSURE_WARN: Int { get }

@available(*, unavailable, renamed: "DispatchSource.ProcessEvent.exec")
var DISPATCH_PROC_EXEC: Int { get }

@available(*, unavailable, renamed: "DispatchSource.ProcessEvent.exit")
var DISPATCH_PROC_EXIT: Int { get }

@available(*, unavailable, renamed: "DispatchSource.ProcessEvent.fork")
var DISPATCH_PROC_FORK: Int { get }

@available(*, unavailable, renamed: "DispatchSource.ProcessEvent.signal")
var DISPATCH_PROC_SIGNAL: Int { get }

@available(*, unavailable, renamed: "DispatchQueue.GlobalQueuePriority.background")
var DISPATCH_QUEUE_PRIORITY_BACKGROUND: Int { get }

@available(*, unavailable, renamed: "DispatchQueue.GlobalQueuePriority.default")
var DISPATCH_QUEUE_PRIORITY_DEFAULT: Int { get }

@available(*, unavailable, renamed: "DispatchQueue.GlobalQueuePriority.high")
var DISPATCH_QUEUE_PRIORITY_HIGH: Int { get }

@available(*, unavailable, renamed: "DispatchQueue.GlobalQueuePriority.low")
var DISPATCH_QUEUE_PRIORITY_LOW: Int { get }

@available(*, unavailable, renamed: "DispatchSource.TimerFlags.strict")
var DISPATCH_TIMER_STRICT: Int { get }

@available(*, unavailable, renamed: "DispatchTime.distantFuture")
var DISPATCH_TIME_FOREVER: Int { get }

@available(*, unavailable, renamed: "DispatchTime.now()")
var DISPATCH_TIME_NOW: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.attrib")
var DISPATCH_VNODE_ATTRIB: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.delete")
var DISPATCH_VNODE_DELETE: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.extend")
var DISPATCH_VNODE_EXTEND: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.funlock")
var DISPATCH_VNODE_FUNLOCK: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.link")
var DISPATCH_VNODE_LINK: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.rename")
var DISPATCH_VNODE_RENAME: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.revoke")
var DISPATCH_VNODE_REVOKE: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.write")
var DISPATCH_VNODE_WRITE: Int { get }

struct DispatchData : RandomAccessCollection, _ObjectiveCBridgeable {
  typealias Iterator = DispatchDataIterator
  typealias Index = Int
  typealias Indices = DefaultIndices<DispatchData>
  static let empty: DispatchData
  enum Deallocator {
    /// Use `free`
    case free
    /// Use `munmap`
    case unmap
    /// A custom deallocator
    case custom(DispatchQueue?, @convention(block) () -> Void)
  }
  /// Initialize a `Data` with copied memory content.
  ///
  /// - parameter bytes: A pointer to the memory. It will be copied.
  /// - parameter count: The number of bytes to copy.
  @available(swift, deprecated: 4, message: "Use init(bytes: UnsafeRawBufferPointer) instead")
  init(bytes buffer: UnsafeBufferPointer<UInt8>)
  /// Initialize a `Data` with copied memory content.
  ///
  /// - parameter bytes: A pointer to the memory. It will be copied.
  /// - parameter count: The number of bytes to copy.
  init(bytes buffer: UnsafeRawBufferPointer)
  /// Initialize a `Data` without copying the bytes.
  ///
  /// - parameter bytes: A pointer to the bytes.
  /// - parameter count: The size of the bytes.
  /// - parameter deallocator: Specifies the mechanism to free the indicated buffer.
  @available(swift, deprecated: 4, message: "Use init(bytesNoCopy: UnsafeRawBufferPointer, deallocater: Deallocator) instead")
  init(bytesNoCopy bytes: UnsafeBufferPointer<UInt8>, deallocator: DispatchData.Deallocator = .free)
  /// Initialize a `Data` without copying the bytes.
  ///
  /// - parameter bytes: A pointer to the bytes.
  /// - parameter count: The size of the bytes.
  /// - parameter deallocator: Specifies the mechanism to free the indicated buffer.
  init(bytesNoCopy bytes: UnsafeRawBufferPointer, deallocator: DispatchData.Deallocator = .free)
  var count: Int { get }
  func withUnsafeBytes<Result, ContentType>(body: (UnsafePointer<ContentType>) throws -> Result) rethrows -> Result
  @available(swift 4.2)
  func enumerateBytes(_ block: (_ buffer: UnsafeBufferPointer<UInt8>, _ byteIndex: Int, _ stop: inout Bool) -> Void)
  @available(swift, obsoleted: 4.2, renamed: "enumerateBytes(_:)")
  func enumerateBytes(block: (_ buffer: UnsafeBufferPointer<UInt8>, _ byteIndex: Int, _ stop: inout Bool) -> Void)
  /// Append bytes to the data.
  ///
  /// - parameter bytes: A pointer to the bytes to copy in to the data.
  /// - parameter count: The number of bytes to copy.
  @available(swift, deprecated: 4, message: "Use append(_: UnsafeRawBufferPointer) instead")
  mutating func append(_ bytes: UnsafePointer<UInt8>, count: Int)
  /// Append bytes to the data.
  ///
  /// - parameter bytes: A pointer to the bytes to copy in to the data.
  /// - parameter count: The number of bytes to copy.
  mutating func append(_ bytes: UnsafeRawBufferPointer)
  /// Append data to the data.
  ///
  /// - parameter data: The data to append to this data.
  mutating func append(_ other: DispatchData)
  /// Append a buffer of bytes to the data.
  ///
  /// - parameter buffer: The buffer of bytes to append. The size is calculated from `SourceType` and `buffer.count`.
  mutating func append<SourceType>(_ buffer: UnsafeBufferPointer<SourceType>)
  /// Copy the contents of the data to a pointer.
  ///
  /// - parameter pointer: A pointer to the buffer you wish to copy the bytes into.
  /// - parameter count: The number of bytes to copy.
  /// - warning: This method does not verify that the contents at pointer have enough space to hold `count` bytes.
  @available(swift, deprecated: 4, message: "Use copyBytes(to: UnsafeMutableRawBufferPointer, count: Int) instead")
  func copyBytes(to pointer: UnsafeMutablePointer<UInt8>, count: Int)
  /// Copy the contents of the data to a pointer.
  ///
  /// - parameter pointer: A pointer to the buffer you wish to copy the bytes into. The buffer must be large
  ///	enough to hold `count` bytes.
  /// - parameter count: The number of bytes to copy.
  func copyBytes(to pointer: UnsafeMutableRawBufferPointer, count: Int)
  /// Copy a subset of the contents of the data to a pointer.
  ///
  /// - parameter pointer: A pointer to the buffer you wish to copy the bytes into.
  /// - parameter range: The range in the `Data` to copy.
  /// - warning: This method does not verify that the contents at pointer have enough space to hold the required number of bytes.
  @available(swift, deprecated: 4, message: "Use copyBytes(to: UnsafeMutableRawBufferPointer, from: Range<Index>) instead")
  func copyBytes(to pointer: UnsafeMutablePointer<UInt8>, from range: Range<DispatchData.Index>)
  /// Copy a subset of the contents of the data to a pointer.
  ///
  /// - parameter pointer: A pointer to the buffer you wish to copy the bytes into. The buffer must be large
  ///	enough to hold `count` bytes.
  /// - parameter range: The range in the `Data` to copy.
  func copyBytes(to pointer: UnsafeMutableRawBufferPointer, from range: Range<DispatchData.Index>)
  /// Copy the contents of the data into a buffer.
  ///
  /// This function copies the bytes in `range` from the data into the buffer. If the count of the `range` is greater than `MemoryLayout<DestinationType>.stride * buffer.count` then the first N bytes will be copied into the buffer.
  /// - precondition: The range must be within the bounds of the data. Otherwise `fatalError` is called.
  /// - parameter buffer: A buffer to copy the data into.
  /// - parameter range: A range in the data to copy into the buffer. If the range is empty, this function will return 0 without copying anything. If the range is nil, as much data as will fit into `buffer` is copied.
  /// - returns: Number of bytes copied into the destination buffer.
  func copyBytes<DestinationType>(to buffer: UnsafeMutableBufferPointer<DestinationType>, from range: Range<DispatchData.Index>? = nil) -> Int
  /// Sets or returns the byte at the specified index.
  subscript(index: DispatchData.Index) -> UInt8 { get }
  subscript(bounds: Range<Int>) -> Slice<DispatchData> { get }
  /// Return a new copy of the data in a specified range.
  ///
  /// - parameter range: The range to copy.
  func subdata(in range: Range<DispatchData.Index>) -> DispatchData
  func region(location: Int) -> (data: DispatchData, offset: Int)
  var startIndex: DispatchData.Index { get }
  var endIndex: DispatchData.Index { get }
  func index(before i: DispatchData.Index) -> DispatchData.Index
  func index(after i: DispatchData.Index) -> DispatchData.Index
  /// An iterator over the contents of the data.
  ///
  /// The iterator will increment byte-by-byte.
  func makeIterator() -> DispatchData.Iterator
  typealias Element = UInt8
  typealias SubSequence = Slice<DispatchData>
  typealias _ObjectiveCType = __DispatchData
}

extension DispatchData {
  @_semantics("convertToObjectiveC") func _bridgeToObjectiveC() -> __DispatchData
  static func _forceBridgeFromObjectiveC(_ input: __DispatchData, result: inout DispatchData?)
  static func _conditionallyBridgeFromObjectiveC(_ input: __DispatchData, result: inout DispatchData?) -> Bool
  @_effects(readonly) static func _unconditionallyBridgeFromObjectiveC(_ source: __DispatchData?) -> DispatchData
}

struct DispatchDataIterator : IteratorProtocol, Sequence {
  typealias Element = UInt8
  /// Create an iterator over the given DispatchData
  init(_data: DispatchData)
  /// Advance to the next element and return it, or `nil` if no next
  /// element exists.
  mutating func next() -> DispatchData.Element?
  typealias Iterator = DispatchDataIterator
}

/// dispatch_assert
@available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
enum DispatchPredicate {
  case onQueue(DispatchQueue)
  case onQueueAsBarrier(DispatchQueue)
  case notOnQueue(DispatchQueue)
}

/// qos_class_t
struct DispatchQoS : Equatable {
  let qosClass: DispatchQoS.QoSClass
  let relativePriority: Int
  @available(macOS 10.10, iOS 8.0, *)
  static let background: DispatchQoS
  @available(macOS 10.10, iOS 8.0, *)
  static let utility: DispatchQoS
  @available(macOS 10.10, iOS 8.0, *)
  static let `default`: DispatchQoS
  @available(macOS 10.10, iOS 8.0, *)
  static let userInitiated: DispatchQoS
  @available(macOS 10.10, iOS 8.0, *)
  static let userInteractive: DispatchQoS
  static let unspecified: DispatchQoS
  enum QoSClass {
    @available(macOS 10.10, iOS 8.0, *)
    case background
    @available(macOS 10.10, iOS 8.0, *)
    case utility
    @available(macOS 10.10, iOS 8.0, *)
    case `default`
    @available(macOS 10.10, iOS 8.0, *)
    case userInitiated
    @available(macOS 10.10, iOS 8.0, *)
    case userInteractive
    case unspecified
    @available(macOS 10.10, iOS 8.0, *)
    init?(rawValue: qos_class_t)
    @available(macOS 10.10, iOS 8.0, *)
    var rawValue: qos_class_t { get }
    static func == (a: DispatchQoS.QoSClass, b: DispatchQoS.QoSClass) -> Bool
    func hash(into hasher: inout Hasher)
    var hashValue: Int { get }
  }
  init(qosClass: DispatchQoS.QoSClass, relativePriority: Int)
  static func == (a: DispatchQoS, b: DispatchQoS) -> Bool
}

extension DispatchQoS.QoSClass : Equatable {
}

extension DispatchQoS.QoSClass : Hashable {
}

final class DispatchSpecificKey<T> {
  init()
}

struct DispatchTime : Comparable {
  let rawValue: dispatch_time_t
  static func now() -> DispatchTime
  static let distantFuture: DispatchTime
  /// Creates a `DispatchTime` relative to the system clock that
  /// ticks since boot.
  ///
  /// - Parameters:
  ///   - uptimeNanoseconds: The number of nanoseconds since boot, excluding
  ///                        time the system spent asleep
  /// - Returns: A new `DispatchTime`
  /// - Discussion: This clock is the same as the value returned by
  ///               `mach_absolute_time` when converted into nanoseconds.
  ///               On some platforms, the nanosecond value is rounded up to a
  ///               multiple of the Mach timebase, using the conversion factors
  ///               returned by `mach_timebase_info()`. The nanosecond equivalent
  ///               of the rounded result can be obtained by reading the
  ///               `uptimeNanoseconds` property.
  ///               Note that `DispatchTime(uptimeNanoseconds: 0)` is
  ///               equivalent to `DispatchTime.now()`, that is, its value
  ///               represents the number of nanoseconds since boot (excluding
  ///               system sleep time), not zero nanoseconds since boot.
  init(uptimeNanoseconds: UInt64)
  var uptimeNanoseconds: UInt64 { get }
}

extension DispatchTime {
  static func < (a: DispatchTime, b: DispatchTime) -> Bool
  static func == (a: DispatchTime, b: DispatchTime) -> Bool
}

@available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
extension DispatchTime {
  func distance(to other: DispatchTime) -> DispatchTimeInterval
  func advanced(by n: DispatchTimeInterval) -> DispatchTime
}

/// Represents a time interval that can be used as an offset from a `DispatchTime`
/// or `DispatchWallTime`.
///
/// For example:
///		let inOneSecond = DispatchTime.now() + DispatchTimeInterval.seconds(1)
///
///	If the requested time interval is larger then the internal representation
/// permits, the result of adding it to a `DispatchTime` or `DispatchWallTime`
/// is `DispatchTime.distantFuture` and `DispatchWallTime.distantFuture`
/// respectively. Such time intervals compare as equal:
///
///		let t1 = DispatchTimeInterval.seconds(Int.max)
///		let t2 = DispatchTimeInterval.milliseconds(Int.max)
///		let result = t1 == t2   // true
enum DispatchTimeInterval : Equatable {
  case seconds(Int)
  case milliseconds(Int)
  case microseconds(Int)
  case nanoseconds(Int)
  case never
  static func == (lhs: DispatchTimeInterval, rhs: DispatchTimeInterval) -> Bool
}

/// 
@frozen enum DispatchTimeoutResult {
  case success
  case timedOut
  static func == (a: DispatchTimeoutResult, b: DispatchTimeoutResult) -> Bool
  func hash(into hasher: inout Hasher)
  var hashValue: Int { get }
}

extension DispatchTimeoutResult : Equatable {
}

extension DispatchTimeoutResult : Hashable {
}

extension DispatchTimeoutResult : Sendable {
}

struct DispatchWallTime : Comparable {
  let rawValue: dispatch_time_t
  static func now() -> DispatchWallTime
  static let distantFuture: DispatchWallTime
  init(timespec: timespec)
}

extension DispatchWallTime {
  static func < (a: DispatchWallTime, b: DispatchWallTime) -> Bool
  static func == (a: DispatchWallTime, b: DispatchWallTime) -> Bool
}

@available(macOS 10.10, iOS 8.0, *)
class DispatchWorkItem {
  init(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], block: @escaping @convention(block) () -> Void)
  @available(macOS 11.3, iOS 14.5, watchOS 7.4, tvOS 14.5, *)
  init(flags: DispatchWorkItemFlags = [], block: @escaping @convention(block) () -> Void)
  func perform()
  func wait()
  func wait(timeout: DispatchTime) -> DispatchTimeoutResult
  func wait(wallTimeout: DispatchWallTime) -> DispatchTimeoutResult
  func notify(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], queue: DispatchQueue, execute: @escaping @convention(block) () -> Void)
  func notify(queue: DispatchQueue, execute: DispatchWorkItem)
  func cancel()
  var isCancelled: Bool { get }
}

struct DispatchWorkItemFlags : OptionSet, RawRepresentable {
  let rawValue: UInt
  init(rawValue: UInt)
  static let barrier: DispatchWorkItemFlags
  @available(macOS 10.10, iOS 8.0, *)
  static let detached: DispatchWorkItemFlags
  @available(macOS 10.10, iOS 8.0, *)
  static let assignCurrentContext: DispatchWorkItemFlags
  @available(macOS 10.10, iOS 8.0, *)
  static let noQoS: DispatchWorkItemFlags
  @available(macOS 10.10, iOS 8.0, *)
  static let inheritQoS: DispatchWorkItemFlags
  @available(macOS 10.10, iOS 8.0, *)
  static let enforceQoS: DispatchWorkItemFlags
  typealias ArrayLiteralElement = DispatchWorkItemFlags
  typealias Element = DispatchWorkItemFlags
  typealias RawValue = UInt
}

@available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
func _dispatchPreconditionTest(_ condition: DispatchPredicate) -> Bool

@available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
@_transparent func dispatchPrecondition(condition: @autoclosure () -> DispatchPredicate)

@available(*, unavailable, renamed: "DispatchQueue.asyncAfter(self:deadline:qos:flags:execute:)")
func dispatch_after(_ when: dispatch_time_t, _ queue: DispatchQueue, _ block: () -> Void)

@available(*, unavailable, message: "Use DispatchQueue.concurrentPerform(iterations:execute:). The 'queue' argument is not required because the system chooses the appropriate execution context for the block")
func dispatch_apply(_ iterations: Int, _ queue: DispatchQueue, _ block: (Int) -> Void)

@available(*, unavailable, renamed: "dispatchPrecondition(_:)")
func dispatch_assert_queue(_ queue: DispatchQueue)

@available(*, unavailable, renamed: "dispatchPrecondition(_:)")
func dispatch_assert_queue_barrier(_ queue: DispatchQueue)

@available(*, unavailable, renamed: "dispatchPrecondition(_:)")
func dispatch_assert_queue_not(_ queue: DispatchQueue)

@available(*, unavailable, renamed: "DispatchQueue.async(self:execute:)")
func dispatch_async(_ queue: DispatchQueue, _ block: () -> Void)

@available(*, unavailable, renamed: "DispatchQueue.async(self:group:qos:flags:execute:)")
func dispatch_barrier_async(_ queue: DispatchQueue, _ block: () -> Void)

@available(*, unavailable, renamed: "DispatchQueue.sync(self:flags:execute:)")
func dispatch_barrier_sync(_ queue: DispatchQueue, _ block: () -> Void)

@available(*, unavailable, renamed: "DispatchData.enumerateBytes(self:block:)")
func dispatch_data_apply(_ data: __DispatchData, _ applier: (__DispatchData, Int, UnsafeRawPointer, Int) -> Bool) -> Bool

@available(*, unavailable, renamed: "DispatchData.region(self:location:)")
func dispatch_data_copy_region(_ data: __DispatchData, _ location: Int, _ offset_ptr: UnsafeMutablePointer<Int>) -> __DispatchData

@available(*, unavailable, renamed: "DispatchData.init(bytes:)")
func dispatch_data_create(_ buffer: UnsafeRawPointer, _ size: Int, _ queue: DispatchQueue?, _ destructor: (() -> Void)?) -> __DispatchData

@available(*, unavailable, renamed: "DispatchData.append(self:_:)")
func dispatch_data_create_concat(_ data1: __DispatchData, _ data2: __DispatchData) -> __DispatchData

@available(*, unavailable, renamed: "DispatchData.withUnsafeBytes(self:body:)")
func dispatch_data_create_map(_ data: __DispatchData, _ buffer_ptr: UnsafeMutablePointer<UnsafeRawPointer?>?, _ size_ptr: UnsafeMutablePointer<Int>?) -> __DispatchData

@available(*, unavailable, renamed: "DispatchData.subdata(self:in:)")
func dispatch_data_create_subrange(_ data: __DispatchData, _ offset: Int, _ length: Int) -> __DispatchData

@available(*, unavailable, renamed: "getter:DispatchData.count(self:)")
func dispatch_data_get_size(_ data: __DispatchData) -> Int

@available(*, unavailable, renamed: "DispatchQueue.global(attributes:)")
func dispatch_get_global_queue(_ identifier: Int, _ flags: UInt) -> DispatchQueue

@available(*, unavailable, renamed: "getter:DispatchQueue.main()")
func dispatch_get_main_queue() -> DispatchQueue

@available(*, unavailable, renamed: "DispatchQueue.getSpecific(key:)")
func dispatch_get_specific(_ key: UnsafeRawPointer) -> UnsafeMutableRawPointer?

@available(*, unavailable, renamed: "DispatchQueue.async(self:group:qos:flags:execute:)")
func dispatch_group_async(_ group: DispatchGroup, _ queue: DispatchQueue, _ block: () -> Void)

@available(*, unavailable, renamed: "DispatchGroup.notify(self:qos:flags:queue:execute:)")
func dispatch_group_notify(_ group: DispatchGroup, _ queue: DispatchQueue, _ block: () -> Void)

@available(*, unavailable, renamed: "DispatchGroup.wait(self:timeout:)")
func dispatch_group_wait(_ group: DispatchGroup, _ timeout: dispatch_time_t) -> Int

@available(*, unavailable, renamed: "DispatchIO.close(self:flags:)")
func dispatch_io_close(_ channel: DispatchIO, _ flags: UInt)

@available(*, unavailable, renamed: "DispatchIO.init(type:fileDescriptor:queue:cleanupHandler:)")
func dispatch_io_create(_ type: UInt, _ fd: Int32, _ queue: DispatchQueue, _ cleanup_handler: (Int32) -> Void) -> DispatchIO

@available(*, unavailable, renamed: "DispatchIO.init(type:io:queue:cleanupHandler:)")
func dispatch_io_create_with_io(_ type: UInt, _ io: DispatchIO, _ queue: DispatchQueue, _ cleanup_handler: (Int32) -> Void) -> DispatchIO

@available(*, unavailable, renamed: "DispatchIO.init(type:path:oflag:mode:queue:cleanupHandler:)")
func dispatch_io_create_with_path(_ type: UInt, _ path: UnsafePointer<Int8>, _ oflag: Int32, _ mode: mode_t, _ queue: DispatchQueue, _ cleanup_handler: (Int32) -> Void) -> DispatchIO

@available(*, unavailable, renamed: "DispatchIO.setInterval(self:interval:flags:)")
func dispatch_io_set_interval(_ channel: DispatchIO, _ interval: UInt64, _ flags: UInt)

@available(*, unavailable, renamed: "DispatchQueue.Attributes.initiallyInactive")
func dispatch_queue_attr_make_initially_inactive(_ attr: __OS_dispatch_queue_attr?) -> __OS_dispatch_queue_attr

@available(*, unavailable, renamed: "DispatchQueue.AutoreleaseFrequency.workItem")
func dispatch_queue_attr_make_with_autorelease_frequency(_ attr: __OS_dispatch_queue_attr?, _ frequency: __dispatch_autorelease_frequency_t) -> __OS_dispatch_queue_attr

@available(*, unavailable, renamed: "DispatchQoS")
func dispatch_queue_attr_make_with_qos_class(_ attr: __OS_dispatch_queue_attr?, _ qos_class: qos_class_t, _ relative_priority: Int32) -> __OS_dispatch_queue_attr

@available(*, unavailable, renamed: "DispatchQueue.init(label:qos:attributes:autoreleaseFrequency:target:)")
func dispatch_queue_create(_ label: UnsafePointer<Int8>?, _ attr: __OS_dispatch_queue_attr?) -> DispatchQueue

@available(*, unavailable, renamed: "DispatchQueue.init(label:qos:attributes:autoreleaseFrequency:target:)")
func dispatch_queue_create_with_target(_ label: UnsafePointer<Int8>?, _ attr: __OS_dispatch_queue_attr?, _ queue: DispatchQueue?) -> DispatchQueue

@available(*, unavailable, renamed: "getter:DispatchQueue.label(self:)")
func dispatch_queue_get_label(_ queue: DispatchQueue?) -> UnsafePointer<Int8>

@available(*, unavailable, renamed: "getter:DispatchQueue.qos(self:)")
func dispatch_queue_get_qos_class(_ queue: DispatchQueue, _ relative_priority_ptr: UnsafeMutablePointer<Int32>?) -> qos_class_t

@available(*, unavailable, renamed: "DispatchQueue.getSpecific(self:key:)")
func dispatch_queue_get_specific(_ queue: DispatchQueue, _ key: UnsafeRawPointer) -> UnsafeMutableRawPointer?

@available(*, unavailable, renamed: "DispatchQueue.setSpecific(self:key:value:)")
func dispatch_queue_set_specific(_ queue: DispatchQueue, _ key: UnsafeRawPointer, _ context: UnsafeMutableRawPointer?, _ destructor: (@convention(c) (UnsafeMutableRawPointer?) -> Void)?)

@available(*, unavailable, renamed: "DispatchIO.read(fileDescriptor:length:queue:handler:)")
func dispatch_read(_ fd: Int32, _ length: Int, _ queue: DispatchQueue, _ handler: (__DispatchData, Int32) -> Void)

@available(*, unavailable, renamed: "DispatchSemaphore.signal(self:)")
func dispatch_semaphore_signal(_ dsema: DispatchSemaphore) -> Int

@available(*, unavailable, renamed: "DispatchSemaphore.wait(self:timeout:)")
func dispatch_semaphore_wait(_ dsema: DispatchSemaphore, _ timeout: dispatch_time_t) -> Int

@available(*, unavailable, renamed: "DispatchSource.cancel(self:)")
func dispatch_source_cancel(_ source: DispatchSource)

@available(*, unavailable, message: "Use DispatchSource class methods")
func dispatch_source_create(_ type: __dispatch_source_type_t, _ handle: UInt, _ mask: UInt, _ queue: DispatchQueue?) -> DispatchSource

@available(*, unavailable, renamed: "getter:DispatchSource.data(self:)")
func dispatch_source_get_data(_ source: DispatchSource) -> UInt

@available(*, unavailable, renamed: "getter:DispatchSource.handle(self:)")
func dispatch_source_get_handle(_ source: DispatchSource) -> UInt

@available(*, unavailable, renamed: "getter:DispatchSource.mask(self:)")
func dispatch_source_get_mask(_ source: DispatchSource) -> UInt

@available(*, unavailable, renamed: "DispatchUserDataAdd.mergeData(self:value:)")
func dispatch_source_merge_data(_ source: DispatchSource, _ value: UInt)

@available(*, unavailable, renamed: "DispatchSource.setCancelHandler(self:handler:)")
func dispatch_source_set_cancel_handler(_ source: DispatchSource, _ handler: (() -> Void)?)

@available(*, unavailable, renamed: "DispatchSource.setEventHandler(self:handler:)")
func dispatch_source_set_event_handler(_ source: DispatchSource, _ handler: (() -> Void)?)

@available(*, unavailable, renamed: "DispatchSource.setRegistrationHandler(self:handler:)")
func dispatch_source_set_registration_handler(_ source: DispatchSource, _ handler: (() -> Void)?)

@available(*, unavailable, renamed: "DispatchTimerSource.setTimer(self:start:interval:leeway:)")
func dispatch_source_set_timer(_ source: DispatchSource, _ start: dispatch_time_t, _ interval: UInt64, _ leeway: UInt64)

@available(*, unavailable, renamed: "getter:DispatchSource.isCancelled(self:)")
func dispatch_source_testcancel(_ source: DispatchSource) -> Int

@available(*, unavailable, renamed: "DispatchTime.now()")
func dispatch_time(_ when: dispatch_time_t, _ delta: Int64) -> dispatch_time_t

@available(*, unavailable, renamed: "DispatchWalltime.init(time:)")
func dispatch_walltime(_ when: UnsafePointer<timespec>?, _ delta: Int64) -> dispatch_time_t

extension DispatchQueue {
  struct Attributes : OptionSet {
    let rawValue: UInt64
    init(rawValue: UInt64)
    static let concurrent: DispatchQueue.Attributes
    @available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
    static let initiallyInactive: DispatchQueue.Attributes
    typealias ArrayLiteralElement = DispatchQueue.Attributes
    typealias Element = DispatchQueue.Attributes
    typealias RawValue = UInt64
  }
  enum GlobalQueuePriority {
    @available(macOS, deprecated: 10.10, message: "Use qos attributes instead")
    @available(iOS, deprecated: 8.0, message: "Use qos attributes instead")
    @available(tvOS, deprecated, message: "Use qos attributes instead")
    @available(watchOS, deprecated, message: "Use qos attributes instead")
    case high
    @available(macOS, deprecated: 10.10, message: "Use qos attributes instead")
    @available(iOS, deprecated: 8.0, message: "Use qos attributes instead")
    @available(tvOS, deprecated, message: "Use qos attributes instead")
    @available(watchOS, deprecated, message: "Use qos attributes instead")
    case `default`
    @available(macOS, deprecated: 10.10, message: "Use qos attributes instead")
    @available(iOS, deprecated: 8.0, message: "Use qos attributes instead")
    @available(tvOS, deprecated, message: "Use qos attributes instead")
    @available(watchOS, deprecated, message: "Use qos attributes instead")
    case low
    @available(macOS, deprecated: 10.10, message: "Use qos attributes instead")
    @available(iOS, deprecated: 8.0, message: "Use qos attributes instead")
    @available(tvOS, deprecated, message: "Use qos attributes instead")
    @available(watchOS, deprecated, message: "Use qos attributes instead")
    case background
    static func == (a: DispatchQueue.GlobalQueuePriority, b: DispatchQueue.GlobalQueuePriority) -> Bool
    func hash(into hasher: inout Hasher)
    var hashValue: Int { get }
  }
  enum AutoreleaseFrequency {
    case inherit
    @available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
    case workItem
    @available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
    case never
    static func == (a: DispatchQueue.AutoreleaseFrequency, b: DispatchQueue.AutoreleaseFrequency) -> Bool
    func hash(into hasher: inout Hasher)
    var hashValue: Int { get }
  }
  class func concurrentPerform(iterations: Int, execute work: (Int) -> Void)
  class var main: DispatchQueue { get }
  @available(macOS, deprecated: 10.10)
  @available(iOS, deprecated: 8.0)
  @available(tvOS, deprecated)
  @available(watchOS, deprecated)
  class func global(priority: DispatchQueue.GlobalQueuePriority) -> DispatchQueue
  @available(macOS 10.10, iOS 8.0, *)
  class func global(qos: DispatchQoS.QoSClass = .default) -> DispatchQueue
  class func getSpecific<T>(key: DispatchSpecificKey<T>) -> T?
  convenience init(label: String, qos: DispatchQoS = .unspecified, attributes: DispatchQueue.Attributes = [], autoreleaseFrequency: DispatchQueue.AutoreleaseFrequency = .inherit, target: DispatchQueue? = nil)
  var label: String { get }
  ///
  /// Submits a block for synchronous execution on this queue.
  ///
  /// Submits a work item to a dispatch queue like `async(execute:)`, however
  /// `sync(execute:)` will not return until the work item has finished.
  ///
  /// Work items submitted to a queue with `sync(execute:)` do not observe certain
  /// queue attributes of that queue when invoked (such as autorelease frequency
  /// and QoS class).
  ///
  /// Calls to `sync(execute:)` targeting the current queue will result
  /// in deadlock. Use of `sync(execute:)` is also subject to the same
  /// multi-party deadlock problems that may result from the use of a mutex.
  /// Use of `async(execute:)` is preferred.
  ///
  /// As an optimization, `sync(execute:)` invokes the work item on the thread which
  /// submitted it, except when the queue is the main queue or
  /// a queue targetting it.
  ///
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `async(execute:)`
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func sync(execute workItem: DispatchWorkItem)
  ///
  /// Submits a work item for asynchronous execution on a dispatch queue.
  ///
  /// `async(execute:)` is the fundamental mechanism for submitting
  /// work items to a dispatch queue.
  ///
  /// Calls to `async(execute:)` always return immediately after the work item has
  /// been submitted, and never wait for the work item to be invoked.
  ///
  /// The target queue determines whether the work item will be invoked serially or
  /// concurrently with respect to other work items submitted to that same queue.
  /// Serial queues are processed concurrently with respect to each other.
  ///
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `sync(execute:)`
  ///
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func async(execute workItem: DispatchWorkItem)
  @available(macOS 10.14, iOS 12.0, *)
  func asyncAndWait(execute workItem: DispatchWorkItem)
  ///
  /// Submits a work item to a dispatch queue and associates it with the given
  /// dispatch group. The dispatch group may be used to wait for the completion
  /// of the work items it references.
  ///
  /// - parameter group: the dispatch group to associate with the submitted block.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `sync(execute:)`
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func async(group: DispatchGroup, execute workItem: DispatchWorkItem)
  ///
  /// Submits a work item to a dispatch queue and optionally associates it with a
  /// dispatch group. The dispatch group may be used to wait for the completion
  /// of the work items it references.
  ///
  /// - parameter group: the dispatch group to associate with the submitted
  /// work item. If this is `nil`, the work item is not associated with a group.
  /// - parameter flags: flags that control the execution environment of the
  /// - parameter qos: the QoS at which the work item should be executed.
  ///	Defaults to `DispatchQoS.unspecified`.
  /// - parameter flags: flags that control the execution environment of the
  /// work item.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `sync(execute:)`
  /// - SeeAlso: `DispatchQoS`
  /// - SeeAlso: `DispatchWorkItemFlags`
  ///
  func async(group: DispatchGroup? = nil, qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], execute work: @escaping @convention(block) () -> Void)
  ///
  /// Submits a block for synchronous execution on this queue.
  ///
  /// Submits a work item to a dispatch queue like `sync(execute:)`, and returns
  /// the value, of type `T`, returned by that work item.
  ///
  /// - parameter execute: The work item to be invoked on the queue.
  /// - returns the value returned by the work item.
  /// - SeeAlso: `sync(execute:)`
  ///
  func sync<T>(execute work: () throws -> T) rethrows -> T
  ///
  /// Submits a block for synchronous execution on this queue.
  ///
  /// Submits a work item to a dispatch queue like `sync(execute:)`, and returns
  /// the value, of type `T`, returned by that work item.
  ///
  /// - parameter flags: flags that control the execution environment of the
  /// - parameter execute: The work item to be invoked on the queue.
  /// - returns the value returned by the work item.
  /// - SeeAlso: `sync(execute:)`
  /// - SeeAlso: `DispatchWorkItemFlags`
  ///
  func sync<T>(flags: DispatchWorkItemFlags, execute work: () throws -> T) rethrows -> T
  ///
  /// Submits a work item to a dispatch queue for asynchronous execution after
  /// a specified time.
  ///
  /// - parameter: deadline the time after which the work item should be executed,
  /// given as a `DispatchTime`.
  /// - parameter qos: the QoS at which the work item should be executed.
  ///	Defaults to `DispatchQoS.unspecified`.
  /// - parameter flags: flags that control the execution environment of the
  /// work item.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `async(execute:)`
  /// - SeeAlso: `asyncAfter(deadline:execute:)`
  /// - SeeAlso: `DispatchQoS`
  /// - SeeAlso: `DispatchWorkItemFlags`
  /// - SeeAlso: `DispatchTime`
  ///
  func asyncAfter(deadline: DispatchTime, qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], execute work: @escaping @convention(block) () -> Void)
  ///
  /// Submits a work item to a dispatch queue for asynchronous execution after
  /// a specified time.
  ///
  /// - parameter: deadline the time after which the work item should be executed,
  /// given as a `DispatchWallTime`.
  /// - parameter qos: the QoS at which the work item should be executed.
  ///	Defaults to `DispatchQoS.unspecified`.
  /// - parameter flags: flags that control the execution environment of the
  /// work item.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `async(execute:)`
  /// - SeeAlso: `asyncAfter(wallDeadline:execute:)`
  /// - SeeAlso: `DispatchQoS`
  /// - SeeAlso: `DispatchWorkItemFlags`
  /// - SeeAlso: `DispatchWallTime`
  ///
  func asyncAfter(wallDeadline: DispatchWallTime, qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], execute work: @escaping @convention(block) () -> Void)
  ///
  /// Submits a work item to a dispatch queue for asynchronous execution after
  /// a specified time.
  ///
  /// - parameter: deadline the time after which the work item should be executed,
  /// given as a `DispatchTime`.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `asyncAfter(deadline:qos:flags:execute:)`
  /// - SeeAlso: `DispatchTime`
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func asyncAfter(deadline: DispatchTime, execute: DispatchWorkItem)
  ///
  /// Submits a work item to a dispatch queue for asynchronous execution after
  /// a specified time.
  ///
  /// - parameter: deadline the time after which the work item should be executed,
  /// given as a `DispatchWallTime`.
  /// - parameter execute: The work item to be invoked on the queue.
  /// - SeeAlso: `asyncAfter(wallDeadline:qos:flags:execute:)`
  /// - SeeAlso: `DispatchTime`
  ///
  @available(macOS 10.10, iOS 8.0, *)
  func asyncAfter(wallDeadline: DispatchWallTime, execute: DispatchWorkItem)
  @available(macOS 10.10, iOS 8.0, *)
  var qos: DispatchQoS { get }
  func getSpecific<T>(key: DispatchSpecificKey<T>) -> T?
  func setSpecific<T>(key: DispatchSpecificKey<T>, value: T?)
}

extension DispatchSourceProtocol {
  typealias DispatchSourceHandler = @convention(block) () -> Void
  func setEventHandler(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], handler: Self.DispatchSourceHandler?)
  @available(macOS 10.10, iOS 8.0, *)
  func setEventHandler(handler: DispatchWorkItem)
  func setCancelHandler(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], handler: Self.DispatchSourceHandler?)
  @available(macOS 10.10, iOS 8.0, *)
  func setCancelHandler(handler: DispatchWorkItem)
  func setRegistrationHandler(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], handler: Self.DispatchSourceHandler?)
  @available(macOS 10.10, iOS 8.0, *)
  func setRegistrationHandler(handler: DispatchWorkItem)
  @available(macOS 10.12, iOS 10.0, tvOS 10.0, watchOS 3.0, *)
  func activate()
  func cancel()
  func resume()
  func suspend()
  var handle: UInt { get }
  var mask: UInt { get }
  var data: UInt { get }
  var isCancelled: Bool { get }
}

extension DispatchSource {
  struct MachSendEvent : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let dead: DispatchSource.MachSendEvent
    typealias ArrayLiteralElement = DispatchSource.MachSendEvent
    typealias Element = DispatchSource.MachSendEvent
    typealias RawValue = UInt
  }
  struct MemoryPressureEvent : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let normal: DispatchSource.MemoryPressureEvent
    static let warning: DispatchSource.MemoryPressureEvent
    static let critical: DispatchSource.MemoryPressureEvent
    static let all: DispatchSource.MemoryPressureEvent
    typealias ArrayLiteralElement = DispatchSource.MemoryPressureEvent
    typealias Element = DispatchSource.MemoryPressureEvent
    typealias RawValue = UInt
  }
  struct ProcessEvent : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let exit: DispatchSource.ProcessEvent
    static let fork: DispatchSource.ProcessEvent
    static let exec: DispatchSource.ProcessEvent
    static let signal: DispatchSource.ProcessEvent
    static let all: DispatchSource.ProcessEvent
    typealias ArrayLiteralElement = DispatchSource.ProcessEvent
    typealias Element = DispatchSource.ProcessEvent
    typealias RawValue = UInt
  }
  struct TimerFlags : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let strict: DispatchSource.TimerFlags
    typealias ArrayLiteralElement = DispatchSource.TimerFlags
    typealias Element = DispatchSource.TimerFlags
    typealias RawValue = UInt
  }
  struct FileSystemEvent : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let delete: DispatchSource.FileSystemEvent
    static let write: DispatchSource.FileSystemEvent
    static let extend: DispatchSource.FileSystemEvent
    static let attrib: DispatchSource.FileSystemEvent
    static let link: DispatchSource.FileSystemEvent
    static let rename: DispatchSource.FileSystemEvent
    static let revoke: DispatchSource.FileSystemEvent
    static let funlock: DispatchSource.FileSystemEvent
    static let all: DispatchSource.FileSystemEvent
    typealias ArrayLiteralElement = DispatchSource.FileSystemEvent
    typealias Element = DispatchSource.FileSystemEvent
    typealias RawValue = UInt
  }
  class func makeMachSendSource(port: mach_port_t, eventMask: DispatchSource.MachSendEvent, queue: DispatchQueue? = nil) -> DispatchSourceMachSend
  class func makeMachReceiveSource(port: mach_port_t, queue: DispatchQueue? = nil) -> DispatchSourceMachReceive
  class func makeMemoryPressureSource(eventMask: DispatchSource.MemoryPressureEvent, queue: DispatchQueue? = nil) -> DispatchSourceMemoryPressure
  class func makeProcessSource(identifier: pid_t, eventMask: DispatchSource.ProcessEvent, queue: DispatchQueue? = nil) -> DispatchSourceProcess
  class func makeReadSource(fileDescriptor: Int32, queue: DispatchQueue? = nil) -> DispatchSourceRead
  class func makeSignalSource(signal: Int32, queue: DispatchQueue? = nil) -> DispatchSourceSignal
  class func makeTimerSource(flags: DispatchSource.TimerFlags = [], queue: DispatchQueue? = nil) -> DispatchSourceTimer
  class func makeUserDataAddSource(queue: DispatchQueue? = nil) -> DispatchSourceUserDataAdd
  class func makeUserDataOrSource(queue: DispatchQueue? = nil) -> DispatchSourceUserDataOr
  class func makeUserDataReplaceSource(queue: DispatchQueue? = nil) -> DispatchSourceUserDataReplace
  class func makeFileSystemObjectSource(fileDescriptor: Int32, eventMask: DispatchSource.FileSystemEvent, queue: DispatchQueue? = nil) -> DispatchSourceFileSystemObject
  class func makeWriteSource(fileDescriptor: Int32, queue: DispatchQueue? = nil) -> DispatchSourceWrite
}

extension DispatchSourceMachSend {
  var handle: mach_port_t { get }
  var data: DispatchSource.MachSendEvent { get }
  var mask: DispatchSource.MachSendEvent { get }
}

extension DispatchSourceMachReceive {
  var handle: mach_port_t { get }
}

extension DispatchSourceMemoryPressure {
  var data: DispatchSource.MemoryPressureEvent { get }
  var mask: DispatchSource.MemoryPressureEvent { get }
}

extension DispatchSourceProcess {
  var handle: pid_t { get }
  var data: DispatchSource.ProcessEvent { get }
  var mask: DispatchSource.ProcessEvent { get }
}

extension DispatchSourceTimer {
  ///
  /// Sets the deadline and leeway for a timer event that fires once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared and the next timer event will occur at `deadline`.
  ///
  /// Delivery of the timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  /// - note: Delivery of the timer event does not cancel the timer source.
  ///
  /// - parameter deadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(deadline:repeating:leeway:)")
  func scheduleOneshot(deadline: DispatchTime, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline and leeway for a timer event that fires once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared and the next timer event will occur at `wallDeadline`.
  ///
  /// Delivery of the timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  /// - note: Delivery of the timer event does not cancel the timer source.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(wallDeadline:repeating:leeway:)")
  func scheduleOneshot(wallDeadline: DispatchWallTime, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `deadline` and every `interval` units of
  /// time thereafter until the timer source is canceled.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `deadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `deadline + N * interval`, the upper
  /// limit is the smaller of `leeway` and `interval/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter deadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter interval: the interval for the timer.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(deadline:repeating:leeway:)")
  func scheduleRepeating(deadline: DispatchTime, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `deadline` and every `interval` seconds
  /// thereafter until the timer source is canceled.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption and
  /// system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `deadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `deadline + N * interval`, the upper
  /// limit is the smaller of `leeway` and `interval/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter deadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter interval: the interval for the timer in seconds.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(deadline:repeating:leeway:)")
  func scheduleRepeating(deadline: DispatchTime, interval: Double, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `wallDeadline` and every `interval` units of
  /// time thereafter until the timer source is canceled.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption and
  /// system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `wallDeadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `wallDeadline + N * interval`, the upper
  /// limit is the smaller of `leeway` and `interval/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter interval: the interval for the timer.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(wallDeadline:repeating:leeway:)")
  func scheduleRepeating(wallDeadline: DispatchWallTime, interval: DispatchTimeInterval, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `wallDeadline` and every `interval` seconds
  /// thereafter until the timer source is canceled.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption and
  /// system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `wallDeadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `wallDeadline + N * interval`, the upper
  /// limit is the smaller of `leeway` and `interval/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter interval: the interval for the timer in seconds.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift, deprecated: 4, renamed: "schedule(wallDeadline:repeating:leeway:)")
  func scheduleRepeating(wallDeadline: DispatchWallTime, interval: Double, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, repeat interval and leeway for a timer event.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `deadline` and every `repeating` units of
  /// time thereafter until the timer source is canceled. If the value of `repeating` is `.never`,
  /// or is defaulted, the timer fires only once.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `deadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `deadline + N * repeating`, the upper
  /// limit is the smaller of `leeway` and `repeating/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter deadline: the time at which the first timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter repeating: the repeat interval for the timer, or `.never` if the timer should fire
  ///		only once.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift 4)
  func schedule(deadline: DispatchTime, repeating interval: DispatchTimeInterval = .never, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, repeat interval and leeway for a timer event.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `deadline` and every `repeating` seconds
  /// thereafter until the timer source is canceled. If the value of `repeating` is `.infinity`,
  /// the timer fires only once.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `deadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `deadline + N * repeating`, the upper
  /// limit is the smaller of `leeway` and `repeating/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter deadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on Mach absolute
  ///     time.
  /// - parameter repeating: the repeat interval for the timer in seconds, or `.infinity` if the timer
  ///		should fire only once.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift 4)
  func schedule(deadline: DispatchTime, repeating interval: Double, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, repeat interval and leeway for a timer event.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `wallDeadline` and every `repeating` units of
  /// time thereafter until the timer source is canceled. If the value of `repeating` is `.never`,
  /// or is defaulted, the timer fires only once.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption and
  /// system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `wallDeadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `wallDeadline + N * repeating`, the upper
  /// limit is the smaller of `leeway` and `repeating/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter repeating: the repeat interval for the timer, or `.never` if the timer should fire
  ///		only once.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift 4)
  func schedule(wallDeadline: DispatchWallTime, repeating interval: DispatchTimeInterval = .never, leeway: DispatchTimeInterval = .nanoseconds(0))
  ///
  /// Sets the deadline, repeat interval and leeway for a timer event that fires at least once.
  ///
  /// Once this function returns, any pending source data accumulated for the previous timer values
  /// has been cleared. The next timer event will occur at `wallDeadline` and every `repeating` seconds
  /// thereafter until the timer source is canceled. If the value of `repeating` is `.infinity`,
  /// the timer fires only once.
  ///
  /// Delivery of a timer event may be delayed by the system in order to improve power consumption
  /// and system performance. The upper limit to the allowable delay may be configured with the `leeway`
  /// argument; the lower limit is under the control of the system.
  ///
  /// For the initial timer fire at `wallDeadline`, the upper limit to the allowable delay is set to
  /// `leeway`. For the subsequent timer fires at `wallDeadline + N * repeating`, the upper
  /// limit is the smaller of `leeway` and `repeating/2`.
  ///
  /// The lower limit to the allowable delay may vary with process state such as visibility of the
  /// application UI. If the timer source was created with flags `TimerFlags.strict`, the system
  /// will make a best effort to strictly observe the provided `leeway` value, even if it is smaller
  /// than the current lower limit. Note that a minimal amount of delay is to be expected even if
  /// this flag is specified.
  ///
  /// Calling this method has no effect if the timer source has already been canceled.
  ///
  /// - parameter wallDeadline: the time at which the timer event will be delivered, subject to the
  ///     leeway and other considerations described above. The deadline is based on
  ///     `gettimeofday(3)`.
  /// - parameter repeating: the repeat interval for the timer in secondss, or `.infinity` if the timer
  /// 	should fire only once.
  /// - parameter leeway: the leeway for the timer.
  ///
  @available(swift 4)
  func schedule(wallDeadline: DispatchWallTime, repeating interval: Double, leeway: DispatchTimeInterval = .nanoseconds(0))
}

extension DispatchSourceFileSystemObject {
  var handle: Int32 { get }
  var data: DispatchSource.FileSystemEvent { get }
  var mask: DispatchSource.FileSystemEvent { get }
}

extension DispatchSourceUserDataAdd {
  /// @function add
  ///
  /// @abstract
  /// Merges data into a dispatch source of type DISPATCH_SOURCE_TYPE_DATA_ADD
  /// and submits its event handler block to its target queue.
  ///
  /// @param data
  /// The value to add to the current pending data. A value of zero has no effect
  /// and will not result in the submission of the event handler block.
  func add(data: UInt)
}

extension DispatchSourceUserDataOr {
  /// @function or
  ///
  /// @abstract
  /// Merges data into a dispatch source of type DISPATCH_SOURCE_TYPE_DATA_OR and
  /// submits its event handler block to its target queue.
  ///
  /// @param data
  /// The value to OR into the current pending data. A value of zero has no effect
  /// and will not result in the submission of the event handler block.
  func or(data: UInt)
}

extension DispatchSourceUserDataReplace {
  /// @function replace
  ///
  /// @abstract
  /// Merges data into a dispatch source of type DISPATCH_SOURCE_TYPE_DATA_REPLACE
  /// and submits its event handler block to its target queue.
  ///
  /// @param data
  /// The value that will replace the current pending data. A value of zero will be stored
  /// but will not result in the submission of the event handler block.
  func replace(data: UInt)
}

@available(macOS 10.15, iOS 13.0, tvOS 13.0, watchOS 6.0, *)
extension DispatchQueue : Scheduler {
  /// The scheduler time type used by the dispatch queue.
  struct SchedulerTimeType : Strideable, Codable, Hashable {
    /// The dispatch time represented by this type.
    var dispatchTime: DispatchTime
    /// Creates a dispatch queue time type instance.
    ///
    /// - Parameter time: The dispatch time to represent.
    init(_ time: DispatchTime)
    init(from decoder: Decoder) throws
    func encode(to encoder: Encoder) throws
    /// Returns the distance to another dispatch queue time.
    ///
    /// - Parameter other: Another dispatch queue time.
    /// - Returns: The time interval between this time and the provided time.
    func distance(to other: DispatchQueue.SchedulerTimeType) -> DispatchQueue.SchedulerTimeType.Stride
    /// Returns a dispatch queue scheduler time calculated by advancing this instance’s time by the given interval.
    ///
    /// - Parameter n: A time interval to advance.
    /// - Returns: A dispatch queue time advanced by the given interval from this instance’s time.
    func advanced(by n: DispatchQueue.SchedulerTimeType.Stride) -> DispatchQueue.SchedulerTimeType
    func hash(into hasher: inout Hasher)
    @_alwaysEmitIntoClient static func < (lhs: DispatchQueue.SchedulerTimeType, rhs: DispatchQueue.SchedulerTimeType) -> Bool
    struct Stride : SchedulerTimeIntervalConvertible, Comparable, SignedNumeric, ExpressibleByFloatLiteral, Hashable, Codable {
      /// If created via floating point literal, the value is converted to nanoseconds via multiplication.
      typealias FloatLiteralType = Double
      /// Nanoseconds, same as DispatchTimeInterval.
      typealias IntegerLiteralType = Int
      typealias Magnitude = Int
      /// The value of this time interval in nanoseconds.
      var magnitude: Int
      /// A `DispatchTimeInterval` created with the value of this type in nanoseconds.
      var timeInterval: DispatchTimeInterval { get }
      /// Creates a dispatch queue time interval from the given dispatch time interval.
      ///
      /// - Parameter timeInterval: A dispatch time interval.
      init(_ timeInterval: DispatchTimeInterval)
      /// Creates a dispatch queue time interval from a floating-point seconds value.
      ///
      /// - Parameter value: The number of seconds, as a `Double`.
      init(floatLiteral value: Double)
      /// Creates a dispatch queue time interval from an integer seconds value.
      ///
      /// - Parameter value: The number of seconds, as an `Int`.
      init(integerLiteral value: Int)
      /// Creates a dispatch queue time interval from a binary integer type representing a number of seconds.
      ///
      /// If `source` cannot be exactly represented, the resulting time interval is `nil`.
      /// - Parameter source: A binary integer representing a time interval.
      init?<T>(exactly source: T) where T : BinaryInteger
      static func < (lhs: DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride) -> Bool
      static func * (lhs: DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride) -> DispatchQueue.SchedulerTimeType.Stride
      static func + (lhs: DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride) -> DispatchQueue.SchedulerTimeType.Stride
      static func - (lhs: DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride) -> DispatchQueue.SchedulerTimeType.Stride
      static func -= (lhs: inout DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride)
      static func *= (lhs: inout DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride)
      static func += (lhs: inout DispatchQueue.SchedulerTimeType.Stride, rhs: DispatchQueue.SchedulerTimeType.Stride)
      static func seconds(_ s: Double) -> DispatchQueue.SchedulerTimeType.Stride
      static func seconds(_ s: Int) -> DispatchQueue.SchedulerTimeType.Stride
      static func milliseconds(_ ms: Int) -> DispatchQueue.SchedulerTimeType.Stride
      static func microseconds(_ us: Int) -> DispatchQueue.SchedulerTimeType.Stride
      static func nanoseconds(_ ns: Int) -> DispatchQueue.SchedulerTimeType.Stride
      func hash(into hasher: inout Hasher)
      static func == (a: DispatchQueue.SchedulerTimeType.Stride, b: DispatchQueue.SchedulerTimeType.Stride) -> Bool
      func encode(to encoder: Encoder) throws
      var hashValue: Int { get }
      init(from decoder: Decoder) throws
    }
    var hashValue: Int { get }
  }
  /// Options that affect the operation of the dispatch queue scheduler.
  struct SchedulerOptions {
    /// The dispatch queue quality of service.
    var qos: DispatchQoS
    /// The dispatch queue work item flags.
    var flags: DispatchWorkItemFlags
    /// The dispatch group, if any, that should be used for performing actions.
    var group: DispatchGroup?
    init(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], group: DispatchGroup? = nil)
  }
  var minimumTolerance: DispatchQueue.SchedulerTimeType.Stride { get }
  var now: DispatchQueue.SchedulerTimeType { get }
  func schedule(options: DispatchQueue.SchedulerOptions?, _ action: @escaping () -> Void)
  func schedule(after date: DispatchQueue.SchedulerTimeType, tolerance: DispatchQueue.SchedulerTimeType.Stride, options: DispatchQueue.SchedulerOptions?, _ action: @escaping () -> Void)
  func schedule(after date: DispatchQueue.SchedulerTimeType, interval: DispatchQueue.SchedulerTimeType.Stride, tolerance: DispatchQueue.SchedulerTimeType.Stride, options: DispatchQueue.SchedulerOptions?, _ action: @escaping () -> Void) -> Cancellable
}

extension DispatchIO {
  enum StreamType : UInt {
    case stream
    case random
    init?(rawValue: UInt)
    typealias RawValue = UInt
    var rawValue: UInt { get }
  }
  struct CloseFlags : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    static let stop: DispatchIO.CloseFlags
    typealias ArrayLiteralElement = DispatchIO.CloseFlags
    typealias Element = DispatchIO.CloseFlags
    typealias RawValue = UInt
  }
  struct IntervalFlags : OptionSet, RawRepresentable {
    let rawValue: UInt
    init(rawValue: UInt)
    init(nilLiteral: ())
    static let strictInterval: DispatchIO.IntervalFlags
    typealias ArrayLiteralElement = DispatchIO.IntervalFlags
    typealias Element = DispatchIO.IntervalFlags
    typealias RawValue = UInt
  }
  class func read(fromFileDescriptor: Int32, maxLength: Int, runningHandlerOn queue: DispatchQueue, handler: @escaping (_ data: DispatchData, _ error: Int32) -> Void)
  class func write(toFileDescriptor: Int32, data: DispatchData, runningHandlerOn queue: DispatchQueue, handler: @escaping (_ data: DispatchData?, _ error: Int32) -> Void)
  convenience init(type: DispatchIO.StreamType, fileDescriptor: Int32, queue: DispatchQueue, cleanupHandler: @escaping (_ error: Int32) -> Void)
  @available(swift, obsoleted: 4)
  convenience init(type: DispatchIO.StreamType, path: UnsafePointer<Int8>, oflag: Int32, mode: mode_t, queue: DispatchQueue, cleanupHandler: @escaping (_ error: Int32) -> Void)
  @available(swift 4)
  convenience init?(type: DispatchIO.StreamType, path: UnsafePointer<Int8>, oflag: Int32, mode: mode_t, queue: DispatchQueue, cleanupHandler: @escaping (_ error: Int32) -> Void)
  convenience init(type: DispatchIO.StreamType, io: DispatchIO, queue: DispatchQueue, cleanupHandler: @escaping (_ error: Int32) -> Void)
  func read(offset: off_t, length: Int, queue: DispatchQueue, ioHandler: @escaping (_ done: Bool, _ data: DispatchData?, _ error: Int32) -> Void)
  func write(offset: off_t, data: DispatchData, queue: DispatchQueue, ioHandler: @escaping (_ done: Bool, _ data: DispatchData?, _ error: Int32) -> Void)
  func setInterval(interval: DispatchTimeInterval, flags: DispatchIO.IntervalFlags = [])
  func close(flags: DispatchIO.CloseFlags = [])
}

/// dispatch_group
extension DispatchGroup {
  func notify(qos: DispatchQoS = .unspecified, flags: DispatchWorkItemFlags = [], queue: DispatchQueue, execute work: @escaping @convention(block) () -> Void)
  @available(macOS 10.10, iOS 8.0, *)
  func notify(queue: DispatchQueue, work: DispatchWorkItem)
  func wait()
  func wait(timeout: DispatchTime) -> DispatchTimeoutResult
  func wait(wallTimeout timeout: DispatchWallTime) -> DispatchTimeoutResult
}

/// dispatch_semaphore
extension DispatchSemaphore {
  @discardableResult
  func signal() -> Int
  func wait()
  func wait(timeout: DispatchTime) -> DispatchTimeoutResult
  func wait(wallTimeout: DispatchWallTime) -> DispatchTimeoutResult
}

@available(*, unavailable, renamed: "DispatchQueue.GlobalQueuePriority.high")
let DISPATCH_QUEUE_PRIORITY_HIGH: Int { get }

@available(*, unavailable, renamed: "DispatchQueue.GlobalQueuePriority.default")
let DISPATCH_QUEUE_PRIORITY_DEFAULT: Int { get }

@available(*, unavailable, renamed: "DispatchQueue.GlobalQueuePriority.low")
let DISPATCH_QUEUE_PRIORITY_LOW: Int { get }

@available(*, unavailable, renamed: "DispatchQueue.GlobalQueuePriority.background")
let DISPATCH_QUEUE_PRIORITY_BACKGROUND: Int { get }

@available(*, unavailable, renamed: "DispatchIO.StreamType.stream")
let DISPATCH_IO_STREAM: Int { get }

@available(*, unavailable, renamed: "DispatchIO.StreamType.random")
let DISPATCH_IO_RANDOM: Int { get }

@available(*, unavailable, renamed: "DispatchIO.CloseFlags.stop")
let DISPATCH_IO_STOP: Int { get }

@available(*, unavailable, renamed: "DispatchIO.IntervalFlags.strictInterval")
let DISPATCH_IO_STRICT_INTERVAL: Int { get }

@available(*, unavailable, renamed: "DispatchSource.MachSendEvent.dead")
let DISPATCH_MACH_SEND_DEAD: Int { get }

@available(*, unavailable, renamed: "DispatchSource.MemoryPressureEvent.normal")
let DISPATCH_MEMORYPRESSURE_NORMAL: Int { get }

@available(*, unavailable, renamed: "DispatchSource.MemoryPressureEvent.warning")
let DISPATCH_MEMORYPRESSURE_WARN: Int { get }

@available(*, unavailable, renamed: "DispatchSource.MemoryPressureEvent.critical")
let DISPATCH_MEMORYPRESSURE_CRITICAL: Int { get }

@available(*, unavailable, renamed: "DispatchSource.ProcessEvent.exit")
let DISPATCH_PROC_EXIT: Int { get }

@available(*, unavailable, renamed: "DispatchSource.ProcessEvent.fork")
let DISPATCH_PROC_FORK: Int { get }

@available(*, unavailable, renamed: "DispatchSource.ProcessEvent.exec")
let DISPATCH_PROC_EXEC: Int { get }

@available(*, unavailable, renamed: "DispatchSource.ProcessEvent.signal")
let DISPATCH_PROC_SIGNAL: Int { get }

@available(*, unavailable, renamed: "DispatchSource.TimerFlags.strict")
let DISPATCH_TIMER_STRICT: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.delete")
let DISPATCH_VNODE_DELETE: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.write")
let DISPATCH_VNODE_WRITE: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.extend")
let DISPATCH_VNODE_EXTEND: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.attrib")
let DISPATCH_VNODE_ATTRIB: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.link")
let DISPATCH_VNODE_LINK: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.rename")
let DISPATCH_VNODE_RENAME: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.revoke")
let DISPATCH_VNODE_REVOKE: Int { get }

@available(*, unavailable, renamed: "DispatchSource.FileSystemEvent.funlock")
let DISPATCH_VNODE_FUNLOCK: Int { get }

@available(*, unavailable, renamed: "DispatchTime.now()")
let DISPATCH_TIME_NOW: Int { get }

@available(*, unavailable, renamed: "DispatchTime.distantFuture")
let DISPATCH_TIME_FOREVER: Int { get }

